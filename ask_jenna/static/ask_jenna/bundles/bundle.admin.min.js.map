{"version":3,"file":"static/ask_jenna/bundles/bundle.admin.min.js","mappings":";;;;;;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA,kLAAkL,QAAQ,cAAc,QAAQ;AAChN,0BAA0B,EAAE;AAC5B;AACA;AACA;AACA,oBAAoB,cAAc;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,eAAe,iDAAiD,2BAA2B,GAAG,EAAE,iCAAiC,EAAE,4BAA4B,EAAE;AAC5L,kCAAkC,gBAAgB;AAClD,cAAc,EAAE,EAAE,kBAAkB,EAAE,EAAE;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,oBAAoB,cAAc;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN,0BAA0B,UAAU,kBAAkB;AACtD,uCAAuC,EAAE,iDAAiD,EAAE,+BAA+B,EAAE;AAC7H;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,k7BAAk7B,wFAAwF,oLAAoL,SAAS,ucAAuc,SAAS,ulBAAulB,SAAS,2jBAA2jB,SAAS,4KAA4K,SAAS,kLAAkL,SAAS,4KAA4K;AACn2G;AACA,8BAA8B,qKAAqK;AACnM,sCAAsC,qKAAqK;AAC3M,kCAAkC,qKAAqK;AACvM,aAAa,0RAA0R;AACvS,eAAe,0rBAA0rB;AACzsB,0BAA0B,0rBAA0rB;AACptB,oBAAoB,2rBAA2rB;AAC/sB,+BAA+B,2rBAA2rB;AAC1tB,oBAAoB,2rBAA2rB;AAC/sB,+BAA+B,2rBAA2rB;AAC1tB,cAAc,igBAAigB;AAC/gB,yCAAyC,2aAA2a;AACpd,wCAAwC,igBAAigB;AACziB,6BAA6B,2jBAA2jB,oGAAoG;AAC5rB,uBAAuB,mgBAAmgB;AAC1hB,kCAAkC,miBAAmiB;AACrkB,4BAA4B,maAAma;AAC/b,uCAAuC,maAAma;AAC1c,uCAAuC,maAAma;AAC1c,uCAAuC,maAAma;AAC1c,iCAAiC,maAAma;AACpc,4CAA4C,maAAma;AAC/c,mBAAmB,+fAA+f;AAClhB,6CAA6C,+fAA+f;AAC5iB,kCAAkC,yjBAAyjB,sGAAsG;AACjsB,8BAA8B,giBAAgiB,6FAA6F;AAC3pB,yBAAyB,qkBAAqkB;AAC9lB,cAAc,spBAAspB;AACpqB,yBAAyB,spBAAspB;AAC/qB;AACA,eAAe,yRAAyR;AACxS,4BAA4B,qgBAAqgB;AACjiB,cAAc,ulBAAulB;AACrmB,yBAAyB,ulBAAulB;AAChnB;AACA,qBAAqB,ulBAAulB;AAC5mB,eAAe,kZAAkZ;AACja,0BAA0B,kZAAkZ;AAC5a,eAAe,2aAA2a;AAC1b,0BAA0B,2aAA2a;AACrc,0BAA0B,gTAAgT;AAC1U,kBAAkB,gTAAgT;AAClU,6BAA6B,gTAAgT;AAC7U,qBAAqB,ucAAuc;AAC5d,yBAAyB,iXAAiX;AAC1Y,yBAAyB,4bAA4b;AACrd,yBAAyB,igBAAigB;AAC1hB,yBAAyB,igBAAigB;AAC1hB,0CAA0C,ifAAif;AAC3hB,+BAA+B,ocAAoc;AACne,0CAA0C,ocAAoc;AAC9e,oCAAoC,ifAAif;AACrhB,+CAA+C,ifAAif;AAChiB,2BAA2B,2VAA2V;AACtX,kBAAkB,2PAA2P;AAC7Q,kBAAkB,0TAA0T;AAC5U,iBAAiB,6PAA6P;AAC9Q,sBAAsB,6PAA6P;AACnR,sBAAsB,6PAA6P;AACnR,mBAAmB,gXAAgX;AACnY,8BAA8B,gXAAgX;AAC9Y,0BAA0B,mUAAmU;AAC7V,0BAA0B,mUAAmU;AAC7V,4BAA4B,yUAAyU;AACrW,iCAAiC,yUAAyU;AAC1W,qBAAqB,4RAA4R;AACjT,0BAA0B,4PAA4P;AACtR,0BAA0B,2RAA2R;AACrT,0BAA0B,oUAAoU;AAC9V,0BAA0B,qUAAqU;AAC/V,yBAAyB,6PAA6P;AACtR,8BAA8B,6PAA6P;AAC3R,wBAAwB,ySAAyS;AACjU,6BAA6B,+NAA+N;AAC5P,6BAA6B,+NAA+N;AAC5P,6BAA6B,8NAA8N;AAC3P,qBAAqB,8XAA8X;AACnZ,4BAA4B,mcAAmc;AAC/d,4BAA4B,6bAA6b;AACzd,iCAAiC,+fAA+f;AAChiB,sBAAsB,uQAAuQ;AAC7R,sBAAsB,uQAAuQ;AAC7R,8BAA8B,iPAAiP;AAC/Q,8BAA8B,+OAA+O;AAC7Q,8BAA8B,yKAAyK;AACvM,iCAAiC,qNAAqN;AACtP,8BAA8B,qKAAqK;AACnM,2BAA2B,qKAAqK;AAChM,8BAA8B,qKAAqK;AACnM,0BAA0B,iHAAiH;AAC3I,0BAA0B,+GAA+G;AACzI,4BAA4B,6GAA6G;AACzI,+BAA+B,gHAAgH;AAC/I,+BAA+B,gHAAgH;AAC/I,+BAA+B,gHAAgH;AAC/I,qCAAqC,gHAAgH;AACrJ,qCAAqC,gHAAgH;AACrJ,qCAAqC,kHAAkH;AACvJ,mBAAmB,qKAAqK;AACxL,mCAAmC,qKAAqK;AACxM,sCAAsC,qKAAqK;AAC3M,oCAAoC,sKAAsK;AAC1M,mCAAmC,qKAAqK;AACxM,sCAAsC,qKAAqK;AAC3M,oCAAoC,sKAAsK;AAC1M,mCAAmC,qKAAqK;AACxM,sCAAsC,qKAAqK;AAC3M,oCAAoC,sKAAsK;AAC1M,yBAAyB,wPAAwP;AACjR,8BAA8B,yPAAyP;AACvR,iBAAiB,uKAAuK;AACxL,aAAa,8HAA8H;AAC3I,gBAAgB,6HAA6H;AAC7I,uBAAuB,2SAA2S;AAClU,6BAA6B,0SAA0S;AACvU,kCAAkC,qgBAAqgB;AACviB,6CAA6C,4nBAA4nB;AACzqB,kDAAkD,4nBAA4nB;AAC9qB,qBAAqB,2tBAA2tB,oGAAoG;AACp1B,gCAAgC,2tBAA2tB,oGAAoG;AAC/1B,0BAA0B,4tBAA4tB,sGAAsG;AAC51B,qCAAqC,4tBAA4tB,sGAAsG;AACv2B,0BAA0B,kqBAAkqB;AAC5rB,qCAAqC,kqBAAkqB;AACvsB,gBAAgB,4iBAA4iB;AAC5jB,2BAA2B,4iBAA4iB;AACvkB,qBAAqB,+iBAA+iB;AACpkB,qDAAqD,gfAAgf;AACriB,wDAAwD,sfAAsf;AAC9iB,wDAAwD,sfAAsf;AAC9iB,gDAAgD,4hBAA4hB;AAC5kB,mDAAmD,0kBAA0kB;AAC7nB,mDAAmD,0kBAA0kB;AAC7nB,gDAAgD,gfAAgf;AAChiB,mDAAmD,sfAAsf;AACziB,mDAAmD,sfAAsf;AACziB,gCAAgC,kZAAkZ;AAClb,gCAAgC,4SAA4S;AAC5U,mCAAmC,4XAA4X;AAC/Z,mCAAmC,4XAA4X;AAC/Z,mBAAmB,kFAAkF;AACrG,sBAAsB,iFAAiF;AACvG,uBAAuB,mHAAmH;AAC1I,+BAA+B,uPAAuP;AACtR,oCAAoC,wPAAwP;AAC5R,qBAAqB,0UAA0U;AAC/V,qBAAqB,kWAAkW;AACvX,gCAAgC,+VAA+V;AAC/X,mCAAmC,uZAAuZ;AAC1b,mCAAmC,uZAAuZ;AAC1b,gBAAgB,kXAAkX;AAClY,2BAA2B,kXAAkX;AAC7Y,8BAA8B,6VAA6V;AAC3X,8BAA8B,6VAA6V;AAC3X,+BAA+B,okBAAokB;AACnmB,wBAAwB,8VAA8V;AACtX,mCAAmC,sXAAsX;AACzZ,sCAAsC,yUAAyU;AAC/W,sCAAsC,yUAAyU;AAC/W,6BAA6B,0eAA0e;AACvgB,oBAAoB,+XAA+X;AACnZ,sCAAsC,+XAA+X;AACra,+BAA+B,+XAA+X;AAC9Z,sCAAsC,+XAA+X;AACra,+BAA+B,iYAAiY;AACha,kCAAkC,wWAAwW;AAC1Y,kCAAkC,wWAAwW;AAC1Y,+BAA+B,0TAA0T;AACzV,+CAA+C,+ZAA+Z;AAC9c,kCAAkC,kYAAkY;AACpa,kCAAkC,kYAAkY;AACpa,+CAA+C,kYAAkY;AACjb,yCAAyC,6TAA6T;AACtW,yBAAyB,gYAAgY;AACzZ,oCAAoC,gYAAgY;AACpa,uCAAuC,gYAAgY;AACva,uCAAuC,gYAAgY;AACva,oCAAoC,4RAA4R;AAChU,gCAAgC,uQAAuQ;AACvS,gCAAgC,uQAAuQ;AACvS,wBAAwB,8NAA8N;AACtP,4BAA4B,iMAAiM;AAC7N,uBAAuB,iMAAiM;AACxN,mBAAmB,8NAA8N;AACjP,yBAAyB,uQAAuQ;AAChS,wCAAwC,qNAAqN;AAC7P,mCAAmC,+NAA+N;AAClQ,+BAA+B,uSAAuS;AACtU,+BAA+B,uSAAuS;AACtU,+BAA+B,sSAAsS;AACrU,+BAA+B,wSAAwS;AACvU,gCAAgC,wSAAwS;AACxU,8BAA8B,gMAAgM;AAC9N,0BAA0B,+NAA+N;AACzP,2BAA2B,+NAA+N;AAC1P,yCAAyC,wJAAwJ;AACjM,mCAAmC,wJAAwJ;AAC3L,wCAAwC,wJAAwJ;AAChM,kCAAkC,4KAA4K;AAC9M,gCAAgC,4KAA4K;AAC5M,4BAA4B,sMAAsM;AAClO,iBAAiB,8IAA8I;AAC/J,oCAAoC,8IAA8I;AAClL,oCAAoC,+IAA+I;AACnL,oCAAoC,8IAA8I;AAClL,yBAAyB,oKAAoK;AAC7L,yCAAyC,oKAAoK;AAC7M,4CAA4C,oKAAoK;AAChN,0CAA0C,qKAAqK;AAC/M,yCAAyC,oKAAoK;AAC7M,4CAA4C,oKAAoK;AAChN,0CAA0C,qKAAqK;AAC/M,yCAAyC,oKAAoK;AAC7M,4CAA4C,oKAAoK;AAChN,0CAA0C,qKAAqK;AAC/M,2CAA2C,iHAAiH;AAC5J,qCAAqC,+GAA+G;AACpJ,2CAA2C,+GAA+G;AAC1J,2CAA2C,+GAA+G;AAC1J,qCAAqC,+GAA+G;AACpJ,qCAAqC,+GAA+G;AACpJ,2CAA2C,wGAAwG;AACnJ,4BAA4B,qXAAqX;AACjZ,4BAA4B,6UAA6U;AACzW,iCAAiC,4WAA4W;AAC7Y,+BAA+B,iMAAiM;AAChO,6BAA6B,iUAAiU;AAC9V,oCAAoC,mQAAmQ;AACvS,8BAA8B,kOAAkO;AAChQ,8BAA8B,iOAAiO;AAC/P,mCAAmC,yPAAyP;AAC5R,mCAAmC,yVAAyV;AAC5X,qCAAqC,yVAAyV;AAC9X,6BAA6B,qVAAqV;AAClX,8CAA8C,+XAA+X;AAC7a,uCAAuC,8VAA8V;AACrY,+CAA+C,iXAAiX;AACha,uDAAuD,mXAAmX;AAC1a,8CAA8C,iYAAiY;AAC/a,0CAA0C,oMAAoM;AAC9O,2CAA2C,0UAA0U;AACrX,4CAA4C,8UAA8U;AAC1X,6CAA6C,8UAA8U;AAC3X,oCAAoC,4WAA4W;AAChZ,0CAA0C,6bAA6b;AACve,sBAAsB,4ZAA4Z;AAClb,sCAAsC,8RAA8R;AACpU,wCAAwC,8RAA8R;AACtU,qCAAqC,8RAA8R;AACnU,uCAAuC,6RAA6R;AACpU,yCAAyC,8RAA8R;AACvU,wCAAwC,4RAA4R;AACpU,0CAA0C,6RAA6R;AACvU,yCAAyC,6RAA6R;AACtU,2CAA2C,8RAA8R;AACzU,8CAA8C,wNAAwN;AACtQ,yCAAyC,wNAAwN;AACjQ,wCAAwC,6UAA6U;AACrX,6CAA6C,6UAA6U;AAC1X,4BAA4B,2ZAA2Z;AACvb,mBAAmB,8LAA8L;AACjN,mBAAmB,8LAA8L;AACjN,8BAA8B,6LAA6L;AAC3N,mCAAmC,6LAA6L;AAChO,wBAAwB,4KAA4K;AACpM,4BAA4B,mOAAmO;AAC/P,6BAA6B,gQAAgQ;AAC7R,oCAAoC,gQAAgQ;AACpS,8BAA8B,mOAAmO;AACjQ,qCAAqC,kQAAkQ;AACvS,mCAAmC,kQAAkQ;AACrS,mCAAmC,mOAAmO;AACtQ,oCAAoC,mQAAmQ;AACvS,kCAAkC,mQAAmQ;AACrS,kCAAkC,iQAAiQ;AACnS,kCAAkC,mQAAmQ;AACrS,oCAAoC,wRAAwR;AAC5T,kCAAkC,wRAAwR;AAC1T,gCAAgC,0RAA0R;AAC1T,+BAA+B,mOAAmO;AAClQ,iCAAiC,gQAAgQ;AACjS,kCAAkC,iQAAiQ;AACnS,gCAAgC,iOAAiO;AACjQ,8BAA8B,iOAAiO;AAC/P,iCAAiC,8QAA8Q;AAC/S,sCAAsC,8QAA8Q;AACpT,oCAAoC,gRAAgR;AACpT,sCAAsC,gRAAgR;AACtT,mCAAmC,+SAA+S;AAClV,qCAAqC,kUAAkU;AACvW,oCAAoC,4TAA4T;AAChW,6BAA6B,sHAAsH;AACnJ,kCAAkC,iWAAiW;AACnY,8BAA8B,8YAA8Y;AAC5a,kCAAkC,8RAA8R;AAChU,gCAAgC,8RAA8R;AAC9T,kDAAkD,0PAA0P;AAC5S,gDAAgD,0PAA0P;AAC1S,qBAAqB,iRAAiR;AACtS,8BAA8B,ySAAyS;AACvU,gCAAgC,ySAAyS;AACzU,yBAAyB,ySAAyS;AAClU,kBAAkB,8TAA8T;AAChV,uBAAuB,8TAA8T;AACrV,4BAA4B,8TAA8T;AAC1V,8BAA8B,8TAA8T;AAC5V,4BAA4B,qVAAqV;AACjX,iCAAiC,qVAAqV;AACtX,mCAAmC,qVAAqV;AACxX,4BAA4B,uSAAuS;AACnU,uBAAuB,2PAA2P;AAClR,kBAAkB,2PAA2P;AAC7Q,yBAAyB,2PAA2P;AACpR,+BAA+B,wUAAwU;AACvW,0CAA0C,wRAAwR;AAClU,oCAAoC,gQAAgQ;AACpS,kCAAkC,gOAAgO;AAClQ,6BAA6B,oKAAoK;AACjM,4BAA4B,2PAA2P;AACvR,2BAA2B,8LAA8L;AACzN,iCAAiC,2RAA2R;AAC5T,iCAAiC,2RAA2R;AAC5T,uCAAuC,6RAA6R;AACpU,yCAAyC,kTAAkT;AAC3V,uCAAuC,2RAA2R;AAClU,yCAAyC,gTAAgT;AACzV,4BAA4B,8NAA8N;AAC1P,iCAAiC,4PAA4P;AAC7R,oCAAoC,6RAA6R;AACjU,qCAAqC,6PAA6P;AAClS,sDAAsD,+PAA+P;AACrT,0DAA0D,6PAA6P;AACvT,6BAA6B,sKAAsK;AACnM,+BAA+B,gSAAgS;AAC/T,wBAAwB,2RAA2R;AACnT,yBAAyB,2PAA2P;AACpR,kDAAkD,6RAA6R;AAC/U,iDAAiD,6RAA6R;AAC9U,yBAAyB,wRAAwR;AACjT,uBAAuB,gJAAgJ;AACvK,6BAA6B,kHAAkH;AAC/I,mCAAmC,kHAAkH;AACrJ,uCAAuC,iHAAiH;AACxJ,4BAA4B,oOAAoO;AAChQ,6BAA6B,oOAAoO;AACjQ,8BAA8B,sOAAsO;AACpQ,2BAA2B,kSAAkS;AAC7T,6CAA6C,uUAAuU;AACpX,8CAA8C,uUAAuU;AACrX,0BAA0B,sMAAsM;AAChO,gBAAgB,yKAAyK;AACzL,kBAAkB,mMAAmM;AACrN,+BAA+B,keAAke;AACjgB,iCAAiC,sOAAsO,iGAAiG,6UAA6U;AACrrB,+BAA+B,wOAAwO,iGAAiG,6UAA6U;AACrrB,4BAA4B,qeAAqe;AACjgB,8BAA8B,qeAAqe;AACngB,gCAAgC,sZAAsZ;AACtb,gCAAgC,oQAAoQ,iGAAiG,6UAA6U;AACltB,kCAAkC,0fAA0f;AAC5hB,8BAA8B,8JAA8J,iGAAiG,qZAAqZ;AAClrB,gCAAgC,6JAA6J,iGAAiG,mZAAmZ;AACjrB,8BAA8B,8JAA8J,iGAAiG,qZAAqZ;AAClrB,gCAAgC,6JAA6J,iGAAiG,mZAAmZ;AACjrB,gCAAgC,0LAA0L,iGAAiG,wZAAwZ;AACntB,kCAAkC,sQAAsQ,iGAAiG,qWAAqW;AAC9uB,kCAAkC,oQAAoQ,iGAAiG,6UAA6U;AACptB,kBAAkB,oSAAoS;AACtT,sBAAsB,oSAAoS;AAC1T,sBAAsB,oSAAoS;AAC1T,qBAAqB,iWAAiW;AACtX,yBAAyB,iWAAiW;AAC1X,oBAAoB,4RAA4R;AAChT,wBAAwB,4RAA4R;AACpT,kBAAkB,qXAAqX;AACvY,sBAAsB,qXAAqX;AAC3Y,sBAAsB,qZAAqZ;AAC3a,sBAAsB,qXAAqX;AAC3Y,0BAA0B,qXAAqX;AAC/Y,kBAAkB,0XAA0X;AAC5Y,sBAAsB,sWAAsW;AAC5X,sBAAsB,sWAAsW;AAC5X,qBAAqB,sWAAsW;AAC3X,0BAA0B,sWAAsW;AAChY,sBAAsB,gSAAgS;AACtT,sBAAsB,gSAAgS;AACtT,kBAAkB,gSAAgS;AAClT,yBAAyB,gSAAgS;AACzT,6BAA6B,0XAA0X;AACvZ,sBAAsB,0XAA0X;AAChZ,0BAA0B,0XAA0X;AACpZ,0BAA0B,0XAA0X;AACpZ,0BAA0B,0XAA0X;AACpZ,8BAA8B,0XAA0X;AACxZ,qDAAqD,kTAAkT;AACvW,yDAAyD,kTAAkT;AAC3W,yCAAyC,2SAA2S;AACpV,wCAAwC,2SAA2S;AACnV,kBAAkB,yeAAye;AAC3f,sBAAsB,ufAAuf;AAC7gB,0BAA0B,qiBAAqiB;AAC/jB,wBAAwB,kpBAAkpB;AAC1qB,4BAA4B,kpBAAkpB;AAC9qB,0BAA0B,qiBAAqiB;AAC/jB,sBAAsB,khCAAkhC;AACxiC,0BAA0B,uhCAAuhC;AACjjC,0BAA0B,shCAAshC;AAChjC,mCAAmC,8+BAA8+B;AACjhC,mCAAmC,8+BAA8+B;AACjhC,mCAAmC,g9BAAg9B;AACn/B,wBAAwB,snCAAsnC;AAC9oC,iCAAiC,uoCAAuoC;AACxqC,4BAA4B,ypCAAypC;AACrrC,4BAA4B,spCAAspC;AAClrC,qCAAqC,smCAAsmC;AAC3oC,+BAA+B,8aAA8a;AAC7c,iCAAiC,8aAA8a;AAC/c,yBAAyB,sfAAsf;AAC/gB,6BAA6B,sfAAsf;AACnhB,iCAAiC,shBAAshB;AACvjB,oBAAoB,4TAA4T;AAChV,mBAAmB,4TAA4T;AAC/U,gCAAgC,q7BAAq7B;AACr9B,gCAAgC,m7BAAm7B;AACn9B,4BAA4B,ktCAAktC;AAC9uC,4BAA4B,2yBAA2yB;AACv0B,qCAAqC,suCAAsuC;AAC3wC,2CAA2C,wuCAAwuC;AACnxC,uCAAuC,63BAA63B;AACp6B,2CAA2C,k1BAAk1B;AAC73B,6CAA6C,s4BAAs4B;AACn7B,6CAA6C,42BAA42B;AACz5B,sCAAsC,07BAA07B;AACh+B,sCAAsC,g6BAAg6B;AACt8B,wBAAwB,4yBAA4yB;AACp0B,6BAA6B,4wBAA4wB;AACzyB,iCAAiC,4yBAA4yB;AAC70B,oCAAoC,09BAA09B;AAC9/B,oCAAoC,y/BAAy/B;AAC7hC,oCAAoC,09BAA09B;AAC9/B,iDAAiD,kxBAAkxB;AACn0B,kCAAkC,s1BAAs1B;AACx3B,uCAAuC,wmCAAwmC;AAC/oC,wDAAwD,2uBAA2uB;AACnyB,+BAA+B,qwBAAqwB;AACpyB,oCAAoC,qtBAAqtB;AACzvB,mCAAmC,itBAAitB;AACpvB,yCAAyC,+yBAA+yB;AACx1B,2CAA2C,m2BAAm2B;AAC94B,2CAA2C,m2BAAm2B;AAC94B,2CAA2C,y0BAAy0B;AACp3B,mCAAmC,8rCAA8rC;AACjuC,kDAAkD,4vBAA4vB;AAC9yB,4CAA4C,+rCAA+rC;AAC3uC,kDAAkD,+rCAA+rC;AACjvC,6BAA6B,u1BAAu1B;AACp3B,2CAA2C,s1BAAs1B;AACj4B,iCAAiC,wSAAwS;AACzU,0CAA0C,wSAAwS;AAClV,mCAAmC,2VAA2V;AAC9X,4CAA4C,gUAAgU;AAC5W,sCAAsC,2VAA2V;AACjY,+CAA+C,2VAA2V;AAC1Y,4CAA4C,8jBAA8jB;AAC1mB,+BAA+B,8JAA8J,iGAAiG,saAAsa;AACpsB,wCAAwC,8JAA8J,iGAAiG,saAAsa;AAC7sB,iCAAiC,6JAA6J,iGAAiG,oaAAoa;AACnsB,0CAA0C,6JAA6J,iGAAiG,oaAAoa;AAC5sB,gCAAgC,0SAA0S;AAC1U,yCAAyC,0SAA0S;AACnV,kCAAkC,0SAA0S;AAC5U,2CAA2C,0SAA0S;AACrV,+BAA+B,ySAAyS;AACxU,wCAAwC,ySAAyS;AACjV,gDAAgD,6RAA6R;AAC7U,0DAA0D,wZAAwZ;AACld,2DAA2D,wZAAwZ;AACnd,8DAA8D,0ZAA0Z;AACxd,6DAA6D,0ZAA0Z;AACvd,+CAA+C,6RAA6R;AAC5U,8CAA8C,6RAA6R;AAC3U,yDAAyD,qXAAqX;AAC9a,sCAAsC,kPAAkP;AACxR,wCAAwC,kPAAkP;AAC1R,oCAAoC,kPAAkP;AACtR,oCAAoC,kPAAkP;AACtR,qCAAqC,sPAAsP;AAC3R,wCAAwC,iPAAiP;AACzR,oCAAoC,yQAAyQ;AAC7S,oCAAoC,kNAAkN;AACtP,qCAAqC,kNAAkN;AACvP,2BAA2B,kNAAkN;AAC7O,gCAAgC,kNAAkN;AAClP,iCAAiC,kNAAkN;AACnP,mCAAmC,oPAAoP;AACvR,kCAAkC,oPAAoP;AACtR,gCAAgC,oPAAoP;AACpR,gCAAgC,oPAAoP;AACpR,qCAAqC,uKAAuK;AAC5M,yCAAyC,uKAAuK;AAChN,yCAAyC,uKAAuK;AAChN,8CAA8C,uKAAuK;AACrN,0BAA0B,2SAA2S;AACrU,4BAA4B,4QAA4Q;AACxS,0BAA0B,2SAA2S;AACrU,uCAAuC,2SAA2S;AAClV;AACA,+BAA+B,2jBAA2jB;AAC1lB,sCAAsC,4SAA4S;AAClV,2BAA2B,6TAA6T;AACxV,wCAAwC,6TAA6T;AACrW,4CAA4C,6TAA6T;AACzW,+BAA+B,6TAA6T;AAC5V,+BAA+B,6TAA6T;AAC5V,mCAAmC,8SAA8S;AACjV,gDAAgD,+RAA+R;AAC/U,uBAAuB,wQAAwQ;AAC/R,2BAA2B,wQAAwQ;AACnS,uBAAuB,8QAA8Q;AACrS,2BAA2B,8QAA8Q;AACzS,kCAAkC,8QAA8Q;AAChT,6CAA6C,8QAA8Q;AAC3T,mCAAmC,ivBAAivB;AACpxB,mCAAmC,ivBAAivB;AACpxB,+BAA+B,smBAAsmB;AACroB,sCAAsC,moBAAmoB;AACzqB,kCAAkC,qnBAAqnB;AACvpB,2CAA2C,qnBAAqnB;AAChqB,8BAA8B,omBAAomB,uHAAuH;AACzvB,8BAA8B,omBAAomB,uHAAuH;AACzvB,wCAAwC,wlBAAwlB;AAChoB,2CAA2C,olBAAolB;AAC/nB,yBAAyB,+ZAA+Z;AACxb,6BAA6B,idAAid;AAC9e,iCAAiC,8gBAA8gB;AAC/iB,iCAAiC,8gBAA8gB;AAC/iB,sCAAsC,idAAid;AACvf,sCAAsC,icAAic;AACve,oCAAoC,idAAid;AACrf,gCAAgC,qdAAqd;AACrf,oCAAoC,+TAA+T;AACnW,mCAAmC,+TAA+T;AAClW,yBAAyB,oOAAoO;AAC7P,iBAAiB,sOAAsO;AACvP,yBAAyB,sOAAsO;AAC/P,2BAA2B,gSAAgS;AAC3T,qBAAqB,qMAAqM;AAC1N,sBAAsB,sOAAsO;AAC5P,8BAA8B,sOAAsO;AACpQ,uBAAuB,4KAA4K;AACnM;AACA,mBAAmB,sNAAsN;AACzO,2BAA2B,sNAAsN;AACjP,gCAAgC,sNAAsN;AACtP,2BAA2B,sNAAsN;AACjP,gCAAgC,sNAAsN;AACtP,gCAAgC,+IAA+I;AAC/K,+BAA+B,mLAAmL;AAClN,0BAA0B,+IAA+I;AACzK,gCAAgC,+IAA+I;AAC/K,+BAA+B,6IAA6I;AAC5K,0BAA0B,qPAAqP,wGAAwG;AACvX,kCAAkC,mMAAmM;AACrO,uCAAuC,mMAAmM;AAC1O,kCAAkC,sMAAsM;AACxO,uCAAuC,sMAAsM;AAC7O,iCAAiC,oMAAoM;AACrO,sCAAsC,oMAAoM;AAC1O,kCAAkC,sMAAsM;AACxO,2CAA2C,sMAAsM;AACjP,iCAAiC,oMAAoM;AACrO,0CAA0C,oMAAoM;AAC9O,2CAA2C,oMAAoM;AAC/O,oDAAoD,oMAAoM;AACxP,sDAAsD,mMAAmM;AACzP,uCAAuC,mWAAmW;AAC1Y,yCAAyC,oOAAoO;AAC7Q,0CAA0C,mOAAmO;AAC7Q,mDAAmD,oJAAoJ;AACvM,wCAAwC,uRAAuR;AAC/T,8CAA8C,2gBAA2gB;AACzjB,mDAAmD,sJAAsJ;AACzM,wCAAwC,qJAAqJ;AAC7L,2CAA2C,oJAAoJ;AAC/L,2CAA2C,qOAAqO;AAChR,6CAA6C,iLAAiL;AAC9N,oDAAoD,8RAA8R;AAClV,sDAAsD,sQAAsQ;AAC5T,8CAA8C,uVAAuV;AACrY,mDAAmD,uTAAuT;AAC1W,8CAA8C,4YAA4Y;AAC1b,mDAAmD,4WAA4W;AAC/Z,4CAA4C,oOAAoO;AAChR,0CAA0C,oJAAoJ;AAC9L,gDAAgD,mJAAmJ;AACnM,6DAA6D,oJAAoJ;AACjN,2CAA2C,yOAAyO;AACpR,0CAA0C,mJAAmJ;AAC7L,sDAAsD,6IAA6I;AACnM,0DAA0D,wJAAwJ;AAClN,wDAAwD,mJAAmJ;AAC3M,kDAAkD,qJAAqJ;AACvM,4BAA4B,2ZAA2Z;AACvb,iCAAiC,oSAAoS;AACrU,4CAA4C,oSAAoS;AAChV,oCAAoC,oSAAoS;AACxU,+CAA+C,oSAAoS;AACnV,iCAAiC,6TAA6T;AAC9V,sCAAsC,6TAA6T;AACnW,gCAAgC,kSAAkS;AAClU,2CAA2C,kSAAkS;AAC7U,8CAA8C,sOAAsO;AACpR,uCAAuC,oJAAoJ;AAC3L,2CAA2C,oJAAoJ;AAC/L,+BAA+B,mJAAmJ;AAClL,8CAA8C,+KAA+K;AAC7N,qCAAqC,iLAAiL;AACtN,0CAA0C,6RAA6R;AACvU,2CAA2C,oJAAoJ;AAC/L,+CAA+C,oJAAoJ;AACnM,8CAA8C,mJAAmJ;AACjM,8CAA8C,qJAAqJ;AACnM,oDAAoD,mJAAmJ;AACvM,sDAAsD,mJAAmJ;AACzM,gCAAgC,wJAAwJ;AACxL,yCAAyC,yJAAyJ;AAClM,iDAAiD,2JAA2J;AAC5M,2CAA2C,yJAAyJ;AACpM,4CAA4C,yJAAyJ;AACrM,gDAAgD,qJAAqJ;AACrM,qDAAqD,6IAA6I;AAClM,mDAAmD,yMAAyM;AAC5P,gBAAgB,4KAA4K;AAC5L,0BAA0B,iMAAiM;AAC3N,2BAA2B,iMAAiM;AAC5N,iBAAiB,iMAAiM;AAClN,sBAAsB,iMAAiM;AACvN,uBAAuB,iMAAiM;AACxN,uBAAuB,iMAAiM;AACxN,sBAAsB,iMAAiM;AACvN,cAAc,0KAA0K;AACxL,gBAAgB,0KAA0K;AAC1L;AACA;AACA,qBAAqB,iIAAiI;AACtJ,6BAA6B,+HAA+H;AAC5J,yBAAyB,mIAAmI;AAC5J,iCAAiC,iIAAiI;AAClK,wBAAwB,qIAAqI;AAC7J,gCAAgC,mIAAmI;AACnK,sBAAsB,2KAA2K;AACjM,wBAAwB,2KAA2K;AACnM,gCAAgC,oMAAoM;AACpO,iCAAiC,0KAA0K;AAC3M,gCAAgC,0KAA0K;AAC1M,0BAA0B,+RAA+R;AACzT,iCAAiC,qKAAqK;AACtM,oCAAoC,uKAAuK;AAC3M,sCAAsC,wKAAwK;AAC9M,kCAAkC,0KAA0K;AAC5M,oCAAoC,0KAA0K;AAC9M,mCAAmC,iZAAiZ,wGAAwG;AAC5hB,wCAAwC,kMAAkM;AAC1O,0CAA0C,kMAAkM;AAC5O,uCAAuC,iOAAiO;AACxQ,uCAAuC,iOAAiO;AACxQ,uCAAuC,gOAAgO;AACvQ,4DAA4D,kMAAkM;AAC9P,4DAA4D,kMAAkM;AAC9P,4DAA4D,mMAAmM;AAC/P,0DAA0D,kMAAkM;AAC5P,0DAA0D,kMAAkM;AAC5P,0DAA0D,kMAAkM;AAC5P,yDAAyD,iOAAiO;AAC1R,yDAAyD,iOAAiO;AAC1R,yDAAyD,oOAAoO;AAC7R,8BAA8B,yQAAyQ;AACvS,iCAAiC,yQAAyQ;AAC1S,iCAAiC,0QAA0Q;AAC3S,6BAA6B,uTAAuT;AACpV,gCAAgC,uTAAuT;AACvV,gCAAgC,yTAAyT;AACzV,4BAA4B,qTAAqT;AACjV,+BAA+B,qTAAqT;AACpV,4DAA4D,4GAA4G;AACxK,+BAA+B,0WAA0W;AACzY,mCAAmC,uTAAuT;AAC1V,+CAA+C,2SAA2S;AAC1V,gEAAgE,+RAA+R,6EAA6E;AAC5a,iDAAiD,2SAA2S;AAC5V,6CAA6C,8JAA8J,iGAAiG,4ZAA4Z;AACxsB,+CAA+C,6JAA6J,iGAAiG,0ZAA0Z;AACvsB,iDAAiD,gfAAgf;AACjiB,iDAAiD,+cAA+c;AAChgB,8CAA8C,6SAA6S;AAC3V,gDAAgD,4ZAA4Z;AAC5c,6CAA6C,oRAAoR;AACjU,kDAAkD,2SAA2S;AAC7V,oDAAoD,2SAA2S;AAC/V,oDAAoD,+cAA+c;AACngB,oDAAoD,gfAAgf;AACpiB,gDAAgD,8JAA8J,iGAAiG,4ZAA4Z;AAC3sB,kDAAkD,6JAA6J,iGAAiG,0ZAA0Z;AAC1sB,iDAAiD,6SAA6S;AAC9V,mDAAmD,4ZAA4Z;AAC/c,gDAAgD,oRAAoR;AACpU,kDAAkD,2SAA2S;AAC7V,oDAAoD,2SAA2S;AAC/V,oDAAoD,mYAAmY;AACvb,oDAAoD,2ZAA2Z;AAC/c,iDAAiD,6SAA6S;AAC9V,gDAAgD,8JAA8J,iGAAiG,4ZAA4Z;AAC3sB,kDAAkD,6JAA6J,iGAAiG,0ZAA0Z;AAC1sB,mDAAmD,qVAAqV;AACxY,gDAAgD,oRAAoR;AACpU,2BAA2B,uKAAuK;AAClM,6CAA6C,iMAAiM;AAC9O,6CAA6C,iMAAiM;AAC9O,kDAAkD,iMAAiM;AACnP,qEAAqE,4KAA4K;AACjP,qEAAqE,8KAA8K;AACnP,gDAAgD,uKAAuK;AACvN,mEAAmE,4KAA4K;AAC/O,mEAAmE,8KAA8K;AACjP,gEAAgE,4KAA4K;AAC5O,gEAAgE,4KAA4K;AAC5O,gEAAgE,4KAA4K;AAC5O,gEAAgE,4KAA4K;AAC5O,2BAA2B,iMAAiM;AAC5N,6CAA6C,iMAAiM;AAC9O,6CAA6C,iMAAiM;AAC9O,kDAAkD,iMAAiM;AACnP,qEAAqE,sMAAsM;AAC3Q,qEAAqE,wMAAwM;AAC7Q,gDAAgD,iMAAiM;AACjP,mEAAmE,sMAAsM;AACzQ,mEAAmE,wMAAwM;AAC3Q,gEAAgE,sMAAsM;AACtQ,gEAAgE,sMAAsM;AACtQ,gEAAgE,sMAAsM;AACtQ,gEAAgE,sMAAsM;AACtQ,6BAA6B,iMAAiM;AAC9N,+CAA+C,iMAAiM;AAChP,+CAA+C,iMAAiM;AAChP,oDAAoD,iMAAiM;AACrP,uEAAuE,sMAAsM;AAC7Q,uEAAuE,wMAAwM;AAC/Q,kDAAkD,iMAAiM;AACnP,qEAAqE,sMAAsM;AAC3Q,qEAAqE,wMAAwM;AAC7Q,kEAAkE,sMAAsM;AACxQ,kEAAkE,sMAAsM;AACxQ,kEAAkE,sMAAsM;AACxQ,kEAAkE,sMAAsM;AACxQ,mCAAmC,iMAAiM;AACpO,qDAAqD,iMAAiM;AACtP,wEAAwE,oMAAoM;AAC5Q,wEAAwE,sMAAsM;AAC9Q,wEAAwE,oMAAoM;AAC5Q,wEAAwE,sMAAsM;AAC9Q,qDAAqD,iMAAiM;AACtP,0DAA0D,oMAAoM;AAC9P,6EAA6E,wMAAwM;AACrR,6EAA6E,wMAAwM;AACrR,wDAAwD,oMAAoM;AAC5P,2EAA2E,wMAAwM;AACnR,2EAA2E,wMAAwM;AACnR,4BAA4B,+RAA+R;AAC3T,+BAA+B,kMAAkM;AACjO,4DAA4D,qMAAqM;AACjQ,4DAA4D,2MAA2M;AACvQ,qCAAqC,iMAAiM;AACtO,kEAAkE,yMAAyM;AAC3Q,kEAAkE,2MAA2M;AAC7Q,kCAAkC,mMAAmM;AACrO,6BAA6B,mMAAmM;AAChO,+BAA+B,kLAAkL;AACjN,oCAAoC,kLAAkL;AACtN,2BAA2B,qQAAqQ;AAChS,uCAAuC,4OAA4O;AACnR,+BAA+B,wKAAwK;AACvM,+BAA+B,2KAA2K;AAC1M,oCAAoC,uKAAuK;AAC3M,sDAAsD,uKAAuK;AAC7N,sDAAsD,uKAAuK;AAC7N,uDAAuD,yKAAyK;AAChO,yDAAyD,yKAAyK;AAClO,sDAAsD,yKAAyK;AAC/N,sDAAsD,yKAAyK;AAC/N,sDAAsD,yKAAyK;AAC/N,qCAAqC,0KAA0K;AAC/M,uDAAuD,0KAA0K;AACjO,uDAAuD,0KAA0K;AACjO,wDAAwD,0KAA0K;AAClO,0DAA0D,2KAA2K;AACrO,uDAAuD,2KAA2K;AAClO,uDAAuD,2KAA2K;AAClO,uDAAuD,2KAA2K;AAClO,sCAAsC,oOAAoO;AAC1Q,yCAAyC,oOAAoO;AAC7Q,uCAAuC,oOAAoO;AAC3Q,0CAA0C,oOAAoO;AAC9Q,wCAAwC,qOAAqO;AAC7Q,2CAA2C,qOAAqO;AAChR,sCAAsC,kOAAkO;AACxQ,yCAAyC,kOAAkO;AAC3Q,yCAAyC,oOAAoO;AAC7Q,sCAAsC,oOAAoO;AAC1Q,yCAAyC,oOAAoO;AAC7Q,yCAAyC,oOAAoO;AAC7Q,uCAAuC,yPAAyP;AAChS,0CAA0C,yPAAyP;AACnS,uCAAuC,uPAAuP;AAC9R,0CAA0C,uPAAuP;AACjS,0CAA0C,4OAA4O;AACtR,8CAA8C,gZAAgZ;AAC9b,iDAAiD,gZAAgZ;AACjc,2CAA2C,+YAA+Y;AAC1b,8CAA8C,+YAA+Y;AAC7b,2DAA2D,2HAA2H;AACtL,4DAA4D,2HAA2H;AACvL,2DAA2D,2HAA2H;AACtL,4DAA4D,2HAA2H;AACvL,6DAA6D,0HAA0H;AACvL,8DAA8D,0HAA0H;AACxL,gCAAgC,0HAA0H;AAC1J,kCAAkC,0HAA0H;AAC5J,wCAAwC,0HAA0H;AAClK,wCAAwC,0HAA0H;AAClK,yCAAyC,0HAA0H;AACnK,yCAAyC,0HAA0H;AACnK,gDAAgD,yKAAyK;AACzN,kDAAkD,mKAAmK;AACrN,iDAAiD,yKAAyK;AAC1N,mDAAmD,mKAAmK;AACtN,iDAAiD,yKAAyK;AAC1N,qDAAqD,mKAAmK;AACxN,4BAA4B,wGAAwG;AACpI,2BAA2B,wGAAwG;AACnI,4BAA4B,yHAAyH;AACrJ,6BAA6B,wGAAwG;AACrI,6BAA6B,wGAAwG;AACrI,8BAA8B,0GAA0G;AACxI,wCAAwC,0GAA0G;AAClJ,0CAA0C,2GAA2G;AACrJ,+DAA+D,yOAAyO;AACxS,gEAAgE,yOAAyO;AACzS,iEAAiE,2MAA2M;AAC5Q,2DAA2D,yOAAyO;AACpS,gEAAgE,iOAAiO;AACjS,wDAAwD,uOAAuO;AAC/R,sDAAsD,8KAA8K;AACpO,2DAA2D,gJAAgJ;AAC3M,qEAAqE,gJAAgJ;AACrN,6DAA6D,gJAAgJ;AAC7M,0DAA0D,gJAAgJ;AAC1M,kDAAkD,gJAAgJ;AAClM,mDAAmD,gJAAgJ;AACnM,2CAA2C,gJAAgJ;AAC3L,6DAA6D,gJAAgJ;AAC7M,wBAAwB,sKAAsK;AAC9L,wBAAwB,iMAAiM;AACzN,yCAAyC,iMAAiM;AAC1O,qCAAqC,qMAAqM;AAC1O,8CAA8C,iMAAiM;AAC/O,0CAA0C,qMAAqM;AAC/O,mCAAmC,iMAAiM;AACpO,qBAAqB,gKAAgK;AACrL,wBAAwB,gKAAgK;AACxL,yBAAyB,gKAAgK;AACzL,yBAAyB,gKAAgK;AACzL,gCAAgC,sKAAsK;AACtM,qBAAqB,gKAAgK;AACrL,wBAAwB,gKAAgK;AACxL,yBAAyB,gKAAgK;AACzL,uBAAuB,gMAAgM;AACvN,0CAA0C,iMAAiM;AAC3O,sBAAsB,qMAAqM;AAC3N,uCAAuC,+LAA+L;AACtO,uCAAuC,kMAAkM;AACzO,yCAAyC,kMAAkM;AAC3O,0CAA0C,kMAAkM;AAC5O,wBAAwB,sKAAsK;AAC9L,wBAAwB,sKAAsK;AAC9L,qBAAqB,sKAAsK;AAC3L,gDAAgD,mMAAmM;AACnP,wCAAwC,qMAAqM;AAC7O,oDAAoD,sMAAsM;AAC1P,gDAAgD,mMAAmM;AACnP,gEAAgE,sMAAsM;AACtQ,qDAAqD,mMAAmM;AACxP,mCAAmC,iLAAiL;AACpN,8CAA8C,oMAAoM;AAClP,sDAAsD,sMAAsM;AAC5P,yCAAyC,mMAAmM;AAC5O,mCAAmC,mMAAmM;AACtO,kCAAkC,gLAAgL;AAClN,uDAAuD,mMAAmM;AAC1P,gDAAgD,qMAAqM;AACrP,oCAAoC,oMAAoM;AACxO,+CAA+C,qMAAqM;AACpP,qDAAqD,mMAAmM;AACxP,sDAAsD,qMAAqM;AAC3P,yDAAyD,6QAA6Q;AACtU,mCAAmC,8KAA8K;AACjN,uCAAuC,qMAAqM;AAC5O,yCAAyC,+KAA+K;AACxN,yCAAyC,8KAA8K;AACvN,yCAAyC,gLAAgL;AACzN,wCAAwC,gLAAgL;AACxN,mDAAmD,gNAAgN;AACnQ,oDAAoD,gNAAgN;AACpQ,kDAAkD,gNAAgN;AAClQ,kDAAkD,gNAAgN;AAClQ,oDAAoD,gNAAgN;AACpQ,+BAA+B,2KAA2K;AAC1M,gCAAgC,2KAA2K;AAC3M,iCAAiC,sMAAsM;AACvO,kCAAkC,sMAAsM;AACxO,mCAAmC,2KAA2K;AAC9M,sCAAsC,2KAA2K;AACjN,wCAAwC,2KAA2K;AACnN,mCAAmC,8KAA8K;AACjN,qCAAqC,sMAAsM;AAC3O,oCAAoC,8KAA8K;AAClN,sCAAsC,sMAAsM;AAC5O,wBAAwB,oLAAoL,kGAAkG,2BAA2B;AACzU,4BAA4B,yMAAyM,kGAAkG,2BAA2B;AAClW,kCAAkC,oLAAoL,kGAAkG,mDAAmD;AAC3W,sCAAsC,oLAAoL,kGAAkG,mDAAmD;AAC/W,sCAAsC,2NAA2N,iGAAiG,mDAAmD;AACrZ,qEAAqE,8SAA8S;AACnX,qEAAqE,8SAA8S;AACnX,qEAAqE,8SAA8S;AACnX,6EAA6E,mUAAmU;AAChZ,6EAA6E,oSAAoS;AACjX,8DAA8D,2SAA2S;AACzW,wEAAwE,gTAAgT;AACxX,iEAAiE,8SAA8S;AAC/W,yEAAyE,2SAA2S;AACpX,uDAAuD,8SAA8S;AACrW,yEAAyE,gTAAgT;AACzX,0DAA0D,6QAA6Q;AACvU,0DAA0D,+QAA+Q;AACzU,gEAAgE,kRAAkR;AAClV,+DAA+D,4QAA4Q;AAC3U,uEAAuE,8SAA8S;AACrX,6EAA6E,oRAAoR;AACjW,0EAA0E,mRAAmR;AAC7V,mDAAmD,8MAA8M;AACjQ,iDAAiD,8MAA8M;AAC/P,2CAA2C,6MAA6M;AACxP,uCAAuC,6MAA6M;AACpP,sCAAsC,4MAA4M;AAClP,6BAA6B,2FAA2F;AACxH,gCAAgC,2FAA2F;AAC3H,8BAA8B,2FAA2F;AACzH,kCAAkC,2FAA2F;AAC7H,gCAAgC,6FAA6F;AAC7H,4BAA4B,qFAAqF;AACjH,yCAAyC,yGAAyG;AAClJ,2CAA2C,0GAA0G;AACrJ,mDAAmD,uUAAuU;AAC1X,qDAAqD,yUAAyU;AAC9X,sDAAsD,wUAAwU;AAC9X,6CAA6C,6KAA6K;AAC1N,mCAAmC,qRAAqR;AACxT,8CAA8C,0KAA0K;AACxN,+CAA+C,0KAA0K;AACzN,+CAA+C,wKAAwK;AACvN,oDAAoD,wKAAwK;AAC5N,oDAAoD,oSAAoS;AACxV,oDAAoD,sSAAsS;AAC1V,qDAAqD,qSAAqS;AAC1V,gDAAgD,gLAAgL;AAChO,gDAAgD,gLAAgL;AAChO,uDAAuD,gLAAgL;AACvO,yDAAyD,gLAAgL;AACzO,wBAAwB,+IAA+I;AACvK,6BAA6B,+IAA+I;AAC5K,6BAA6B,gJAAgJ;AAC7K,+BAA+B,gJAAgJ;AAC/K,sCAAsC,6IAA6I;AACnL,2BAA2B,gJAAgJ;AAC3K,4BAA4B,gJAAgJ;AAC5K,uBAAuB,6IAA6I;AACpK,6BAA6B,gJAAgJ;AAC7K,uBAAuB,+IAA+I;AACtK,4BAA4B,+IAA+I;AAC3K,4BAA4B,gJAAgJ;AAC5K,kCAAkC,gJAAgJ;AAClL,uBAAuB,yNAAyN;AAChP,4BAA4B,qNAAqN;AACjP,+CAA+C,iVAAiV,yLAAyL,mHAAmH;AAC5qB,0DAA0D,wVAAwV,4LAA4L,4BAA4B;AAC1mB,yDAAyD,6VAA6V,4LAA4L,4BAA4B;AAC9mB,yDAAyD,6VAA6V,4LAA4L,4BAA4B;AAC9mB,8CAA8C,iVAAiV,wHAAwH,4BAA4B;AACnhB,2CAA2C,4VAA4V,4LAA4L,4BAA4B;AAC/lB,uDAAuD,6VAA6V,4LAA4L,4BAA4B;AAC5mB,8CAA8C,mVAAmV,4LAA4L,4BAA4B;AACzlB,mDAAmD,uVAAuV,4LAA4L,4BAA4B;AAClmB,8CAA8C,wVAAwV,4LAA4L,4BAA4B;AAC9lB,6CAA6C,wUAAwU,4LAA4L,4BAA4B;AAC7kB,0CAA0C,4UAA4U,8LAA8L;AACpjB,0CAA0C,8UAA8U,8LAA8L;AACtjB,4CAA4C,uTAAuT;AACnW,8CAA8C,uTAAuT;AACrW,4CAA4C,gOAAgO;AAC5Q,4CAA4C,8NAA8N;AAC1Q,oDAAoD,6VAA6V,uGAAuG;AACxf,gDAAgD,gUAAgU,uGAAuG;AACvd,6CAA6C,2TAA2T;AACxW,uCAAuC,gOAAgO;AACvQ,2BAA2B,8SAA8S;AACzU,yBAAyB,gOAAgO;AACzP,yCAAyC,uPAAuP;AAChS,+CAA+C,oOAAoO;AACnR,6BAA6B,gOAAgO;AAC7P,kCAAkC,kTAAkT;AACpV,uBAAuB,yHAAyH;AAChJ,uBAAuB,wHAAwH;AAC/I,0CAA0C,gNAAgN;AAC1P,6BAA6B,0IAA0I;AACvK,kCAAkC,gHAAgH;AAClJ,mCAAmC,2IAA2I;AAC9K,+BAA+B,gHAAgH;AAC/I,gCAAgC,kHAAkH;AAClJ,4BAA4B,8GAA8G;AAC1I,2BAA2B,gHAAgH;AAC3I,gCAAgC,kHAAkH;AAClJ,gCAAgC,kHAAkH;AAClJ,iCAAiC,kHAAkH;AACnJ,8BAA8B,gHAAgH;AAC9I,iCAAiC,gHAAgH;AACjJ,2BAA2B,8GAA8G;AACzI,4BAA4B,8GAA8G;AAC1I,6BAA6B,kHAAkH;AAC/I,8BAA8B,kHAAkH;AAChJ,8BAA8B,kHAAkH;AAChJ,yCAAyC,8GAA8G;AACvJ,+BAA+B,kHAAkH;AACjJ,0CAA0C,8GAA8G;AACxJ,6BAA6B,kHAAkH;AAC/I,6BAA6B,kHAAkH;AAC/I,4BAA4B,gHAAgH;AAC5I,0BAA0B,8GAA8G;AACxI,wDAAwD,4LAA4L;AACpP,6CAA6C,2LAA2L;AACxO,6CAA6C,2LAA2L;AACxO,8CAA8C,2LAA2L;AACzO,2BAA2B,4LAA4L;AACvN,wDAAwD,2MAA2M,2FAA2F;AAC9V,uDAAuD,yMAAyM,2FAA2F;AAC3V,wDAAwD,uMAAuM,2FAA2F;AAC1V,sDAAsD,uMAAuM,2FAA2F;AACxV,uDAAuD,uMAAuM,2FAA2F;AACzV,uDAAuD,yMAAyM,2FAA2F;AAC3V,oDAAoD,uMAAuM,2FAA2F;AACtV,+CAA+C,uMAAuM,2FAA2F;AACjV,gDAAgD,uMAAuM,2FAA2F;AAClV,+CAA+C,wPAAwP;AACvS,uDAAuD,sPAAsP;AAC7S,gDAAgD,uHAAuH;AACvK,oDAAoD,uHAAuH;AAC3K,uBAAuB,6NAA6N,kGAAkG;AACtV,+BAA+B,6NAA6N,kGAAkG;AAC9V,+BAA+B,6NAA6N,iHAAiH;AAC7W,uBAAuB,6NAA6N,kGAAkG;AACtV,+BAA+B,6NAA6N,kGAAkG;AAC9V,+BAA+B,6NAA6N,kGAAkG;AAC9V,iCAAiC,6NAA6N,kGAAkG;AAChW,iCAAiC,6NAA6N,kGAAkG;AAChW,+BAA+B,6NAA6N,kGAAkG;AAC9V,wCAAwC,6NAA6N,kGAAkG;AACvW,6BAA6B,6NAA6N,kGAAkG;AAC5V,iCAAiC,6NAA6N,kGAAkG;AAChW,kCAAkC,6NAA6N,kGAAkG;AACjW,2BAA2B,6NAA6N,kGAAkG;AAC1V,qBAAqB,6NAA6N,kGAAkG;AACpV,6BAA6B,6NAA6N,kGAAkG;AAC5V,+BAA+B,6NAA6N,kGAAkG;AAC9V,yBAAyB,8NAA8N,mGAAmG;AAC1V,iCAAiC,8NAA8N,mGAAmG;AAClW,iCAAiC,8NAA8N,mGAAmG;AAClW,mCAAmC,8NAA8N,mGAAmG;AACpW,iCAAiC,8NAA8N,mGAAmG;AAClW,qBAAqB,8NAA8N,mGAAmG;AACtV,6BAA6B,8NAA8N,mGAAmG;AAC9V,6BAA6B,8NAA8N,mGAAmG;AAC9V,+BAA+B,8NAA8N,mGAAmG;AAChW,+BAA+B,8NAA8N,mGAAmG;AAChW,6BAA6B,8NAA8N,mGAAmG;AAC9V,sCAAsC,8NAA8N,mGAAmG;AACvW,2BAA2B,8NAA8N,mGAAmG;AAC5V,wBAAwB,0NAA0N,qGAAqG;AACvV,6BAA6B,0NAA0N,qGAAqG;AAC5V,6BAA6B,0NAA0N,qGAAqG;AAC5V,8BAA8B,0NAA0N,qGAAqG;AAC7V,+BAA+B,0NAA0N,qGAAqG;AAC9V,8BAA8B,0NAA0N;AACxP;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA,oEAAoE,EAAE,kDAAkD,EAAE,iDAAiD,EAAE,GAAG,EAAE,4CAA4C,EAAE,GAAG,EAAE;AACrO;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,UAAU,GAAG,QAAQ,qBAAqB,IAAI,cAAc;AACrE;AACA;AACA,gBAAgB,EAAE,GAAG,EAAE;AACvB;AACA;AACA;AACA;AACA;AACA,gBAAgB,EAAE,GAAG,EAAE;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,MAAM;AACN,wDAAwD,GAAG;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,EAAE,kBAAkB,EAAE;AAClD;AACA,8DAA8D,EAAE;AAChE;AACA,MAAM;AACN,6CAA6C,GAAG;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wBAAwB,iBAAiB,WAAW;AACrD;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA,8CAA8C,UAAU,EAAE,aAAa;AACvE;AACA;AACA,gJAAgJ,aAAa,IAAI,gBAAgB;AACjL;AACA;AACA;AACA;AACA,WAAW;AACX,UAAU,oBAAoB;AAC9B;AACA,0BAA0B,YAAY;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD;AACxD;AACA;AACA;AACA,sBAAsB,EAAE,sBAAsB,EAAE;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,EAAE,KAAK,EAAE;AACvB;AACA;AACA,gCAAgC,OAAO;AACvC;AACA;AACA,gCAAgC,OAAO;AACvC;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA,+eAA+e,ufAAuf,cAAc;AACp/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,2BAA2B,2CAA2C,2BAA2B;AACnI,MAAM,0EAA0E,2BAA2B;AAC3G,4BAA4B,2BAA2B;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE,YAAY;AACnF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,qBAAqB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,gCAAgC;AAChD,6FAA6F,cAAc;AAC3G;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,4CAA4C;AACpF;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA,0DAA0D;AAC1D,YAAY;AACZ,oDAAoD;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,cAAc,oBAAoB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE;AACjE;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,aAAa;AACb;AACA;AACA,gBAAgB;AAChB,mBAAmB,cAAc;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA,sDAAsD,QAAQ;AAC9D,iIAAiI;AACjI,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,4BAA4B,mDAAmD;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mEAAmE;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8DAA8D;AAC9D;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wEAAwE,wCAAwC;AAChH;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sGAAsG;AACtG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,iCAAiC,aAAa;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,uCAAuC;AAC9F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,8DAA8D;AAC9D;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,oBAAoB,0BAA0B;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,QAAQ,uBAAuB,YAAY;AACnF;AACA;AACA,cAAc,eAAe,OAAO,YAAY;AAChD;AACA;AACA;AACA,wEAAwE,uBAAuB,iBAAiB,IAAI,iDAAiD,wBAAwB,iBAAiB,GAAG,mDAAmD,wSAAwS;AAC5iB;AACA;AACA;AACA,KAAK,IAAI,8DAA8D,yCAAyC,qBAAqB;AACrI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,uCAAuC;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,mBAAmB;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE,kFAAkF;AAClJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGE;AACF;;;;;;;;;;;;;;;;ACtkEuC;;AAEvC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,uCAAuC;AACvC,mCAAmC;AACnC;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,iEAAG,0BAA0B,QAAQ,MAAM,0BAA0B;AACxF;AACA,eAAe,iEAAG;AAClB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kEAAkE,MAAM,IAAI,oBAAoB;AAChG;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,mDAAmD,IAAI,KAAK;AACtF;AACA;AACA;AACA;AACA,2BAA2B,IAAI,IAAI,IAAI;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,GAAG;AAChD;;AAEA;AACA;AACA;AACA;AACA,sBAAsB,gEAAgE;AACtF,sBAAsB;AACtB;AACA,aAAa;AACb;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;;;;;;;;UCrJA;UACA;;UAEA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;;UAEA;UACA;;UAEA;UACA;UACA;;;;;WCtBA;WACA;WACA;WACA;WACA,yCAAyC,wCAAwC;WACjF;WACA;WACA;;;;;WCPA;;;;;WCAA;WACA;WACA;WACA,uDAAuD,iBAAiB;WACxE;WACA,gDAAgD,aAAa;WAC7D;;;;;;;;;;;;ACNuC;;;AAGvC;AACA;AACA;;AAEA,oBAAoB,gDAAQ;AAC5B;AACA;AACA,yDAAyD,MAAM,oCAAoC,MAAM;AACzG;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,C","sources":["webpack:///./node_modules/@themaximalist/llm.js/dist/index.mjs","webpack:///./private/js/ask_jenna.js","webpack:///webpack/bootstrap","webpack:///webpack/runtime/define property getters","webpack:///webpack/runtime/hasOwnProperty shorthand","webpack:///webpack/runtime/make namespace object","webpack:///./private/js/admin.ask_jenna.js"],"sourcesContent":["class X {\n  constructor() {\n    this.loggers = /* @__PURE__ */ new Map(), this.patterns = [], this.isNode = typeof process < \"u\" && process.env, this.colors = [\n      \"#e6194b\",\n      \"#3cb44b\",\n      \"#ffe119\",\n      \"#4363d8\",\n      \"#f58231\",\n      \"#911eb4\",\n      \"#46f0f0\",\n      \"#f032e6\",\n      \"#bcf60c\",\n      \"#fabebe\",\n      \"#008080\",\n      \"#e6beff\",\n      \"#9a6324\",\n      \"#fffac8\",\n      \"#800000\",\n      \"#aaffc3\",\n      \"#808000\",\n      \"#ffd8b1\",\n      \"#000075\",\n      \"#808080\"\n    ], this.updatePatterns();\n  }\n  updatePatterns() {\n    let t = \"\";\n    this.isNode ? t = typeof process < \"u\" && process.env.DEBUG || \"\" : (typeof localStorage < \"u\" && (t = localStorage.getItem(\"DEBUG\") || \"\"), typeof globalThis < \"u\" && globalThis.DEBUG && (t = globalThis.DEBUG)), this.patterns = t.split(\",\").map((e) => e.trim()).filter(Boolean);\n    for (const [e, o] of this.loggers)\n      o.enabled = this.isEnabled(e);\n  }\n  isEnabled(t) {\n    if (this.patterns.length === 0) return !1;\n    for (const e of this.patterns)\n      if (e.startsWith(\"-\")) {\n        const o = e.slice(1);\n        if (this.matchPattern(t, o))\n          return !1;\n      } else if (this.matchPattern(t, e))\n        return !0;\n    return !1;\n  }\n  matchPattern(t, e) {\n    if (e === \"*\" || e === t) return !0;\n    const o = e.replace(/\\*/g, \".*\").replace(/\\?/g, \".\").replace(/\\+/g, \"\\\\+\").replace(/\\[/g, \"\\\\[\").replace(/\\]/g, \"\\\\]\").replace(/\\(/g, \"\\\\(\").replace(/\\)/g, \"\\\\)\").replace(/\\{/g, \"\\\\{\").replace(/\\}/g, \"\\\\}\").replace(/\\^/g, \"\\\\^\").replace(/\\$/g, \"\\\\$\").replace(/\\|/g, \"\\\\|\");\n    return new RegExp(`^${o}$`).test(t);\n  }\n  getColor(t) {\n    let e = 0;\n    for (let o = 0; o < t.length; o++) {\n      const _ = t.charCodeAt(o);\n      e = (e << 5) - e + _, e = e & e;\n    }\n    return this.colors[Math.abs(e) % this.colors.length];\n  }\n  formatMessage(t, e, o, _) {\n    const s = Date.now(), r = this.loggers.get(t);\n    let u = t, n = \"\";\n    r.lastTime && (n = `+${s - r.lastTime}ms`), r.lastTime = s, this.isNode ? (u = `\\x1B[${this.getAnsiColor(r.color)}m${t}\\x1B[0m`, n && (u += ` \\x1B[90m${n}\\x1B[0m`)) : n && (u += ` ${n}`);\n    const c = e !== \"debug\" ? `[${e.toUpperCase()}]` : \"\";\n    return `${u}${c ? \" \" + c : \"\"} ${o}`;\n  }\n  getAnsiColor(t) {\n    return {\n      \"#e6194b\": \"31\",\n      // red\n      \"#3cb44b\": \"32\",\n      // green  \n      \"#ffe119\": \"33\",\n      // yellow\n      \"#4363d8\": \"34\",\n      // blue\n      \"#f58231\": \"35\",\n      // magenta\n      \"#911eb4\": \"36\"\n      // cyan\n    }[t] || \"37\";\n  }\n  log(t, e, o, ..._) {\n    const s = this.loggers.get(t);\n    if (!s || !s.enabled) return;\n    (typeof o == \"object\" || Array.isArray(o)) && (o = JSON.stringify(o));\n    for (let u = 0; u < _.length; u++)\n      (typeof _[u] == \"object\" || Array.isArray(_[u])) && (_[u] = JSON.stringify(_[u]));\n    const r = this.formatMessage(t, e, o, _);\n    if (this.isNode) {\n      const u = e === \"debug\" ? process.stderr : process.stdout;\n      u.write(r + \" \"), _.length > 0 && u.write(_.map(\n        (n) => typeof n == \"object\" ? JSON.stringify(n, null, 2) : String(n)\n      ).join(\" \")), u.write(`\n`);\n    } else {\n      const u = `color: ${s.color}; font-weight: bold;`;\n      e === \"warn\" ? console.warn(`%c${r}`, u, ..._) : e === \"error\" ? console.error(`%c${r}`, u, ..._) : console.log(`%c${r}`, u, ..._);\n    }\n  }\n  createLogger(t) {\n    this.loggers.has(t) || this.loggers.set(t, {\n      enabled: this.isEnabled(t),\n      color: this.getColor(t)\n    });\n    const e = this.loggers.get(t), o = (_, ...s) => {\n      this.log(t, \"debug\", _, ...s);\n    };\n    return o.debug = (_, ...s) => {\n      this.log(t, \"debug\", _, ...s);\n    }, o.warn = (_, ...s) => {\n      this.log(t, \"warn\", _, ...s);\n    }, o.error = (_, ...s) => {\n      this.log(t, \"error\", _, ...s);\n    }, o.namespace = t, Object.defineProperty(o, \"enabled\", {\n      get: () => e.enabled\n    }), o;\n  }\n  // Update patterns when environment changes\n  refresh() {\n    this.updatePatterns();\n  }\n}\nconst K = new X();\nfunction j(p) {\n  return K.createLogger(p);\n}\nj.refresh = () => K.refresh();\nconst Z = { max_tokens: \"LEGACY parameter. set to max_output_tokens if provider specifies it. IF not set to max_input_tokens, if provider specifies it.\", max_input_tokens: \"max input tokens, if the provider specifies it. if not default to max_tokens\", max_output_tokens: \"max output tokens, if the provider specifies it. if not default to max_tokens\", input_cost_per_token: 0, output_cost_per_token: 0, output_cost_per_reasoning_token: 0, litellm_provider: \"one of https://docs.litellm.ai/docs/providers\", mode: \"one of: chat, embedding, completion, image_generation, audio_transcription, audio_speech, image_generation, moderation, rerank\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_audio_input: !0, supports_audio_output: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_system_messages: !0, supports_reasoning: !0, supports_web_search: !0, search_context_cost_per_query: { search_context_size_low: 0, search_context_size_medium: 0, search_context_size_high: 0 }, supported_regions: [\"global\", \"us-west-2\", \"eu-west-1\", \"ap-southeast-1\", \"ap-northeast-1\"], deprecation_date: \"date when the model becomes deprecated in the format YYYY-MM-DD\" }, tt = { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, cache_read_input_token_cost: 75e-7, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 }, et = { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, cache_read_input_token_cost: 5e-7, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0, supported_endpoints: [\"/v1/responses\", \"/v1/chat/completions\", \"/v1/completions\", \"/v1/batch\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"] }, ot = { max_tokens: 2048, max_input_tokens: 2048, output_vector_size: 768, input_cost_per_character: 2e-7, input_cost_per_image: 1e-4, input_cost_per_video_per_second: 5e-4, input_cost_per_video_per_second_above_8s_interval: 1e-3, input_cost_per_video_per_second_above_15s_interval: 2e-3, input_cost_per_token: 8e-7, output_cost_per_token: 0, litellm_provider: \"vertex_ai-embedding-models\", mode: \"embedding\", supported_endpoints: [\"/v1/embeddings\"], supported_modalities: [\"text\", \"image\", \"video\"], source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\" }, _t = { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 1e-6, output_cost_per_token: 2e-6, litellm_provider: \"cohere\", mode: \"completion\" }, st = { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 5e-7, output_cost_per_token: 5e-7, litellm_provider: \"nlp_cloud\", mode: \"completion\" }, pt = { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 5e-7, output_cost_per_token: 5e-7, litellm_provider: \"nlp_cloud\", mode: \"chat\" }, Q = {\n  sample_spec: Z,\n  \"omni-moderation-latest\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 0, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"openai\", mode: \"moderation\" },\n  \"omni-moderation-latest-intents\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 0, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"openai\", mode: \"moderation\" },\n  \"omni-moderation-2024-09-26\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 0, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"openai\", mode: \"moderation\" },\n  \"gpt-4\": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 3e-5, output_cost_per_token: 6e-5, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4.1\": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, input_cost_per_token_batches: 1e-6, output_cost_per_token_batches: 4e-6, cache_read_input_token_cost: 5e-7, litellm_provider: \"openai\", mode: \"chat\", supported_endpoints: [\"/v1/chat/completions\", \"/v1/batch\", \"/v1/responses\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0 },\n  \"gpt-4.1-2025-04-14\": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, input_cost_per_token_batches: 1e-6, output_cost_per_token_batches: 4e-6, cache_read_input_token_cost: 5e-7, litellm_provider: \"openai\", mode: \"chat\", supported_endpoints: [\"/v1/chat/completions\", \"/v1/batch\", \"/v1/responses\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0 },\n  \"gpt-4.1-mini\": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 4e-7, output_cost_per_token: 16e-7, input_cost_per_token_batches: 2e-7, output_cost_per_token_batches: 8e-7, cache_read_input_token_cost: 1e-7, litellm_provider: \"openai\", mode: \"chat\", supported_endpoints: [\"/v1/chat/completions\", \"/v1/batch\", \"/v1/responses\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0 },\n  \"gpt-4.1-mini-2025-04-14\": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 4e-7, output_cost_per_token: 16e-7, input_cost_per_token_batches: 2e-7, output_cost_per_token_batches: 8e-7, cache_read_input_token_cost: 1e-7, litellm_provider: \"openai\", mode: \"chat\", supported_endpoints: [\"/v1/chat/completions\", \"/v1/batch\", \"/v1/responses\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0 },\n  \"gpt-4.1-nano\": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 1e-7, output_cost_per_token: 4e-7, input_cost_per_token_batches: 5e-8, output_cost_per_token_batches: 2e-7, cache_read_input_token_cost: 25e-9, litellm_provider: \"openai\", mode: \"chat\", supported_endpoints: [\"/v1/chat/completions\", \"/v1/batch\", \"/v1/responses\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0 },\n  \"gpt-4.1-nano-2025-04-14\": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 1e-7, output_cost_per_token: 4e-7, input_cost_per_token_batches: 5e-8, output_cost_per_token_batches: 2e-7, cache_read_input_token_cost: 25e-9, litellm_provider: \"openai\", mode: \"chat\", supported_endpoints: [\"/v1/chat/completions\", \"/v1/batch\", \"/v1/responses\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0 },\n  \"gpt-4o\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, input_cost_per_token_batches: 125e-8, output_cost_per_token_batches: 5e-6, cache_read_input_token_cost: 125e-8, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"watsonx/ibm/granite-3-8b-instruct\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 2e-4, output_cost_per_token: 2e-4, litellm_provider: \"watsonx\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0, supports_parallel_function_calling: !1, supports_vision: !1, supports_audio_input: !1, supports_audio_output: !1, supports_prompt_caching: !0, supports_response_schema: !0, supports_system_messages: !0 },\n  \"gpt-4o-search-preview-2025-03-11\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, input_cost_per_token_batches: 125e-8, output_cost_per_token_batches: 5e-6, cache_read_input_token_cost: 125e-8, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4o-search-preview\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, input_cost_per_token_batches: 125e-8, output_cost_per_token_batches: 5e-6, cache_read_input_token_cost: 125e-8, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_web_search: !0, search_context_cost_per_query: { search_context_size_low: 0.03, search_context_size_medium: 0.035, search_context_size_high: 0.05 } },\n  \"gpt-4.5-preview\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 75e-6, output_cost_per_token: 15e-5, input_cost_per_token_batches: 375e-7, output_cost_per_token_batches: 75e-6, cache_read_input_token_cost: 375e-7, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4.5-preview-2025-02-27\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 75e-6, output_cost_per_token: 15e-5, input_cost_per_token_batches: 375e-7, output_cost_per_token_batches: 75e-6, cache_read_input_token_cost: 375e-7, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, deprecation_date: \"2025-07-14\" },\n  \"gpt-4o-audio-preview\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, input_cost_per_audio_token: 1e-4, output_cost_per_token: 1e-5, output_cost_per_audio_token: 2e-4, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4o-audio-preview-2024-12-17\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, input_cost_per_audio_token: 4e-5, output_cost_per_token: 1e-5, output_cost_per_audio_token: 8e-5, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4o-audio-preview-2024-10-01\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, input_cost_per_audio_token: 1e-4, output_cost_per_token: 1e-5, output_cost_per_audio_token: 2e-4, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4o-audio-preview-2025-06-03\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, input_cost_per_audio_token: 4e-5, output_cost_per_token: 1e-5, output_cost_per_audio_token: 8e-5, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4o-mini-audio-preview\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 15e-8, input_cost_per_audio_token: 1e-5, output_cost_per_token: 6e-7, output_cost_per_audio_token: 2e-5, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4o-mini-audio-preview-2024-12-17\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 15e-8, input_cost_per_audio_token: 1e-5, output_cost_per_token: 6e-7, output_cost_per_audio_token: 2e-5, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4o-mini\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, input_cost_per_token_batches: 75e-9, output_cost_per_token_batches: 3e-7, cache_read_input_token_cost: 75e-9, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4o-mini-search-preview-2025-03-11\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, input_cost_per_token_batches: 75e-9, output_cost_per_token_batches: 3e-7, cache_read_input_token_cost: 75e-9, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4o-mini-search-preview\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, input_cost_per_token_batches: 75e-9, output_cost_per_token_batches: 3e-7, cache_read_input_token_cost: 75e-9, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_web_search: !0, search_context_cost_per_query: { search_context_size_low: 0.025, search_context_size_medium: 0.0275, search_context_size_high: 0.03 } },\n  \"gpt-4o-mini-2024-07-18\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, input_cost_per_token_batches: 75e-9, output_cost_per_token_batches: 3e-7, cache_read_input_token_cost: 75e-9, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, search_context_cost_per_query: { search_context_size_low: 30, search_context_size_medium: 35, search_context_size_high: 50 } },\n  \"codex-mini-latest\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 15e-7, output_cost_per_token: 6e-6, cache_read_input_token_cost: 375e-9, litellm_provider: \"openai\", mode: \"responses\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supported_endpoints: [\"/v1/responses\"] },\n  \"o1-pro\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 15e-5, output_cost_per_token: 6e-4, input_cost_per_token_batches: 75e-6, output_cost_per_token_batches: 3e-4, litellm_provider: \"openai\", mode: \"responses\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_native_streaming: !1, supports_reasoning: !0, supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supported_endpoints: [\"/v1/responses\", \"/v1/batch\"] },\n  \"o1-pro-2025-03-19\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 15e-5, output_cost_per_token: 6e-4, input_cost_per_token_batches: 75e-6, output_cost_per_token_batches: 3e-4, litellm_provider: \"openai\", mode: \"responses\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_native_streaming: !1, supports_reasoning: !0, supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supported_endpoints: [\"/v1/responses\", \"/v1/batch\"] },\n  o1: tt,\n  \"o1-mini\": { max_tokens: 65536, max_input_tokens: 128e3, max_output_tokens: 65536, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, cache_read_input_token_cost: 55e-8, litellm_provider: \"openai\", mode: \"chat\", supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0 },\n  \"computer-use-preview\": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 3e-6, output_cost_per_token: 12e-6, litellm_provider: \"azure\", mode: \"chat\", supported_endpoints: [\"/v1/responses\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !1, supports_system_messages: !0, supports_tool_choice: !0, supports_reasoning: !0 },\n  \"o3-pro\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 2e-5, input_cost_per_token_batches: 1e-5, output_cost_per_token_batches: 4e-5, output_cost_per_token: 8e-5, litellm_provider: \"openai\", mode: \"responses\", supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0, supported_endpoints: [\"/v1/responses\", \"/v1/batch\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"] },\n  \"o3-pro-2025-06-10\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 2e-5, input_cost_per_token_batches: 1e-5, output_cost_per_token_batches: 4e-5, output_cost_per_token: 8e-5, litellm_provider: \"openai\", mode: \"responses\", supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0, supported_endpoints: [\"/v1/responses\", \"/v1/batch\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"] },\n  o3: et,\n  \"o3-2025-04-16\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, cache_read_input_token_cost: 5e-7, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0, supported_endpoints: [\"/v1/responses\", \"/v1/chat/completions\", \"/v1/completions\", \"/v1/batch\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"] },\n  \"o3-mini\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, cache_read_input_token_cost: 55e-8, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !1, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },\n  \"o3-mini-2025-01-31\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, cache_read_input_token_cost: 55e-8, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !1, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },\n  \"o4-mini\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, cache_read_input_token_cost: 275e-9, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },\n  \"o4-mini-2025-04-16\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, cache_read_input_token_cost: 275e-9, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },\n  \"o1-mini-2024-09-12\": { max_tokens: 65536, max_input_tokens: 128e3, max_output_tokens: 65536, input_cost_per_token: 3e-6, output_cost_per_token: 12e-6, cache_read_input_token_cost: 15e-7, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_vision: !0, supports_reasoning: !0, supports_prompt_caching: !0 },\n  \"o1-preview\": { max_tokens: 32768, max_input_tokens: 128e3, max_output_tokens: 32768, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, cache_read_input_token_cost: 75e-7, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_vision: !0, supports_reasoning: !0, supports_prompt_caching: !0 },\n  \"o1-preview-2024-09-12\": { max_tokens: 32768, max_input_tokens: 128e3, max_output_tokens: 32768, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, cache_read_input_token_cost: 75e-7, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_vision: !0, supports_reasoning: !0, supports_prompt_caching: !0 },\n  \"o1-2024-12-17\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, cache_read_input_token_cost: 75e-7, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },\n  \"chatgpt-4o-latest\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 5e-6, output_cost_per_token: 15e-6, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4o-2024-05-13\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 5e-6, output_cost_per_token: 15e-6, input_cost_per_token_batches: 25e-7, output_cost_per_token_batches: 75e-7, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4o-2024-08-06\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, input_cost_per_token_batches: 125e-8, output_cost_per_token_batches: 5e-6, cache_read_input_token_cost: 125e-8, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4o-2024-11-20\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, input_cost_per_token_batches: 125e-8, output_cost_per_token_batches: 5e-6, cache_read_input_token_cost: 125e-8, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4o-realtime-preview-2024-10-01\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 5e-6, input_cost_per_audio_token: 1e-4, cache_read_input_token_cost: 25e-7, cache_creation_input_audio_token_cost: 2e-5, output_cost_per_token: 2e-5, output_cost_per_audio_token: 2e-4, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4o-realtime-preview\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 5e-6, input_cost_per_audio_token: 4e-5, cache_read_input_token_cost: 25e-7, output_cost_per_token: 2e-5, output_cost_per_audio_token: 8e-5, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4o-realtime-preview-2024-12-17\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 5e-6, input_cost_per_audio_token: 4e-5, cache_read_input_token_cost: 25e-7, output_cost_per_token: 2e-5, output_cost_per_audio_token: 8e-5, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4o-mini-realtime-preview\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 6e-7, input_cost_per_audio_token: 1e-5, cache_read_input_token_cost: 3e-7, cache_creation_input_audio_token_cost: 3e-7, output_cost_per_token: 24e-7, output_cost_per_audio_token: 2e-5, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4o-mini-realtime-preview-2024-12-17\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 6e-7, input_cost_per_audio_token: 1e-5, cache_read_input_token_cost: 3e-7, cache_creation_input_audio_token_cost: 3e-7, output_cost_per_token: 24e-7, output_cost_per_audio_token: 2e-5, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4-turbo-preview\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4-0314\": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 3e-5, output_cost_per_token: 6e-5, litellm_provider: \"openai\", mode: \"chat\", supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4-0613\": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 3e-5, output_cost_per_token: 6e-5, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_prompt_caching: !0, supports_system_messages: !0, deprecation_date: \"2025-06-06\", supports_tool_choice: !0 },\n  \"gpt-4-32k\": { max_tokens: 4096, max_input_tokens: 32768, max_output_tokens: 4096, input_cost_per_token: 6e-5, output_cost_per_token: 12e-5, litellm_provider: \"openai\", mode: \"chat\", supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4-32k-0314\": { max_tokens: 4096, max_input_tokens: 32768, max_output_tokens: 4096, input_cost_per_token: 6e-5, output_cost_per_token: 12e-5, litellm_provider: \"openai\", mode: \"chat\", supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4-32k-0613\": { max_tokens: 4096, max_input_tokens: 32768, max_output_tokens: 4096, input_cost_per_token: 6e-5, output_cost_per_token: 12e-5, litellm_provider: \"openai\", mode: \"chat\", supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4-turbo\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4-turbo-2024-04-09\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4-1106-preview\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4-0125-preview\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-4-vision-preview\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: \"openai\", mode: \"chat\", supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_system_messages: !0, deprecation_date: \"2024-12-06\", supports_tool_choice: !0 },\n  \"gpt-4-1106-vision-preview\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: \"openai\", mode: \"chat\", supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_system_messages: !0, deprecation_date: \"2024-12-06\", supports_tool_choice: !0 },\n  \"gpt-3.5-turbo\": { max_tokens: 4097, max_input_tokens: 16385, max_output_tokens: 4096, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-3.5-turbo-0301\": { max_tokens: 4097, max_input_tokens: 4097, max_output_tokens: 4096, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: \"openai\", mode: \"chat\", supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-3.5-turbo-0613\": { max_tokens: 4097, max_input_tokens: 4097, max_output_tokens: 4096, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-3.5-turbo-1106\": { max_tokens: 16385, max_input_tokens: 16385, max_output_tokens: 4096, input_cost_per_token: 1e-6, output_cost_per_token: 2e-6, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-3.5-turbo-0125\": { max_tokens: 16385, max_input_tokens: 16385, max_output_tokens: 4096, input_cost_per_token: 5e-7, output_cost_per_token: 15e-7, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-3.5-turbo-16k\": { max_tokens: 16385, max_input_tokens: 16385, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 4e-6, litellm_provider: \"openai\", mode: \"chat\", supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"gpt-3.5-turbo-16k-0613\": { max_tokens: 16385, max_input_tokens: 16385, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 4e-6, litellm_provider: \"openai\", mode: \"chat\", supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"ft:gpt-3.5-turbo\": { max_tokens: 4096, max_input_tokens: 16385, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 6e-6, input_cost_per_token_batches: 15e-7, output_cost_per_token_batches: 3e-6, litellm_provider: \"openai\", mode: \"chat\", supports_system_messages: !0, supports_tool_choice: !0 },\n  \"ft:gpt-3.5-turbo-0125\": { max_tokens: 4096, max_input_tokens: 16385, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 6e-6, litellm_provider: \"openai\", mode: \"chat\", supports_system_messages: !0, supports_tool_choice: !0 },\n  \"ft:gpt-3.5-turbo-1106\": { max_tokens: 4096, max_input_tokens: 16385, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 6e-6, litellm_provider: \"openai\", mode: \"chat\", supports_system_messages: !0, supports_tool_choice: !0 },\n  \"ft:gpt-3.5-turbo-0613\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 6e-6, litellm_provider: \"openai\", mode: \"chat\", supports_system_messages: !0, supports_tool_choice: !0 },\n  \"ft:gpt-4-0613\": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 3e-5, output_cost_per_token: 6e-5, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, source: \"OpenAI needs to add pricing for this ft model, will be updated when added by OpenAI. Defaulting to base model pricing\", supports_system_messages: !0, supports_tool_choice: !0 },\n  \"ft:gpt-4o-2024-08-06\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 375e-8, output_cost_per_token: 15e-6, input_cost_per_token_batches: 1875e-9, output_cost_per_token_batches: 75e-7, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"ft:gpt-4o-2024-11-20\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 375e-8, cache_creation_input_token_cost: 1875e-9, output_cost_per_token: 15e-6, litellm_provider: \"openai\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"ft:gpt-4o-mini-2024-07-18\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 3e-7, output_cost_per_token: 12e-7, input_cost_per_token_batches: 15e-8, output_cost_per_token_batches: 6e-7, cache_read_input_token_cost: 15e-8, litellm_provider: \"openai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"ft:davinci-002\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 4096, input_cost_per_token: 2e-6, output_cost_per_token: 2e-6, input_cost_per_token_batches: 1e-6, output_cost_per_token_batches: 1e-6, litellm_provider: \"text-completion-openai\", mode: \"completion\" },\n  \"ft:babbage-002\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 4096, input_cost_per_token: 4e-7, output_cost_per_token: 4e-7, input_cost_per_token_batches: 2e-7, output_cost_per_token_batches: 2e-7, litellm_provider: \"text-completion-openai\", mode: \"completion\" },\n  \"text-embedding-3-large\": { max_tokens: 8191, max_input_tokens: 8191, output_vector_size: 3072, input_cost_per_token: 13e-8, output_cost_per_token: 0, input_cost_per_token_batches: 65e-9, output_cost_per_token_batches: 0, litellm_provider: \"openai\", mode: \"embedding\" },\n  \"text-embedding-3-small\": { max_tokens: 8191, max_input_tokens: 8191, output_vector_size: 1536, input_cost_per_token: 2e-8, output_cost_per_token: 0, input_cost_per_token_batches: 1e-8, output_cost_per_token_batches: 0, litellm_provider: \"openai\", mode: \"embedding\" },\n  \"text-embedding-ada-002\": { max_tokens: 8191, max_input_tokens: 8191, output_vector_size: 1536, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"openai\", mode: \"embedding\" },\n  \"text-embedding-ada-002-v2\": { max_tokens: 8191, max_input_tokens: 8191, input_cost_per_token: 1e-7, output_cost_per_token: 0, input_cost_per_token_batches: 5e-8, output_cost_per_token_batches: 0, litellm_provider: \"openai\", mode: \"embedding\" },\n  \"text-moderation-stable\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 0, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"openai\", mode: \"moderation\" },\n  \"text-moderation-007\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 0, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"openai\", mode: \"moderation\" },\n  \"text-moderation-latest\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 0, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"openai\", mode: \"moderation\" },\n  \"256-x-256/dall-e-2\": { mode: \"image_generation\", input_cost_per_pixel: 24414e-11, output_cost_per_pixel: 0, litellm_provider: \"openai\" },\n  \"512-x-512/dall-e-2\": { mode: \"image_generation\", input_cost_per_pixel: 686e-10, output_cost_per_pixel: 0, litellm_provider: \"openai\" },\n  \"1024-x-1024/dall-e-2\": { mode: \"image_generation\", input_cost_per_pixel: 19e-9, output_cost_per_pixel: 0, litellm_provider: \"openai\" },\n  \"hd/1024-x-1792/dall-e-3\": { mode: \"image_generation\", input_cost_per_pixel: 6539e-11, output_cost_per_pixel: 0, litellm_provider: \"openai\" },\n  \"hd/1792-x-1024/dall-e-3\": { mode: \"image_generation\", input_cost_per_pixel: 6539e-11, output_cost_per_pixel: 0, litellm_provider: \"openai\" },\n  \"hd/1024-x-1024/dall-e-3\": { mode: \"image_generation\", input_cost_per_pixel: 7629e-11, output_cost_per_pixel: 0, litellm_provider: \"openai\" },\n  \"standard/1024-x-1792/dall-e-3\": { mode: \"image_generation\", input_cost_per_pixel: 4359e-11, output_cost_per_pixel: 0, litellm_provider: \"openai\" },\n  \"standard/1792-x-1024/dall-e-3\": { mode: \"image_generation\", input_cost_per_pixel: 4359e-11, output_cost_per_pixel: 0, litellm_provider: \"openai\" },\n  \"standard/1024-x-1024/dall-e-3\": { mode: \"image_generation\", input_cost_per_pixel: 381469e-13, output_cost_per_pixel: 0, litellm_provider: \"openai\" },\n  \"gpt-image-1\": { mode: \"image_generation\", input_cost_per_pixel: 40054321e-15, output_cost_per_pixel: 0, litellm_provider: \"openai\", supported_endpoints: [\"/v1/images/generations\"] },\n  \"low/1024-x-1024/gpt-image-1\": { mode: \"image_generation\", input_cost_per_pixel: 10490417e-15, output_cost_per_pixel: 0, litellm_provider: \"openai\", supported_endpoints: [\"/v1/images/generations\"] },\n  \"medium/1024-x-1024/gpt-image-1\": { mode: \"image_generation\", input_cost_per_pixel: 40054321e-15, output_cost_per_pixel: 0, litellm_provider: \"openai\", supported_endpoints: [\"/v1/images/generations\"] },\n  \"high/1024-x-1024/gpt-image-1\": { mode: \"image_generation\", input_cost_per_pixel: 159263611e-15, output_cost_per_pixel: 0, litellm_provider: \"openai\", supported_endpoints: [\"/v1/images/generations\"] },\n  \"low/1024-x-1536/gpt-image-1\": { mode: \"image_generation\", input_cost_per_pixel: 10172526e-15, output_cost_per_pixel: 0, litellm_provider: \"openai\", supported_endpoints: [\"/v1/images/generations\"] },\n  \"medium/1024-x-1536/gpt-image-1\": { mode: \"image_generation\", input_cost_per_pixel: 40054321e-15, output_cost_per_pixel: 0, litellm_provider: \"openai\", supported_endpoints: [\"/v1/images/generations\"] },\n  \"high/1024-x-1536/gpt-image-1\": { mode: \"image_generation\", input_cost_per_pixel: 158945719e-15, output_cost_per_pixel: 0, litellm_provider: \"openai\", supported_endpoints: [\"/v1/images/generations\"] },\n  \"low/1536-x-1024/gpt-image-1\": { mode: \"image_generation\", input_cost_per_pixel: 10172526e-15, output_cost_per_pixel: 0, litellm_provider: \"openai\", supported_endpoints: [\"/v1/images/generations\"] },\n  \"medium/1536-x-1024/gpt-image-1\": { mode: \"image_generation\", input_cost_per_pixel: 40054321e-15, output_cost_per_pixel: 0, litellm_provider: \"openai\", supported_endpoints: [\"/v1/images/generations\"] },\n  \"high/1536-x-1024/gpt-image-1\": { mode: \"image_generation\", input_cost_per_pixel: 158945719e-15, output_cost_per_pixel: 0, litellm_provider: \"openai\", supported_endpoints: [\"/v1/images/generations\"] },\n  \"gpt-4o-transcribe\": { mode: \"audio_transcription\", max_input_tokens: 16e3, max_output_tokens: 2e3, input_cost_per_token: 25e-7, input_cost_per_audio_token: 6e-6, output_cost_per_token: 1e-5, litellm_provider: \"openai\", supported_endpoints: [\"/v1/audio/transcriptions\"] },\n  \"gpt-4o-mini-transcribe\": { mode: \"audio_transcription\", max_input_tokens: 16e3, max_output_tokens: 2e3, input_cost_per_token: 125e-8, input_cost_per_audio_token: 3e-6, output_cost_per_token: 5e-6, litellm_provider: \"openai\", supported_endpoints: [\"/v1/audio/transcriptions\"] },\n  \"whisper-1\": { mode: \"audio_transcription\", input_cost_per_second: 1e-4, output_cost_per_second: 1e-4, litellm_provider: \"openai\", supported_endpoints: [\"/v1/audio/transcriptions\"] },\n  \"tts-1\": { mode: \"audio_speech\", input_cost_per_character: 15e-6, litellm_provider: \"openai\", supported_endpoints: [\"/v1/audio/speech\"] },\n  \"tts-1-hd\": { mode: \"audio_speech\", input_cost_per_character: 3e-5, litellm_provider: \"openai\", supported_endpoints: [\"/v1/audio/speech\"] },\n  \"gpt-4o-mini-tts\": { mode: \"audio_speech\", input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, output_cost_per_audio_token: 12e-6, output_cost_per_second: 25e-5, litellm_provider: \"openai\", supported_modalities: [\"text\", \"audio\"], supported_output_modalities: [\"audio\"], supported_endpoints: [\"/v1/audio/speech\"] },\n  \"azure/gpt-4o-mini-tts\": { mode: \"audio_speech\", input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, output_cost_per_audio_token: 12e-6, output_cost_per_second: 25e-5, litellm_provider: \"azure\", supported_modalities: [\"text\", \"audio\"], supported_output_modalities: [\"audio\"], supported_endpoints: [\"/v1/audio/speech\"] },\n  \"azure/computer-use-preview\": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 3e-6, output_cost_per_token: 12e-6, litellm_provider: \"azure\", mode: \"chat\", supported_endpoints: [\"/v1/responses\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !1, supports_system_messages: !0, supports_tool_choice: !0, supports_reasoning: !0 },\n  \"azure/gpt-4o-audio-preview-2024-12-17\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, input_cost_per_audio_token: 4e-5, output_cost_per_token: 1e-5, output_cost_per_audio_token: 8e-5, litellm_provider: \"azure\", mode: \"chat\", supported_endpoints: [\"/v1/chat/completions\"], supported_modalities: [\"text\", \"audio\"], supported_output_modalities: [\"text\", \"audio\"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !1, supports_vision: !1, supports_prompt_caching: !1, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0, supports_reasoning: !1 },\n  \"azure/gpt-4o-mini-audio-preview-2024-12-17\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, input_cost_per_audio_token: 4e-5, output_cost_per_token: 1e-5, output_cost_per_audio_token: 8e-5, litellm_provider: \"azure\", mode: \"chat\", supported_endpoints: [\"/v1/chat/completions\"], supported_modalities: [\"text\", \"audio\"], supported_output_modalities: [\"text\", \"audio\"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !1, supports_vision: !1, supports_prompt_caching: !1, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0, supports_reasoning: !1 },\n  \"azure/gpt-4.1\": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, input_cost_per_token_batches: 1e-6, output_cost_per_token_batches: 4e-6, cache_read_input_token_cost: 5e-7, litellm_provider: \"azure\", mode: \"chat\", supported_endpoints: [\"/v1/chat/completions\", \"/v1/batch\", \"/v1/responses\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0, supports_web_search: !0, search_context_cost_per_query: { search_context_size_low: 0.03, search_context_size_medium: 0.035, search_context_size_high: 0.05 } },\n  \"azure/gpt-4.1-2025-04-14\": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, input_cost_per_token_batches: 1e-6, output_cost_per_token_batches: 4e-6, cache_read_input_token_cost: 5e-7, litellm_provider: \"azure\", mode: \"chat\", supported_endpoints: [\"/v1/chat/completions\", \"/v1/batch\", \"/v1/responses\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0, supports_web_search: !0, search_context_cost_per_query: { search_context_size_low: 0.03, search_context_size_medium: 0.035, search_context_size_high: 0.05 } },\n  \"azure/gpt-4.1-mini\": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 4e-7, output_cost_per_token: 16e-7, input_cost_per_token_batches: 2e-7, output_cost_per_token_batches: 8e-7, cache_read_input_token_cost: 1e-7, litellm_provider: \"azure\", mode: \"chat\", supported_endpoints: [\"/v1/chat/completions\", \"/v1/batch\", \"/v1/responses\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0, supports_web_search: !0, search_context_cost_per_query: { search_context_size_low: 0.025, search_context_size_medium: 0.0275, search_context_size_high: 0.03 } },\n  \"azure/gpt-4.1-mini-2025-04-14\": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 4e-7, output_cost_per_token: 16e-7, input_cost_per_token_batches: 2e-7, output_cost_per_token_batches: 8e-7, cache_read_input_token_cost: 1e-7, litellm_provider: \"azure\", mode: \"chat\", supported_endpoints: [\"/v1/chat/completions\", \"/v1/batch\", \"/v1/responses\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0, supports_web_search: !0, search_context_cost_per_query: { search_context_size_low: 0.025, search_context_size_medium: 0.0275, search_context_size_high: 0.03 } },\n  \"azure/gpt-4.1-nano\": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 1e-7, output_cost_per_token: 4e-7, input_cost_per_token_batches: 5e-8, output_cost_per_token_batches: 2e-7, cache_read_input_token_cost: 25e-9, litellm_provider: \"azure\", mode: \"chat\", supported_endpoints: [\"/v1/chat/completions\", \"/v1/batch\", \"/v1/responses\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0 },\n  \"azure/gpt-4.1-nano-2025-04-14\": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 1e-7, output_cost_per_token: 4e-7, input_cost_per_token_batches: 5e-8, output_cost_per_token_batches: 2e-7, cache_read_input_token_cost: 25e-9, litellm_provider: \"azure\", mode: \"chat\", supported_endpoints: [\"/v1/chat/completions\", \"/v1/batch\", \"/v1/responses\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0 },\n  \"azure/o3\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 1e-5, output_cost_per_token: 4e-5, cache_read_input_token_cost: 25e-7, litellm_provider: \"azure\", mode: \"chat\", supported_endpoints: [\"/v1/chat/completions\", \"/v1/batch\", \"/v1/responses\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },\n  \"azure/o3-2025-04-16\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 1e-5, output_cost_per_token: 4e-5, cache_read_input_token_cost: 25e-7, litellm_provider: \"azure\", mode: \"chat\", supported_endpoints: [\"/v1/chat/completions\", \"/v1/batch\", \"/v1/responses\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },\n  \"azure/o4-mini\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, cache_read_input_token_cost: 275e-9, litellm_provider: \"azure\", mode: \"chat\", supported_endpoints: [\"/v1/chat/completions\", \"/v1/batch\", \"/v1/responses\"], supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },\n  \"azure/gpt-4o-mini-realtime-preview-2024-12-17\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 6e-7, input_cost_per_audio_token: 1e-5, cache_read_input_token_cost: 3e-7, cache_creation_input_audio_token_cost: 3e-7, output_cost_per_token: 24e-7, output_cost_per_audio_token: 2e-5, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"azure/eu/gpt-4o-mini-realtime-preview-2024-12-17\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 66e-8, input_cost_per_audio_token: 11e-6, cache_read_input_token_cost: 33e-8, cache_creation_input_audio_token_cost: 33e-8, output_cost_per_token: 264e-8, output_cost_per_audio_token: 22e-6, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"azure/us/gpt-4o-mini-realtime-preview-2024-12-17\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 66e-8, input_cost_per_audio_token: 11e-6, cache_read_input_token_cost: 33e-8, cache_creation_input_audio_token_cost: 33e-8, output_cost_per_token: 264e-8, output_cost_per_audio_token: 22e-6, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"azure/gpt-4o-realtime-preview-2024-12-17\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 5e-6, input_cost_per_audio_token: 4e-5, cache_read_input_token_cost: 25e-7, output_cost_per_token: 2e-5, output_cost_per_audio_token: 8e-5, litellm_provider: \"azure\", mode: \"chat\", supported_modalities: [\"text\", \"audio\"], supported_output_modalities: [\"text\", \"audio\"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"azure/us/gpt-4o-realtime-preview-2024-12-17\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 55e-7, input_cost_per_audio_token: 44e-6, cache_read_input_token_cost: 275e-8, cache_read_input_audio_token_cost: 25e-7, output_cost_per_token: 22e-6, output_cost_per_audio_token: 8e-5, litellm_provider: \"azure\", mode: \"chat\", supported_modalities: [\"text\", \"audio\"], supported_output_modalities: [\"text\", \"audio\"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"azure/eu/gpt-4o-realtime-preview-2024-12-17\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 55e-7, input_cost_per_audio_token: 44e-6, cache_read_input_token_cost: 275e-8, cache_read_input_audio_token_cost: 25e-7, output_cost_per_token: 22e-6, output_cost_per_audio_token: 8e-5, litellm_provider: \"azure\", mode: \"chat\", supported_modalities: [\"text\", \"audio\"], supported_output_modalities: [\"text\", \"audio\"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"azure/gpt-4o-realtime-preview-2024-10-01\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 5e-6, input_cost_per_audio_token: 1e-4, cache_read_input_token_cost: 25e-7, cache_creation_input_audio_token_cost: 2e-5, output_cost_per_token: 2e-5, output_cost_per_audio_token: 2e-4, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"azure/us/gpt-4o-realtime-preview-2024-10-01\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 55e-7, input_cost_per_audio_token: 11e-5, cache_read_input_token_cost: 275e-8, cache_creation_input_audio_token_cost: 22e-6, output_cost_per_token: 22e-6, output_cost_per_audio_token: 22e-5, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"azure/eu/gpt-4o-realtime-preview-2024-10-01\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 55e-7, input_cost_per_audio_token: 11e-5, cache_read_input_token_cost: 275e-8, cache_creation_input_audio_token_cost: 22e-6, output_cost_per_token: 22e-6, output_cost_per_audio_token: 22e-5, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"azure/o4-mini-2025-04-16\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, cache_read_input_token_cost: 275e-9, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },\n  \"azure/o3-mini-2025-01-31\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, cache_read_input_token_cost: 55e-8, litellm_provider: \"azure\", mode: \"chat\", supports_reasoning: !0, supports_vision: !1, supports_prompt_caching: !0, supports_tool_choice: !0 },\n  \"azure/us/o3-mini-2025-01-31\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 121e-8, input_cost_per_token_batches: 605e-9, output_cost_per_token: 484e-8, output_cost_per_token_batches: 242e-8, cache_read_input_token_cost: 605e-9, litellm_provider: \"azure\", mode: \"chat\", supports_vision: !1, supports_reasoning: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },\n  \"azure/eu/o3-mini-2025-01-31\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 121e-8, input_cost_per_token_batches: 605e-9, output_cost_per_token: 484e-8, output_cost_per_token_batches: 242e-8, cache_read_input_token_cost: 605e-9, litellm_provider: \"azure\", mode: \"chat\", supports_vision: !1, supports_reasoning: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },\n  \"azure/tts-1\": { mode: \"audio_speech\", input_cost_per_character: 15e-6, litellm_provider: \"azure\" },\n  \"azure/tts-1-hd\": { mode: \"audio_speech\", input_cost_per_character: 3e-5, litellm_provider: \"azure\" },\n  \"azure/whisper-1\": { mode: \"audio_transcription\", input_cost_per_second: 1e-4, output_cost_per_second: 1e-4, litellm_provider: \"azure\" },\n  \"azure/gpt-4o-transcribe\": { mode: \"audio_transcription\", max_input_tokens: 16e3, max_output_tokens: 2e3, input_cost_per_token: 25e-7, input_cost_per_audio_token: 6e-6, output_cost_per_token: 1e-5, litellm_provider: \"azure\", supported_endpoints: [\"/v1/audio/transcriptions\"] },\n  \"azure/gpt-4o-mini-transcribe\": { mode: \"audio_transcription\", max_input_tokens: 16e3, max_output_tokens: 2e3, input_cost_per_token: 125e-8, input_cost_per_audio_token: 3e-6, output_cost_per_token: 5e-6, litellm_provider: \"azure\", supported_endpoints: [\"/v1/audio/transcriptions\"] },\n  \"azure/o3-mini\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, cache_read_input_token_cost: 55e-8, litellm_provider: \"azure\", mode: \"chat\", supports_vision: !1, supports_prompt_caching: !0, supports_reasoning: !0, supports_response_schema: !0, supports_tool_choice: !0 },\n  \"azure/o1-mini\": { max_tokens: 65536, max_input_tokens: 128e3, max_output_tokens: 65536, input_cost_per_token: 121e-8, output_cost_per_token: 484e-8, cache_read_input_token_cost: 605e-9, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_reasoning: !0, supports_prompt_caching: !0 },\n  \"azure/o1-mini-2024-09-12\": { max_tokens: 65536, max_input_tokens: 128e3, max_output_tokens: 65536, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, cache_read_input_token_cost: 55e-8, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_reasoning: !0, supports_prompt_caching: !0 },\n  \"azure/us/o1-mini-2024-09-12\": { max_tokens: 65536, max_input_tokens: 128e3, max_output_tokens: 65536, input_cost_per_token: 121e-8, input_cost_per_token_batches: 605e-9, output_cost_per_token: 484e-8, output_cost_per_token_batches: 242e-8, cache_read_input_token_cost: 605e-9, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_prompt_caching: !0 },\n  \"azure/eu/o1-mini-2024-09-12\": { max_tokens: 65536, max_input_tokens: 128e3, max_output_tokens: 65536, input_cost_per_token: 121e-8, input_cost_per_token_batches: 605e-9, output_cost_per_token: 484e-8, output_cost_per_token_batches: 242e-8, cache_read_input_token_cost: 605e-9, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_prompt_caching: !0 },\n  \"azure/o1\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, cache_read_input_token_cost: 75e-7, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_reasoning: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },\n  \"azure/o1-2024-12-17\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, cache_read_input_token_cost: 75e-7, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_reasoning: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },\n  \"azure/us/o1-2024-12-17\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 165e-7, output_cost_per_token: 66e-6, cache_read_input_token_cost: 825e-8, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },\n  \"azure/eu/o1-2024-12-17\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 165e-7, output_cost_per_token: 66e-6, cache_read_input_token_cost: 825e-8, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },\n  \"azure/codex-mini-latest\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 15e-7, output_cost_per_token: 6e-6, cache_read_input_token_cost: 375e-9, litellm_provider: \"azure\", mode: \"responses\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"], supported_endpoints: [\"/v1/responses\"] },\n  \"azure/o1-preview\": { max_tokens: 32768, max_input_tokens: 128e3, max_output_tokens: 32768, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, cache_read_input_token_cost: 75e-7, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_reasoning: !0, supports_prompt_caching: !0 },\n  \"azure/o1-preview-2024-09-12\": { max_tokens: 32768, max_input_tokens: 128e3, max_output_tokens: 32768, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, cache_read_input_token_cost: 75e-7, litellm_provider: \"azure\", mode: \"chat\", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_reasoning: !0, supports_prompt_caching: !0 },\n  \"azure/us/o1-preview-2024-09-12\": { max_tokens: 32768, max_input_tokens: 128e3, max_output_tokens: 32768, input_cost_per_token: 165e-7, output_cost_per_token: 66e-6, cache_read_input_token_cost: 825e-8, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_prompt_caching: !0 },\n  \"azure/eu/o1-preview-2024-09-12\": { max_tokens: 32768, max_input_tokens: 128e3, max_output_tokens: 32768, input_cost_per_token: 165e-7, output_cost_per_token: 66e-6, cache_read_input_token_cost: 825e-8, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_prompt_caching: !0 },\n  \"azure/gpt-4.5-preview\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 75e-6, output_cost_per_token: 15e-5, input_cost_per_token_batches: 375e-7, output_cost_per_token_batches: 75e-6, cache_read_input_token_cost: 375e-7, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },\n  \"azure/gpt-4o\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, cache_read_input_token_cost: 125e-8, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },\n  \"azure/global/gpt-4o-2024-11-20\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, cache_read_input_token_cost: 125e-8, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },\n  \"azure/gpt-4o-2024-08-06\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, cache_read_input_token_cost: 125e-8, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },\n  \"azure/global/gpt-4o-2024-08-06\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, cache_read_input_token_cost: 125e-8, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },\n  \"azure/gpt-4o-2024-11-20\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 275e-8, output_cost_per_token: 11e-6, cache_read_input_token_cost: 125e-8, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },\n  \"azure/us/gpt-4o-2024-11-20\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 275e-8, cache_creation_input_token_cost: 138e-8, output_cost_per_token: 11e-6, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_tool_choice: !0 },\n  \"azure/eu/gpt-4o-2024-11-20\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 275e-8, cache_creation_input_token_cost: 138e-8, output_cost_per_token: 11e-6, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_tool_choice: !0 },\n  \"azure/gpt-4o-2024-05-13\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 5e-6, output_cost_per_token: 15e-6, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },\n  \"azure/global-standard/gpt-4o-2024-08-06\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, cache_read_input_token_cost: 125e-8, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0, deprecation_date: \"2025-08-20\" },\n  \"azure/us/gpt-4o-2024-08-06\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 275e-8, output_cost_per_token: 11e-6, cache_read_input_token_cost: 1375e-9, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },\n  \"azure/eu/gpt-4o-2024-08-06\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 275e-8, output_cost_per_token: 11e-6, cache_read_input_token_cost: 1375e-9, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },\n  \"azure/global-standard/gpt-4o-2024-11-20\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, cache_read_input_token_cost: 125e-8, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_tool_choice: !0, deprecation_date: \"2025-12-20\" },\n  \"azure/global-standard/gpt-4o-mini\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_tool_choice: !0 },\n  \"azure/gpt-4o-mini\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 165e-9, output_cost_per_token: 66e-8, cache_read_input_token_cost: 75e-9, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },\n  \"azure/gpt-4o-mini-2024-07-18\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 165e-9, output_cost_per_token: 66e-8, cache_read_input_token_cost: 75e-9, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },\n  \"azure/us/gpt-4o-mini-2024-07-18\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 165e-9, output_cost_per_token: 66e-8, cache_read_input_token_cost: 83e-9, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },\n  \"azure/eu/gpt-4o-mini-2024-07-18\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 165e-9, output_cost_per_token: 66e-8, cache_read_input_token_cost: 83e-9, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },\n  \"azure/gpt-4-turbo-2024-04-09\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_tool_choice: !0 },\n  \"azure/gpt-4-0125-preview\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_tool_choice: !0 },\n  \"azure/gpt-4-1106-preview\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_tool_choice: !0 },\n  \"azure/gpt-4-0613\": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 3e-5, output_cost_per_token: 6e-5, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"azure/gpt-4-32k-0613\": { max_tokens: 4096, max_input_tokens: 32768, max_output_tokens: 4096, input_cost_per_token: 6e-5, output_cost_per_token: 12e-5, litellm_provider: \"azure\", mode: \"chat\", supports_tool_choice: !0 },\n  \"azure/gpt-4-32k\": { max_tokens: 4096, max_input_tokens: 32768, max_output_tokens: 4096, input_cost_per_token: 6e-5, output_cost_per_token: 12e-5, litellm_provider: \"azure\", mode: \"chat\", supports_tool_choice: !0 },\n  \"azure/gpt-4\": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 3e-5, output_cost_per_token: 6e-5, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"azure/gpt-4-turbo\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_tool_choice: !0 },\n  \"azure/gpt-4-turbo-vision-preview\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: \"azure\", mode: \"chat\", supports_vision: !0, supports_tool_choice: !0 },\n  \"azure/gpt-35-turbo-16k-0613\": { max_tokens: 4096, max_input_tokens: 16385, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 4e-6, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"azure/gpt-35-turbo-1106\": { max_tokens: 4096, max_input_tokens: 16384, max_output_tokens: 4096, input_cost_per_token: 1e-6, output_cost_per_token: 2e-6, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, deprecation_date: \"2025-03-31\", supports_tool_choice: !0 },\n  \"azure/gpt-35-turbo-0613\": { max_tokens: 4097, max_input_tokens: 4097, max_output_tokens: 4096, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, deprecation_date: \"2025-02-13\", supports_tool_choice: !0 },\n  \"azure/gpt-35-turbo-0301\": { max_tokens: 4097, max_input_tokens: 4097, max_output_tokens: 4096, input_cost_per_token: 2e-7, output_cost_per_token: 2e-6, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, deprecation_date: \"2025-02-13\", supports_tool_choice: !0 },\n  \"azure/gpt-35-turbo-0125\": { max_tokens: 4096, max_input_tokens: 16384, max_output_tokens: 4096, input_cost_per_token: 5e-7, output_cost_per_token: 15e-7, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, deprecation_date: \"2025-05-31\", supports_tool_choice: !0 },\n  \"azure/gpt-3.5-turbo-0125\": { max_tokens: 4096, max_input_tokens: 16384, max_output_tokens: 4096, input_cost_per_token: 5e-7, output_cost_per_token: 15e-7, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, deprecation_date: \"2025-03-31\", supports_tool_choice: !0 },\n  \"azure/gpt-35-turbo-16k\": { max_tokens: 4096, max_input_tokens: 16385, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 4e-6, litellm_provider: \"azure\", mode: \"chat\", supports_tool_choice: !0 },\n  \"azure/gpt-35-turbo\": { max_tokens: 4096, max_input_tokens: 4097, max_output_tokens: 4096, input_cost_per_token: 5e-7, output_cost_per_token: 15e-7, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"azure/gpt-3.5-turbo\": { max_tokens: 4096, max_input_tokens: 4097, max_output_tokens: 4096, input_cost_per_token: 5e-7, output_cost_per_token: 15e-7, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"azure/gpt-3.5-turbo-instruct-0914\": { max_tokens: 4097, max_input_tokens: 4097, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: \"azure_text\", mode: \"completion\" },\n  \"azure/gpt-35-turbo-instruct\": { max_tokens: 4097, max_input_tokens: 4097, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: \"azure_text\", mode: \"completion\" },\n  \"azure/gpt-35-turbo-instruct-0914\": { max_tokens: 4097, max_input_tokens: 4097, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: \"azure_text\", mode: \"completion\" },\n  \"azure/mistral-large-latest\": { max_tokens: 32e3, max_input_tokens: 32e3, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0 },\n  \"azure/mistral-large-2402\": { max_tokens: 32e3, max_input_tokens: 32e3, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0 },\n  \"azure/command-r-plus\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"azure\", mode: \"chat\", supports_function_calling: !0 },\n  \"azure/ada\": { max_tokens: 8191, max_input_tokens: 8191, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"azure\", mode: \"embedding\" },\n  \"azure/text-embedding-ada-002\": { max_tokens: 8191, max_input_tokens: 8191, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"azure\", mode: \"embedding\" },\n  \"azure/text-embedding-3-large\": { max_tokens: 8191, max_input_tokens: 8191, input_cost_per_token: 13e-8, output_cost_per_token: 0, litellm_provider: \"azure\", mode: \"embedding\" },\n  \"azure/text-embedding-3-small\": { max_tokens: 8191, max_input_tokens: 8191, input_cost_per_token: 2e-8, output_cost_per_token: 0, litellm_provider: \"azure\", mode: \"embedding\" },\n  \"azure/gpt-image-1\": { mode: \"image_generation\", input_cost_per_pixel: 40054321e-15, output_cost_per_pixel: 0, litellm_provider: \"azure\", supported_endpoints: [\"/v1/images/generations\"] },\n  \"azure/low/1024-x-1024/gpt-image-1\": { mode: \"image_generation\", input_cost_per_pixel: 10490417e-15, output_cost_per_pixel: 0, litellm_provider: \"azure\", supported_endpoints: [\"/v1/images/generations\"] },\n  \"azure/medium/1024-x-1024/gpt-image-1\": { mode: \"image_generation\", input_cost_per_pixel: 40054321e-15, output_cost_per_pixel: 0, litellm_provider: \"azure\", supported_endpoints: [\"/v1/images/generations\"] },\n  \"azure/high/1024-x-1024/gpt-image-1\": { mode: \"image_generation\", input_cost_per_pixel: 159263611e-15, output_cost_per_pixel: 0, litellm_provider: \"azure\", supported_endpoints: [\"/v1/images/generations\"] },\n  \"azure/low/1024-x-1536/gpt-image-1\": { mode: \"image_generation\", input_cost_per_pixel: 10172526e-15, output_cost_per_pixel: 0, litellm_provider: \"azure\", supported_endpoints: [\"/v1/images/generations\"] },\n  \"azure/medium/1024-x-1536/gpt-image-1\": { mode: \"image_generation\", input_cost_per_pixel: 40054321e-15, output_cost_per_pixel: 0, litellm_provider: \"azure\", supported_endpoints: [\"/v1/images/generations\"] },\n  \"azure/high/1024-x-1536/gpt-image-1\": { mode: \"image_generation\", input_cost_per_pixel: 158945719e-15, output_cost_per_pixel: 0, litellm_provider: \"azure\", supported_endpoints: [\"/v1/images/generations\"] },\n  \"azure/low/1536-x-1024/gpt-image-1\": { mode: \"image_generation\", input_cost_per_pixel: 10172526e-15, output_cost_per_pixel: 0, litellm_provider: \"azure\", supported_endpoints: [\"/v1/images/generations\"] },\n  \"azure/medium/1536-x-1024/gpt-image-1\": { mode: \"image_generation\", input_cost_per_pixel: 40054321e-15, output_cost_per_pixel: 0, litellm_provider: \"azure\", supported_endpoints: [\"/v1/images/generations\"] },\n  \"azure/high/1536-x-1024/gpt-image-1\": { mode: \"image_generation\", input_cost_per_pixel: 158945719e-15, output_cost_per_pixel: 0, litellm_provider: \"azure\", supported_endpoints: [\"/v1/images/generations\"] },\n  \"azure/standard/1024-x-1024/dall-e-3\": { input_cost_per_pixel: 381469e-13, output_cost_per_token: 0, litellm_provider: \"azure\", mode: \"image_generation\" },\n  \"azure/hd/1024-x-1024/dall-e-3\": { input_cost_per_pixel: 7629e-11, output_cost_per_token: 0, litellm_provider: \"azure\", mode: \"image_generation\" },\n  \"azure/standard/1024-x-1792/dall-e-3\": { input_cost_per_pixel: 4359e-11, output_cost_per_token: 0, litellm_provider: \"azure\", mode: \"image_generation\" },\n  \"azure/standard/1792-x-1024/dall-e-3\": { input_cost_per_pixel: 4359e-11, output_cost_per_token: 0, litellm_provider: \"azure\", mode: \"image_generation\" },\n  \"azure/hd/1024-x-1792/dall-e-3\": { input_cost_per_pixel: 6539e-11, output_cost_per_token: 0, litellm_provider: \"azure\", mode: \"image_generation\" },\n  \"azure/hd/1792-x-1024/dall-e-3\": { input_cost_per_pixel: 6539e-11, output_cost_per_token: 0, litellm_provider: \"azure\", mode: \"image_generation\" },\n  \"azure/standard/1024-x-1024/dall-e-2\": { input_cost_per_pixel: 0, output_cost_per_token: 0, litellm_provider: \"azure\", mode: \"image_generation\" },\n  \"azure_ai/deepseek-r1\": { max_tokens: 8192, max_input_tokens: 128e3, max_output_tokens: 8192, input_cost_per_token: 135e-8, output_cost_per_token: 54e-7, litellm_provider: \"azure_ai\", mode: \"chat\", supports_tool_choice: !0, supports_reasoning: !0, source: \"https://techcommunity.microsoft.com/blog/machinelearningblog/deepseek-r1-improved-performance-higher-limits-and-transparent-pricing/4386367\" },\n  \"azure_ai/deepseek-v3\": { max_tokens: 8192, max_input_tokens: 128e3, max_output_tokens: 8192, input_cost_per_token: 114e-8, output_cost_per_token: 456e-8, litellm_provider: \"azure_ai\", mode: \"chat\", supports_tool_choice: !0, source: \"https://techcommunity.microsoft.com/blog/machinelearningblog/announcing-deepseek-v3-on-azure-ai-foundry-and-github/4390438\" },\n  \"azure_ai/deepseek-v3-0324\": { max_tokens: 8192, max_input_tokens: 128e3, max_output_tokens: 8192, input_cost_per_token: 114e-8, output_cost_per_token: 456e-8, litellm_provider: \"azure_ai\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0, source: \"https://techcommunity.microsoft.com/blog/machinelearningblog/announcing-deepseek-v3-on-azure-ai-foundry-and-github/4390438\" },\n  \"azure_ai/jamba-instruct\": { max_tokens: 4096, max_input_tokens: 7e4, max_output_tokens: 4096, input_cost_per_token: 5e-7, output_cost_per_token: 7e-7, litellm_provider: \"azure_ai\", mode: \"chat\", supports_tool_choice: !0 },\n  \"azure_ai/mistral-nemo\": { max_tokens: 4096, max_input_tokens: 131072, max_output_tokens: 4096, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: \"azure_ai\", mode: \"chat\", supports_function_calling: !0, source: \"https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-nemo-12b-2407?tab=PlansAndPrice\" },\n  \"azure_ai/mistral-medium-2505\": { max_tokens: 8191, max_input_tokens: 131072, max_output_tokens: 8191, input_cost_per_token: 4e-7, output_cost_per_token: 2e-6, litellm_provider: \"azure_ai\", mode: \"chat\", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"azure_ai/mistral-large\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 4e-6, output_cost_per_token: 12e-6, litellm_provider: \"azure_ai\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"azure_ai/mistral-small\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 1e-6, output_cost_per_token: 3e-6, litellm_provider: \"azure_ai\", supports_function_calling: !0, mode: \"chat\", supports_tool_choice: !0 },\n  \"azure_ai/mistral-small-2503\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 1e-6, output_cost_per_token: 3e-6, litellm_provider: \"azure_ai\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0 },\n  \"azure_ai/mistral-large-2407\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: \"azure_ai\", supports_function_calling: !0, mode: \"chat\", source: \"https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview\", supports_tool_choice: !0 },\n  \"azure_ai/mistral-large-latest\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: \"azure_ai\", supports_function_calling: !0, mode: \"chat\", source: \"https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview\", supports_tool_choice: !0 },\n  \"azure_ai/ministral-3b\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 4e-8, output_cost_per_token: 4e-8, litellm_provider: \"azure_ai\", supports_function_calling: !0, mode: \"chat\", source: \"https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.ministral-3b-2410-offer?tab=Overview\", supports_tool_choice: !0 },\n  \"azure_ai/Llama-3.2-11B-Vision-Instruct\": { max_tokens: 2048, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 37e-8, output_cost_per_token: 37e-8, litellm_provider: \"azure_ai\", supports_function_calling: !0, supports_vision: !0, mode: \"chat\", source: \"https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-11b-vision-instruct-offer?tab=Overview\", supports_tool_choice: !0 },\n  \"azure_ai/Llama-3.3-70B-Instruct\": { max_tokens: 2048, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 71e-8, output_cost_per_token: 71e-8, litellm_provider: \"azure_ai\", supports_function_calling: !0, mode: \"chat\", source: \"https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.llama-3-3-70b-instruct-offer?tab=Overview\", supports_tool_choice: !0 },\n  \"azure_ai/Llama-4-Scout-17B-16E-Instruct\": { max_tokens: 16384, max_input_tokens: 1e7, max_output_tokens: 16384, input_cost_per_token: 2e-7, output_cost_per_token: 78e-8, litellm_provider: \"azure_ai\", supports_function_calling: !0, supports_vision: !0, mode: \"chat\", source: \"https://azure.microsoft.com/en-us/blog/introducing-the-llama-4-herd-in-azure-ai-foundry-and-azure-databricks/\", supports_tool_choice: !0 },\n  \"azure_ai/Llama-4-Maverick-17B-128E-Instruct-FP8\": { max_tokens: 16384, max_input_tokens: 1e6, max_output_tokens: 16384, input_cost_per_token: 141e-8, output_cost_per_token: 35e-8, litellm_provider: \"azure_ai\", supports_function_calling: !0, supports_vision: !0, mode: \"chat\", source: \"https://azure.microsoft.com/en-us/blog/introducing-the-llama-4-herd-in-azure-ai-foundry-and-azure-databricks/\", supports_tool_choice: !0 },\n  \"azure_ai/Llama-3.2-90B-Vision-Instruct\": { max_tokens: 2048, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 204e-8, output_cost_per_token: 204e-8, litellm_provider: \"azure_ai\", supports_function_calling: !0, supports_vision: !0, mode: \"chat\", source: \"https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-90b-vision-instruct-offer?tab=Overview\", supports_tool_choice: !0 },\n  \"azure_ai/Meta-Llama-3-70B-Instruct\": { max_tokens: 2048, max_input_tokens: 8192, max_output_tokens: 2048, input_cost_per_token: 11e-7, output_cost_per_token: 37e-8, litellm_provider: \"azure_ai\", mode: \"chat\", supports_tool_choice: !0 },\n  \"azure_ai/Meta-Llama-3.1-8B-Instruct\": { max_tokens: 2048, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 3e-7, output_cost_per_token: 61e-8, litellm_provider: \"azure_ai\", mode: \"chat\", source: \"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-8b-instruct-offer?tab=PlansAndPrice\", supports_tool_choice: !0 },\n  \"azure_ai/Meta-Llama-3.1-70B-Instruct\": { max_tokens: 2048, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 268e-8, output_cost_per_token: 354e-8, litellm_provider: \"azure_ai\", mode: \"chat\", source: \"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-70b-instruct-offer?tab=PlansAndPrice\", supports_tool_choice: !0 },\n  \"azure_ai/Meta-Llama-3.1-405B-Instruct\": { max_tokens: 2048, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 533e-8, output_cost_per_token: 16e-6, litellm_provider: \"azure_ai\", mode: \"chat\", source: \"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-405b-instruct-offer?tab=PlansAndPrice\", supports_tool_choice: !0 },\n  \"azure_ai/Phi-4-mini-instruct\": { max_tokens: 4096, max_input_tokens: 131072, max_output_tokens: 4096, input_cost_per_token: 75e-9, output_cost_per_token: 3e-7, litellm_provider: \"azure_ai\", mode: \"chat\", supports_function_calling: !0, source: \"https://techcommunity.microsoft.com/blog/Azure-AI-Services-blog/announcing-new-phi-pricing-empowering-your-business-with-small-language-models/4395112\" },\n  \"azure_ai/Phi-4-multimodal-instruct\": { max_tokens: 4096, max_input_tokens: 131072, max_output_tokens: 4096, input_cost_per_token: 8e-8, input_cost_per_audio_token: 4e-6, output_cost_per_token: 32e-8, litellm_provider: \"azure_ai\", mode: \"chat\", supports_audio_input: !0, supports_function_calling: !0, supports_vision: !0, source: \"https://techcommunity.microsoft.com/blog/Azure-AI-Services-blog/announcing-new-phi-pricing-empowering-your-business-with-small-language-models/4395112\" },\n  \"azure_ai/Phi-4\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 125e-9, output_cost_per_token: 5e-7, litellm_provider: \"azure_ai\", mode: \"chat\", supports_vision: !1, source: \"https://techcommunity.microsoft.com/blog/machinelearningblog/affordable-innovation-unveiling-the-pricing-of-phi-3-slms-on-models-as-a-service/4156495\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"azure_ai/Phi-3.5-mini-instruct\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 13e-8, output_cost_per_token: 52e-8, litellm_provider: \"azure_ai\", mode: \"chat\", supports_vision: !1, source: \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\", supports_tool_choice: !0 },\n  \"azure_ai/Phi-3.5-vision-instruct\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 13e-8, output_cost_per_token: 52e-8, litellm_provider: \"azure_ai\", mode: \"chat\", supports_vision: !0, source: \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\", supports_tool_choice: !0 },\n  \"azure_ai/Phi-3.5-MoE-instruct\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 16e-8, output_cost_per_token: 64e-8, litellm_provider: \"azure_ai\", mode: \"chat\", supports_vision: !1, source: \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\", supports_tool_choice: !0 },\n  \"azure_ai/Phi-3-mini-4k-instruct\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 13e-8, output_cost_per_token: 52e-8, litellm_provider: \"azure_ai\", mode: \"chat\", supports_vision: !1, source: \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\", supports_tool_choice: !0 },\n  \"azure_ai/Phi-3-mini-128k-instruct\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 13e-8, output_cost_per_token: 52e-8, litellm_provider: \"azure_ai\", mode: \"chat\", supports_vision: !1, source: \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\", supports_tool_choice: !0 },\n  \"azure_ai/Phi-3-small-8k-instruct\": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, litellm_provider: \"azure_ai\", mode: \"chat\", supports_vision: !1, source: \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\", supports_tool_choice: !0 },\n  \"azure_ai/Phi-3-small-128k-instruct\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, litellm_provider: \"azure_ai\", mode: \"chat\", supports_vision: !1, source: \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\", supports_tool_choice: !0 },\n  \"azure_ai/Phi-3-medium-4k-instruct\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 17e-8, output_cost_per_token: 68e-8, litellm_provider: \"azure_ai\", mode: \"chat\", supports_vision: !1, source: \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\", supports_tool_choice: !0 },\n  \"azure_ai/Phi-3-medium-128k-instruct\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 17e-8, output_cost_per_token: 68e-8, litellm_provider: \"azure_ai\", mode: \"chat\", supports_vision: !1, source: \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\", supports_tool_choice: !0 },\n  \"azure_ai/cohere-rerank-v3-multilingual\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, max_query_tokens: 2048, input_cost_per_token: 0, input_cost_per_query: 2e-3, output_cost_per_token: 0, litellm_provider: \"azure_ai\", mode: \"rerank\" },\n  \"azure_ai/cohere-rerank-v3-english\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, max_query_tokens: 2048, input_cost_per_token: 0, input_cost_per_query: 2e-3, output_cost_per_token: 0, litellm_provider: \"azure_ai\", mode: \"rerank\" },\n  \"azure_ai/Cohere-embed-v3-english\": { max_tokens: 512, max_input_tokens: 512, output_vector_size: 1024, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"azure_ai\", mode: \"embedding\", supports_embedding_image_input: !0, source: \"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice\" },\n  \"azure_ai/Cohere-embed-v3-multilingual\": { max_tokens: 512, max_input_tokens: 512, output_vector_size: 1024, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"azure_ai\", mode: \"embedding\", supports_embedding_image_input: !0, source: \"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice\" },\n  \"azure_ai/embed-v-4-0\": { max_tokens: 128e3, max_input_tokens: 128e3, output_vector_size: 3072, input_cost_per_token: 12e-8, output_cost_per_token: 0, litellm_provider: \"azure_ai\", mode: \"embedding\", supports_embedding_image_input: !0, supported_endpoints: [\"/v1/embeddings\"], supported_modalities: [\"text\", \"image\"], source: \"https://azuremarketplace.microsoft.com/pt-br/marketplace/apps/cohere.cohere-embed-4-offer?tab=PlansAndPrice\" },\n  \"babbage-002\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 4096, input_cost_per_token: 4e-7, output_cost_per_token: 4e-7, litellm_provider: \"text-completion-openai\", mode: \"completion\" },\n  \"davinci-002\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 4096, input_cost_per_token: 2e-6, output_cost_per_token: 2e-6, litellm_provider: \"text-completion-openai\", mode: \"completion\" },\n  \"gpt-3.5-turbo-instruct\": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: \"text-completion-openai\", mode: \"completion\" },\n  \"gpt-3.5-turbo-instruct-0914\": { max_tokens: 4097, max_input_tokens: 8192, max_output_tokens: 4097, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: \"text-completion-openai\", mode: \"completion\" },\n  \"claude-instant-1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 163e-8, output_cost_per_token: 551e-8, litellm_provider: \"anthropic\", mode: \"chat\" },\n  \"mistral/mistral-tiny\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 25e-8, output_cost_per_token: 25e-8, litellm_provider: \"mistral\", mode: \"chat\", supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/mistral-small\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 1e-7, output_cost_per_token: 3e-7, litellm_provider: \"mistral\", supports_function_calling: !0, mode: \"chat\", supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/mistral-small-latest\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 1e-7, output_cost_per_token: 3e-7, litellm_provider: \"mistral\", supports_function_calling: !0, mode: \"chat\", supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/mistral-medium\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 27e-7, output_cost_per_token: 81e-7, litellm_provider: \"mistral\", mode: \"chat\", supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/mistral-medium-latest\": { max_tokens: 8191, max_input_tokens: 131072, max_output_tokens: 8191, input_cost_per_token: 4e-7, output_cost_per_token: 2e-6, litellm_provider: \"mistral\", mode: \"chat\", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/mistral-medium-2505\": { max_tokens: 8191, max_input_tokens: 131072, max_output_tokens: 8191, input_cost_per_token: 4e-7, output_cost_per_token: 2e-6, litellm_provider: \"mistral\", mode: \"chat\", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/mistral-medium-2312\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 27e-7, output_cost_per_token: 81e-7, litellm_provider: \"mistral\", mode: \"chat\", supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/mistral-large-latest\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: \"mistral\", mode: \"chat\", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/mistral-large-2411\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: \"mistral\", mode: \"chat\", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/mistral-large-2402\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 4e-6, output_cost_per_token: 12e-6, litellm_provider: \"mistral\", mode: \"chat\", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/mistral-large-2407\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 3e-6, output_cost_per_token: 9e-6, litellm_provider: \"mistral\", mode: \"chat\", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/pixtral-large-latest\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: \"mistral\", mode: \"chat\", supports_function_calling: !0, supports_assistant_prefill: !0, supports_vision: !0, supports_tool_choice: !0 },\n  \"mistral/pixtral-large-2411\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: \"mistral\", mode: \"chat\", supports_function_calling: !0, supports_assistant_prefill: !0, supports_vision: !0, supports_tool_choice: !0 },\n  \"mistral/pixtral-12b-2409\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: \"mistral\", mode: \"chat\", supports_function_calling: !0, supports_assistant_prefill: !0, supports_vision: !0, supports_tool_choice: !0 },\n  \"mistral/open-mistral-7b\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 25e-8, output_cost_per_token: 25e-8, litellm_provider: \"mistral\", mode: \"chat\", supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/open-mixtral-8x7b\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 7e-7, output_cost_per_token: 7e-7, litellm_provider: \"mistral\", mode: \"chat\", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/open-mixtral-8x22b\": { max_tokens: 8191, max_input_tokens: 65336, max_output_tokens: 8191, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: \"mistral\", mode: \"chat\", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/codestral-latest\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 1e-6, output_cost_per_token: 3e-6, litellm_provider: \"mistral\", mode: \"chat\", supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/codestral-2405\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 1e-6, output_cost_per_token: 3e-6, litellm_provider: \"mistral\", mode: \"chat\", supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/open-mistral-nemo\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 3e-7, output_cost_per_token: 3e-7, litellm_provider: \"mistral\", mode: \"chat\", source: \"https://mistral.ai/technology/\", supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/open-mistral-nemo-2407\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 3e-7, output_cost_per_token: 3e-7, litellm_provider: \"mistral\", mode: \"chat\", source: \"https://mistral.ai/technology/\", supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/open-codestral-mamba\": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 25e-8, output_cost_per_token: 25e-8, litellm_provider: \"mistral\", mode: \"chat\", source: \"https://mistral.ai/technology/\", supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/codestral-mamba-latest\": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 25e-8, output_cost_per_token: 25e-8, litellm_provider: \"mistral\", mode: \"chat\", source: \"https://mistral.ai/technology/\", supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/devstral-small-2505\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 1e-7, output_cost_per_token: 3e-7, litellm_provider: \"mistral\", mode: \"chat\", source: \"https://mistral.ai/news/devstral\", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"mistral/magistral-medium-2506\": { max_tokens: 4e4, max_input_tokens: 4e4, max_output_tokens: 4e4, input_cost_per_token: 2e-6, output_cost_per_token: 5e-6, litellm_provider: \"mistral\", mode: \"chat\", source: \"https://mistral.ai/news/magistral\", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0, supports_reasoning: !0 },\n  \"mistral/magistral-small-2506\": { max_tokens: 4e4, max_input_tokens: 4e4, max_output_tokens: 4e4, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"mistral\", mode: \"chat\", source: \"https://mistral.ai/news/magistral\", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0, supports_reasoning: !0 },\n  \"mistral/mistral-embed\": { max_tokens: 8192, max_input_tokens: 8192, input_cost_per_token: 1e-7, litellm_provider: \"mistral\", mode: \"embedding\" },\n  \"deepseek/deepseek-reasoner\": { max_tokens: 8192, max_input_tokens: 65536, max_output_tokens: 8192, input_cost_per_token: 55e-8, input_cost_per_token_cache_hit: 14e-8, output_cost_per_token: 219e-8, litellm_provider: \"deepseek\", mode: \"chat\", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_prompt_caching: !0 },\n  \"deepseek/deepseek-chat\": { max_tokens: 8192, max_input_tokens: 65536, max_output_tokens: 8192, input_cost_per_token: 27e-8, input_cost_per_token_cache_hit: 7e-8, cache_read_input_token_cost: 7e-8, cache_creation_input_token_cost: 0, output_cost_per_token: 11e-7, litellm_provider: \"deepseek\", mode: \"chat\", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0, supports_prompt_caching: !0 },\n  \"codestral/codestral-latest\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"codestral\", mode: \"chat\", source: \"https://docs.mistral.ai/capabilities/code_generation/\", supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"codestral/codestral-2405\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"codestral\", mode: \"chat\", source: \"https://docs.mistral.ai/capabilities/code_generation/\", supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"text-completion-codestral/codestral-latest\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"text-completion-codestral\", mode: \"completion\", source: \"https://docs.mistral.ai/capabilities/code_generation/\" },\n  \"text-completion-codestral/codestral-2405\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"text-completion-codestral\", mode: \"completion\", source: \"https://docs.mistral.ai/capabilities/code_generation/\" },\n  \"xai/grok-beta\": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 5e-6, output_cost_per_token: 15e-6, litellm_provider: \"xai\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_web_search: !0 },\n  \"xai/grok-2-vision-1212\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 2e-6, input_cost_per_image: 2e-6, output_cost_per_token: 1e-5, litellm_provider: \"xai\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_web_search: !0 },\n  \"xai/grok-2-vision-latest\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 2e-6, input_cost_per_image: 2e-6, output_cost_per_token: 1e-5, litellm_provider: \"xai\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_web_search: !0 },\n  \"xai/grok-2-vision\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 2e-6, input_cost_per_image: 2e-6, output_cost_per_token: 1e-5, litellm_provider: \"xai\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_web_search: !0 },\n  \"xai/grok-3\": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"xai\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !1, source: \"https://x.ai/api#pricing\", supports_web_search: !0 },\n  \"xai/grok-3-beta\": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"xai\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !1, source: \"https://x.ai/api#pricing\", supports_web_search: !0 },\n  \"xai/grok-3-fast-beta\": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 5e-6, output_cost_per_token: 25e-6, litellm_provider: \"xai\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !1, source: \"https://x.ai/api#pricing\", supports_web_search: !0 },\n  \"xai/grok-3-fast-latest\": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 5e-6, output_cost_per_token: 25e-6, litellm_provider: \"xai\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !1, source: \"https://x.ai/api#pricing\", supports_web_search: !0 },\n  \"xai/grok-3-mini-beta\": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 3e-7, output_cost_per_token: 5e-7, litellm_provider: \"xai\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_response_schema: !1, source: \"https://x.ai/api#pricing\", supports_web_search: !0 },\n  \"xai/grok-3-mini-fast-beta\": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 6e-7, output_cost_per_token: 4e-6, litellm_provider: \"xai\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_response_schema: !1, source: \"https://x.ai/api#pricing\", supports_web_search: !0 },\n  \"xai/grok-3-mini-fast-latest\": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 6e-7, output_cost_per_token: 4e-6, litellm_provider: \"xai\", mode: \"chat\", supports_reasoning: !0, supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !1, source: \"https://x.ai/api#pricing\", supports_web_search: !0 },\n  \"xai/grok-vision-beta\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 5e-6, input_cost_per_image: 5e-6, output_cost_per_token: 15e-6, litellm_provider: \"xai\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_web_search: !0 },\n  \"xai/grok-2-1212\": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 2e-6, output_cost_per_token: 1e-5, litellm_provider: \"xai\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0, supports_web_search: !0 },\n  \"xai/grok-2\": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 2e-6, output_cost_per_token: 1e-5, litellm_provider: \"xai\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0, supports_web_search: !0 },\n  \"xai/grok-2-latest\": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 2e-6, output_cost_per_token: 1e-5, litellm_provider: \"xai\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0, supports_web_search: !0 },\n  \"deepseek/deepseek-coder\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 14e-8, input_cost_per_token_cache_hit: 14e-9, output_cost_per_token: 28e-8, litellm_provider: \"deepseek\", mode: \"chat\", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0, supports_prompt_caching: !0 },\n  \"groq/deepseek-r1-distill-llama-70b\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 75e-8, output_cost_per_token: 99e-8, litellm_provider: \"groq\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },\n  \"groq/llama-3.3-70b-versatile\": { max_tokens: 32768, max_input_tokens: 128e3, max_output_tokens: 32768, input_cost_per_token: 59e-8, output_cost_per_token: 79e-8, litellm_provider: \"groq\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0 },\n  \"groq/llama-3.3-70b-specdec\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 59e-8, output_cost_per_token: 99e-8, litellm_provider: \"groq\", mode: \"chat\", supports_tool_choice: !0, deprecation_date: \"2025-04-14\" },\n  \"groq/llama-guard-3-8b\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: \"groq\", mode: \"chat\" },\n  \"groq/llama2-70b-4096\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 7e-7, output_cost_per_token: 8e-7, litellm_provider: \"groq\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0 },\n  \"groq/llama3-8b-8192\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 5e-8, output_cost_per_token: 8e-8, litellm_provider: \"groq\", mode: \"chat\", supports_tool_choice: !0 },\n  \"groq/llama-3.2-1b-preview\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 4e-8, output_cost_per_token: 4e-8, litellm_provider: \"groq\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0, deprecation_date: \"2025-04-14\" },\n  \"groq/llama-3.2-3b-preview\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 6e-8, output_cost_per_token: 6e-8, litellm_provider: \"groq\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0, deprecation_date: \"2025-04-14\" },\n  \"groq/llama-3.2-11b-text-preview\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 18e-8, output_cost_per_token: 18e-8, litellm_provider: \"groq\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0, deprecation_date: \"2024-10-28\" },\n  \"groq/llama-3.2-11b-vision-preview\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 18e-8, output_cost_per_token: 18e-8, litellm_provider: \"groq\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_tool_choice: !0, deprecation_date: \"2025-04-14\" },\n  \"groq/llama-3.2-90b-text-preview\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: \"groq\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0, deprecation_date: \"2024-11-25\" },\n  \"groq/llama-3.2-90b-vision-preview\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: \"groq\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_tool_choice: !0, deprecation_date: \"2025-04-14\" },\n  \"groq/llama3-70b-8192\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 59e-8, output_cost_per_token: 79e-8, litellm_provider: \"groq\", mode: \"chat\", supports_response_schema: !0, supports_tool_choice: !0 },\n  \"groq/llama-3.1-8b-instant\": { max_tokens: 8192, max_input_tokens: 128e3, max_output_tokens: 8192, input_cost_per_token: 5e-8, output_cost_per_token: 8e-8, litellm_provider: \"groq\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0 },\n  \"groq/llama-3.1-70b-versatile\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 59e-8, output_cost_per_token: 79e-8, litellm_provider: \"groq\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0, deprecation_date: \"2025-01-24\" },\n  \"groq/llama-3.1-405b-reasoning\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 59e-8, output_cost_per_token: 79e-8, litellm_provider: \"groq\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0 },\n  \"groq/meta-llama/llama-4-scout-17b-16e-instruct\": { max_tokens: 8192, max_input_tokens: 131072, max_output_tokens: 8192, input_cost_per_token: 11e-8, output_cost_per_token: 34e-8, litellm_provider: \"groq\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0 },\n  \"groq/meta-llama/llama-4-maverick-17b-128e-instruct\": { max_tokens: 8192, max_input_tokens: 131072, max_output_tokens: 8192, input_cost_per_token: 2e-7, output_cost_per_token: 6e-7, litellm_provider: \"groq\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0 },\n  \"groq/mistral-saba-24b\": { max_tokens: 32e3, max_input_tokens: 32e3, max_output_tokens: 32e3, input_cost_per_token: 79e-8, output_cost_per_token: 79e-8, litellm_provider: \"groq\", mode: \"chat\" },\n  \"groq/mixtral-8x7b-32768\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 24e-8, output_cost_per_token: 24e-8, litellm_provider: \"groq\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0, deprecation_date: \"2025-03-20\" },\n  \"groq/gemma-7b-it\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 7e-8, output_cost_per_token: 7e-8, litellm_provider: \"groq\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0, deprecation_date: \"2024-12-18\" },\n  \"groq/gemma2-9b-it\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: \"groq\", mode: \"chat\", supports_function_calling: !1, supports_response_schema: !0, supports_tool_choice: !1 },\n  \"groq/llama3-groq-70b-8192-tool-use-preview\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 89e-8, output_cost_per_token: 89e-8, litellm_provider: \"groq\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0, deprecation_date: \"2025-01-06\" },\n  \"groq/llama3-groq-8b-8192-tool-use-preview\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 19e-8, output_cost_per_token: 19e-8, litellm_provider: \"groq\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0, deprecation_date: \"2025-01-06\" },\n  \"groq/qwen-qwq-32b\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 29e-8, output_cost_per_token: 39e-8, litellm_provider: \"groq\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },\n  \"groq/playai-tts\": { max_tokens: 1e4, max_input_tokens: 1e4, max_output_tokens: 1e4, input_cost_per_character: 5e-5, litellm_provider: \"groq\", mode: \"audio_speech\" },\n  \"groq/whisper-large-v3\": { input_cost_per_second: 3083e-8, output_cost_per_second: 0, litellm_provider: \"groq\", mode: \"audio_transcription\" },\n  \"groq/whisper-large-v3-turbo\": { input_cost_per_second: 1111e-8, output_cost_per_second: 0, litellm_provider: \"groq\", mode: \"audio_transcription\" },\n  \"groq/distil-whisper-large-v3-en\": { input_cost_per_second: 556e-8, output_cost_per_second: 0, litellm_provider: \"groq\", mode: \"audio_transcription\" },\n  \"cerebras/llama3.1-8b\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 1e-7, output_cost_per_token: 1e-7, litellm_provider: \"cerebras\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"cerebras/llama3.1-70b\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 6e-7, output_cost_per_token: 6e-7, litellm_provider: \"cerebras\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"cerebras/llama-3.3-70b\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 85e-8, output_cost_per_token: 12e-7, litellm_provider: \"cerebras\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"cerebras/qwen-3-32b\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 4e-7, output_cost_per_token: 8e-7, litellm_provider: \"cerebras\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0, source: \"https://inference-docs.cerebras.ai/support/pricing\" },\n  \"friendliai/meta-llama-3.1-8b-instruct\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 1e-7, output_cost_per_token: 1e-7, litellm_provider: \"friendliai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_system_messages: !0, supports_response_schema: !0, supports_tool_choice: !0 },\n  \"friendliai/meta-llama-3.1-70b-instruct\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 6e-7, output_cost_per_token: 6e-7, litellm_provider: \"friendliai\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_system_messages: !0, supports_response_schema: !0, supports_tool_choice: !0 },\n  \"claude-instant-1.2\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 163e-9, output_cost_per_token: 551e-9, litellm_provider: \"anthropic\", mode: \"chat\", supports_tool_choice: !0 },\n  \"claude-2\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"anthropic\", mode: \"chat\" },\n  \"claude-2.1\": { max_tokens: 8191, max_input_tokens: 2e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"anthropic\", mode: \"chat\", supports_tool_choice: !0 },\n  \"claude-3-haiku-20240307\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 25e-8, output_cost_per_token: 125e-8, cache_creation_input_token_cost: 3e-7, cache_read_input_token_cost: 3e-8, litellm_provider: \"anthropic\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 264, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: \"2025-03-01\", supports_tool_choice: !0 },\n  \"claude-3-5-haiku-20241022\": { max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 8e-7, output_cost_per_token: 4e-6, cache_creation_input_token_cost: 1e-6, cache_read_input_token_cost: 8e-8, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, litellm_provider: \"anthropic\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 264, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: \"2025-10-01\", supports_tool_choice: !0, supports_web_search: !0 },\n  \"claude-3-5-haiku-latest\": { max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 1e-6, output_cost_per_token: 5e-6, cache_creation_input_token_cost: 125e-8, cache_read_input_token_cost: 1e-7, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, litellm_provider: \"anthropic\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 264, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: \"2025-10-01\", supports_tool_choice: !0, supports_web_search: !0 },\n  \"claude-3-opus-latest\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, cache_creation_input_token_cost: 1875e-8, cache_read_input_token_cost: 15e-7, litellm_provider: \"anthropic\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 395, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: \"2025-03-01\", supports_tool_choice: !0 },\n  \"claude-3-opus-20240229\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, cache_creation_input_token_cost: 1875e-8, cache_read_input_token_cost: 15e-7, litellm_provider: \"anthropic\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 395, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: \"2025-03-01\", supports_tool_choice: !0 },\n  \"claude-3-sonnet-20240229\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"anthropic\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: \"2025-07-21\", supports_tool_choice: !0 },\n  \"claude-3-5-sonnet-latest\": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, litellm_provider: \"anthropic\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: \"2025-06-01\", supports_tool_choice: !0, supports_web_search: !0 },\n  \"claude-3-5-sonnet-20240620\": { max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: \"anthropic\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: \"2025-06-01\", supports_tool_choice: !0 },\n  \"claude-opus-4-20250514\": { max_tokens: 32e3, max_input_tokens: 2e5, max_output_tokens: 32e3, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 1875e-8, cache_read_input_token_cost: 15e-7, litellm_provider: \"anthropic\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },\n  \"claude-sonnet-4-20250514\": { max_tokens: 64e3, max_input_tokens: 2e5, max_output_tokens: 64e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: \"anthropic\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },\n  \"claude-4-opus-20250514\": { max_tokens: 32e3, max_input_tokens: 2e5, max_output_tokens: 32e3, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 1875e-8, cache_read_input_token_cost: 15e-7, litellm_provider: \"anthropic\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },\n  \"claude-4-sonnet-20250514\": { max_tokens: 64e3, max_input_tokens: 2e5, max_output_tokens: 64e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: \"anthropic\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },\n  \"claude-3-7-sonnet-latest\": { supports_computer_use: !0, max_tokens: 128e3, max_input_tokens: 2e5, max_output_tokens: 128e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: \"anthropic\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: \"2025-06-01\", supports_tool_choice: !0, supports_reasoning: !0 },\n  \"claude-3-7-sonnet-20250219\": { supports_computer_use: !0, max_tokens: 128e3, max_input_tokens: 2e5, max_output_tokens: 128e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, litellm_provider: \"anthropic\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: \"2026-02-01\", supports_tool_choice: !0, supports_reasoning: !0, supports_web_search: !0 },\n  \"claude-3-5-sonnet-20241022\": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, litellm_provider: \"anthropic\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: \"2025-10-01\", supports_tool_choice: !0, supports_web_search: !0 },\n  \"text-bison\": { max_tokens: 2048, max_input_tokens: 8192, max_output_tokens: 2048, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-text-models\", mode: \"completion\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"text-bison@001\": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-text-models\", mode: \"completion\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"text-bison@002\": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-text-models\", mode: \"completion\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"text-bison32k\": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-text-models\", mode: \"completion\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"text-bison32k@002\": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-text-models\", mode: \"completion\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"text-unicorn\": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 1e-5, output_cost_per_token: 28e-6, litellm_provider: \"vertex_ai-text-models\", mode: \"completion\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"text-unicorn@001\": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 1e-5, output_cost_per_token: 28e-6, litellm_provider: \"vertex_ai-text-models\", mode: \"completion\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"chat-bison\": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-chat-models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0 },\n  \"chat-bison@001\": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-chat-models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0 },\n  \"chat-bison@002\": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-chat-models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", deprecation_date: \"2025-04-09\", supports_tool_choice: !0 },\n  \"chat-bison-32k\": { max_tokens: 8192, max_input_tokens: 32e3, max_output_tokens: 8192, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-chat-models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0 },\n  \"chat-bison-32k@002\": { max_tokens: 8192, max_input_tokens: 32e3, max_output_tokens: 8192, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-chat-models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0 },\n  \"code-bison\": { max_tokens: 1024, max_input_tokens: 6144, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-code-text-models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0 },\n  \"code-bison@001\": { max_tokens: 1024, max_input_tokens: 6144, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-code-text-models\", mode: \"completion\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"code-bison@002\": { max_tokens: 1024, max_input_tokens: 6144, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-code-text-models\", mode: \"completion\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"code-bison32k\": { max_tokens: 1024, max_input_tokens: 6144, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-code-text-models\", mode: \"completion\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"code-bison-32k@002\": { max_tokens: 1024, max_input_tokens: 6144, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-code-text-models\", mode: \"completion\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"code-gecko@001\": { max_tokens: 64, max_input_tokens: 2048, max_output_tokens: 64, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, litellm_provider: \"vertex_ai-code-text-models\", mode: \"completion\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"code-gecko@002\": { max_tokens: 64, max_input_tokens: 2048, max_output_tokens: 64, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, litellm_provider: \"vertex_ai-code-text-models\", mode: \"completion\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"code-gecko\": { max_tokens: 64, max_input_tokens: 2048, max_output_tokens: 64, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, litellm_provider: \"vertex_ai-code-text-models\", mode: \"completion\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"code-gecko-latest\": { max_tokens: 64, max_input_tokens: 2048, max_output_tokens: 64, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, litellm_provider: \"vertex_ai-code-text-models\", mode: \"completion\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"codechat-bison@latest\": { max_tokens: 1024, max_input_tokens: 6144, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-code-chat-models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0 },\n  \"codechat-bison\": { max_tokens: 1024, max_input_tokens: 6144, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-code-chat-models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0 },\n  \"codechat-bison@001\": { max_tokens: 1024, max_input_tokens: 6144, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-code-chat-models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0 },\n  \"codechat-bison@002\": { max_tokens: 1024, max_input_tokens: 6144, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-code-chat-models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0 },\n  \"codechat-bison-32k\": { max_tokens: 8192, max_input_tokens: 32e3, max_output_tokens: 8192, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-code-chat-models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0 },\n  \"codechat-bison-32k@002\": { max_tokens: 8192, max_input_tokens: 32e3, max_output_tokens: 8192, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: \"vertex_ai-code-chat-models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0 },\n  \"meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8\": { max_tokens: 128e3, max_input_tokens: 1e7, max_output_tokens: 4028, litellm_provider: \"meta_llama\", mode: \"chat\", supports_function_calling: !1, source: \"https://llama.developer.meta.com/docs/models\", supports_tool_choice: !1, supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"] },\n  \"meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8\": { max_tokens: 128e3, max_input_tokens: 1e6, max_output_tokens: 4028, litellm_provider: \"meta_llama\", mode: \"chat\", supports_function_calling: !1, source: \"https://llama.developer.meta.com/docs/models\", supports_tool_choice: !1, supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\"] },\n  \"meta_llama/Llama-3.3-70B-Instruct\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4028, litellm_provider: \"meta_llama\", mode: \"chat\", supports_function_calling: !1, source: \"https://llama.developer.meta.com/docs/models\", supports_tool_choice: !1, supported_modalities: [\"text\"], supported_output_modalities: [\"text\"] },\n  \"meta_llama/Llama-3.3-8B-Instruct\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4028, litellm_provider: \"meta_llama\", mode: \"chat\", supports_function_calling: !1, source: \"https://llama.developer.meta.com/docs/models\", supports_tool_choice: !1, supported_modalities: [\"text\"], supported_output_modalities: [\"text\"] },\n  \"gemini-pro\": { max_tokens: 8192, max_input_tokens: 32760, max_output_tokens: 8192, input_cost_per_image: 25e-4, input_cost_per_video_per_second: 2e-3, input_cost_per_token: 5e-7, input_cost_per_character: 125e-9, output_cost_per_token: 15e-7, output_cost_per_character: 375e-9, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/pricing\", supports_tool_choice: !0 },\n  \"gemini-1.0-pro\": { max_tokens: 8192, max_input_tokens: 32760, max_output_tokens: 8192, input_cost_per_image: 25e-4, input_cost_per_video_per_second: 2e-3, input_cost_per_token: 5e-7, input_cost_per_character: 125e-9, output_cost_per_token: 15e-7, output_cost_per_character: 375e-9, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/pricing#google_models\", supports_tool_choice: !0 },\n  \"gemini-1.0-pro-001\": { max_tokens: 8192, max_input_tokens: 32760, max_output_tokens: 8192, input_cost_per_image: 25e-4, input_cost_per_video_per_second: 2e-3, input_cost_per_token: 5e-7, input_cost_per_character: 125e-9, output_cost_per_token: 15e-7, output_cost_per_character: 375e-9, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_function_calling: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", deprecation_date: \"2025-04-09\", supports_tool_choice: !0, supports_parallel_function_calling: !0 },\n  \"gemini-1.0-ultra\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 2048, input_cost_per_image: 25e-4, input_cost_per_video_per_second: 2e-3, input_cost_per_token: 5e-7, input_cost_per_character: 125e-9, output_cost_per_token: 15e-7, output_cost_per_character: 375e-9, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_function_calling: !0, source: \"As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0, supports_parallel_function_calling: !0 },\n  \"gemini-1.0-ultra-001\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 2048, input_cost_per_image: 25e-4, input_cost_per_video_per_second: 2e-3, input_cost_per_token: 5e-7, input_cost_per_character: 125e-9, output_cost_per_token: 15e-7, output_cost_per_character: 375e-9, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_function_calling: !0, source: \"As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0, supports_parallel_function_calling: !0 },\n  \"gemini-1.0-pro-002\": { max_tokens: 8192, max_input_tokens: 32760, max_output_tokens: 8192, input_cost_per_image: 25e-4, input_cost_per_video_per_second: 2e-3, input_cost_per_token: 5e-7, input_cost_per_character: 125e-9, output_cost_per_token: 15e-7, output_cost_per_character: 375e-9, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_function_calling: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", deprecation_date: \"2025-04-09\", supports_tool_choice: !0, supports_parallel_function_calling: !0 },\n  \"gemini-1.5-pro\": { max_tokens: 8192, max_input_tokens: 2097152, max_output_tokens: 8192, input_cost_per_image: 32875e-8, input_cost_per_audio_per_second: 3125e-8, input_cost_per_video_per_second: 32875e-8, input_cost_per_token: 125e-8, input_cost_per_character: 3125e-10, input_cost_per_image_above_128k_tokens: 6575e-7, input_cost_per_video_per_second_above_128k_tokens: 6575e-7, input_cost_per_audio_per_second_above_128k_tokens: 625e-7, input_cost_per_token_above_128k_tokens: 25e-7, input_cost_per_character_above_128k_tokens: 625e-9, output_cost_per_token: 5e-6, output_cost_per_character: 125e-8, output_cost_per_token_above_128k_tokens: 1e-5, output_cost_per_character_above_128k_tokens: 25e-7, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_vision: !0, supports_pdf_input: !0, supports_system_messages: !0, supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_parallel_function_calling: !0 },\n  \"gemini-1.5-pro-002\": { max_tokens: 8192, max_input_tokens: 2097152, max_output_tokens: 8192, input_cost_per_image: 32875e-8, input_cost_per_audio_per_second: 3125e-8, input_cost_per_video_per_second: 32875e-8, input_cost_per_token: 125e-8, input_cost_per_character: 3125e-10, input_cost_per_image_above_128k_tokens: 6575e-7, input_cost_per_video_per_second_above_128k_tokens: 6575e-7, input_cost_per_audio_per_second_above_128k_tokens: 625e-7, input_cost_per_token_above_128k_tokens: 25e-7, input_cost_per_character_above_128k_tokens: 625e-9, output_cost_per_token: 5e-6, output_cost_per_character: 125e-8, output_cost_per_token_above_128k_tokens: 1e-5, output_cost_per_character_above_128k_tokens: 25e-7, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_vision: !0, supports_system_messages: !0, supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-pro\", deprecation_date: \"2025-09-24\", supports_parallel_function_calling: !0 },\n  \"gemini-1.5-pro-001\": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, input_cost_per_image: 32875e-8, input_cost_per_audio_per_second: 3125e-8, input_cost_per_video_per_second: 32875e-8, input_cost_per_token: 125e-8, input_cost_per_character: 3125e-10, input_cost_per_image_above_128k_tokens: 6575e-7, input_cost_per_video_per_second_above_128k_tokens: 6575e-7, input_cost_per_audio_per_second_above_128k_tokens: 625e-7, input_cost_per_token_above_128k_tokens: 25e-7, input_cost_per_character_above_128k_tokens: 625e-9, output_cost_per_token: 5e-6, output_cost_per_character: 125e-8, output_cost_per_token_above_128k_tokens: 1e-5, output_cost_per_character_above_128k_tokens: 25e-7, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_vision: !0, supports_system_messages: !0, supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", deprecation_date: \"2025-05-24\", supports_parallel_function_calling: !0 },\n  \"gemini-1.5-pro-preview-0514\": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, input_cost_per_image: 32875e-8, input_cost_per_audio_per_second: 3125e-8, input_cost_per_video_per_second: 32875e-8, input_cost_per_token: 78125e-12, input_cost_per_character: 3125e-10, input_cost_per_image_above_128k_tokens: 6575e-7, input_cost_per_video_per_second_above_128k_tokens: 6575e-7, input_cost_per_audio_per_second_above_128k_tokens: 625e-7, input_cost_per_token_above_128k_tokens: 15625e-11, input_cost_per_character_above_128k_tokens: 625e-9, output_cost_per_token: 3125e-10, output_cost_per_character: 125e-8, output_cost_per_token_above_128k_tokens: 625e-9, output_cost_per_character_above_128k_tokens: 25e-7, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_parallel_function_calling: !0 },\n  \"gemini-1.5-pro-preview-0215\": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, input_cost_per_image: 32875e-8, input_cost_per_audio_per_second: 3125e-8, input_cost_per_video_per_second: 32875e-8, input_cost_per_token: 78125e-12, input_cost_per_character: 3125e-10, input_cost_per_image_above_128k_tokens: 6575e-7, input_cost_per_video_per_second_above_128k_tokens: 6575e-7, input_cost_per_audio_per_second_above_128k_tokens: 625e-7, input_cost_per_token_above_128k_tokens: 15625e-11, input_cost_per_character_above_128k_tokens: 625e-9, output_cost_per_token: 3125e-10, output_cost_per_character: 125e-8, output_cost_per_token_above_128k_tokens: 625e-9, output_cost_per_character_above_128k_tokens: 25e-7, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_parallel_function_calling: !0 },\n  \"gemini-1.5-pro-preview-0409\": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, input_cost_per_image: 32875e-8, input_cost_per_audio_per_second: 3125e-8, input_cost_per_video_per_second: 32875e-8, input_cost_per_token: 78125e-12, input_cost_per_character: 3125e-10, input_cost_per_image_above_128k_tokens: 6575e-7, input_cost_per_video_per_second_above_128k_tokens: 6575e-7, input_cost_per_audio_per_second_above_128k_tokens: 625e-7, input_cost_per_token_above_128k_tokens: 15625e-11, input_cost_per_character_above_128k_tokens: 625e-9, output_cost_per_token: 3125e-10, output_cost_per_character: 125e-8, output_cost_per_token_above_128k_tokens: 625e-9, output_cost_per_character_above_128k_tokens: 25e-7, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_parallel_function_calling: !0 },\n  \"gemini-1.5-flash\": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 2e-5, input_cost_per_video_per_second: 2e-5, input_cost_per_audio_per_second: 2e-6, input_cost_per_token: 75e-9, input_cost_per_character: 1875e-11, input_cost_per_token_above_128k_tokens: 1e-6, input_cost_per_character_above_128k_tokens: 25e-8, input_cost_per_image_above_128k_tokens: 4e-5, input_cost_per_video_per_second_above_128k_tokens: 4e-5, input_cost_per_audio_per_second_above_128k_tokens: 4e-6, output_cost_per_token: 3e-7, output_cost_per_character: 75e-9, output_cost_per_token_above_128k_tokens: 6e-7, output_cost_per_character_above_128k_tokens: 15e-8, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0, supports_parallel_function_calling: !0 },\n  \"gemini-1.5-flash-exp-0827\": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 2e-5, input_cost_per_video_per_second: 2e-5, input_cost_per_audio_per_second: 2e-6, input_cost_per_token: 4688e-12, input_cost_per_character: 1875e-11, input_cost_per_token_above_128k_tokens: 1e-6, input_cost_per_character_above_128k_tokens: 25e-8, input_cost_per_image_above_128k_tokens: 4e-5, input_cost_per_video_per_second_above_128k_tokens: 4e-5, input_cost_per_audio_per_second_above_128k_tokens: 4e-6, output_cost_per_token: 46875e-13, output_cost_per_character: 1875e-11, output_cost_per_token_above_128k_tokens: 9375e-12, output_cost_per_character_above_128k_tokens: 375e-10, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0, supports_parallel_function_calling: !0 },\n  \"gemini-1.5-flash-002\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 2e-5, input_cost_per_video_per_second: 2e-5, input_cost_per_audio_per_second: 2e-6, input_cost_per_token: 75e-9, input_cost_per_character: 1875e-11, input_cost_per_token_above_128k_tokens: 1e-6, input_cost_per_character_above_128k_tokens: 25e-8, input_cost_per_image_above_128k_tokens: 4e-5, input_cost_per_video_per_second_above_128k_tokens: 4e-5, input_cost_per_audio_per_second_above_128k_tokens: 4e-6, output_cost_per_token: 3e-7, output_cost_per_character: 75e-9, output_cost_per_token_above_128k_tokens: 6e-7, output_cost_per_character_above_128k_tokens: 15e-8, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-flash\", deprecation_date: \"2025-09-24\", supports_tool_choice: !0, supports_parallel_function_calling: !0 },\n  \"gemini-1.5-flash-001\": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 2e-5, input_cost_per_video_per_second: 2e-5, input_cost_per_audio_per_second: 2e-6, input_cost_per_token: 75e-9, input_cost_per_character: 1875e-11, input_cost_per_token_above_128k_tokens: 1e-6, input_cost_per_character_above_128k_tokens: 25e-8, input_cost_per_image_above_128k_tokens: 4e-5, input_cost_per_video_per_second_above_128k_tokens: 4e-5, input_cost_per_audio_per_second_above_128k_tokens: 4e-6, output_cost_per_token: 3e-7, output_cost_per_character: 75e-9, output_cost_per_token_above_128k_tokens: 6e-7, output_cost_per_character_above_128k_tokens: 15e-8, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", deprecation_date: \"2025-05-24\", supports_tool_choice: !0, supports_parallel_function_calling: !0 },\n  \"gemini-1.5-flash-preview-0514\": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 2e-5, input_cost_per_video_per_second: 2e-5, input_cost_per_audio_per_second: 2e-6, input_cost_per_token: 75e-9, input_cost_per_character: 1875e-11, input_cost_per_token_above_128k_tokens: 1e-6, input_cost_per_character_above_128k_tokens: 25e-8, input_cost_per_image_above_128k_tokens: 4e-5, input_cost_per_video_per_second_above_128k_tokens: 4e-5, input_cost_per_audio_per_second_above_128k_tokens: 4e-6, output_cost_per_token: 46875e-13, output_cost_per_character: 1875e-11, output_cost_per_token_above_128k_tokens: 9375e-12, output_cost_per_character_above_128k_tokens: 375e-10, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0, supports_parallel_function_calling: !0 },\n  \"gemini-pro-experimental\": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, input_cost_per_character: 0, output_cost_per_character: 0, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_function_calling: !1, supports_tool_choice: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental\", supports_parallel_function_calling: !0 },\n  \"gemini-flash-experimental\": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, input_cost_per_character: 0, output_cost_per_character: 0, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_function_calling: !1, supports_tool_choice: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental\", supports_parallel_function_calling: !0 },\n  \"gemini-pro-vision\": { max_tokens: 2048, max_input_tokens: 16384, max_output_tokens: 2048, max_images_per_prompt: 16, max_videos_per_prompt: 1, max_video_length: 2, input_cost_per_token: 5e-7, output_cost_per_token: 15e-7, input_cost_per_image: 25e-4, litellm_provider: \"vertex_ai-vision-models\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0, supports_parallel_function_calling: !0 },\n  \"gemini-1.0-pro-vision\": { max_tokens: 2048, max_input_tokens: 16384, max_output_tokens: 2048, max_images_per_prompt: 16, max_videos_per_prompt: 1, max_video_length: 2, input_cost_per_token: 5e-7, output_cost_per_token: 15e-7, input_cost_per_image: 25e-4, litellm_provider: \"vertex_ai-vision-models\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0, supports_parallel_function_calling: !0 },\n  \"gemini-1.0-pro-vision-001\": { max_tokens: 2048, max_input_tokens: 16384, max_output_tokens: 2048, max_images_per_prompt: 16, max_videos_per_prompt: 1, max_video_length: 2, input_cost_per_token: 5e-7, output_cost_per_token: 15e-7, input_cost_per_image: 25e-4, litellm_provider: \"vertex_ai-vision-models\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", deprecation_date: \"2025-04-09\", supports_tool_choice: !0, supports_parallel_function_calling: !0 },\n  \"medlm-medium\": { max_tokens: 8192, max_input_tokens: 32768, max_output_tokens: 8192, input_cost_per_character: 5e-7, output_cost_per_character: 1e-6, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0 },\n  \"medlm-large\": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_character: 5e-6, output_cost_per_character: 15e-6, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0 },\n  \"gemini-2.5-pro-exp-03-25\": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 125e-8, input_cost_per_token_above_200k_tokens: 25e-7, output_cost_per_token: 1e-5, output_cost_per_token_above_200k_tokens: 15e-6, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_audio_input: !0, supports_video_input: !0, supports_pdf_input: !0, supports_response_schema: !0, supports_tool_choice: !0, supported_endpoints: [\"/v1/chat/completions\", \"/v1/completions\"], supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\"], source: \"https://cloud.google.com/vertex-ai/generative-ai/pricing\", supports_parallel_function_calling: !0, supports_web_search: !0 },\n  \"gemini-2.0-pro-exp-02-05\": { max_tokens: 8192, max_input_tokens: 2097152, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 125e-8, input_cost_per_token_above_200k_tokens: 25e-7, output_cost_per_token: 1e-5, output_cost_per_token_above_200k_tokens: 15e-6, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_audio_input: !0, supports_video_input: !0, supports_pdf_input: !0, supports_response_schema: !0, supports_tool_choice: !0, supported_endpoints: [\"/v1/chat/completions\", \"/v1/completions\"], supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\"], source: \"https://cloud.google.com/vertex-ai/generative-ai/pricing\", supports_parallel_function_calling: !0, supports_web_search: !0 },\n  \"gemini-2.0-flash-exp\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 0, input_cost_per_video_per_second: 0, input_cost_per_audio_per_second: 0, input_cost_per_token: 15e-8, input_cost_per_character: 0, input_cost_per_token_above_128k_tokens: 0, input_cost_per_character_above_128k_tokens: 0, input_cost_per_image_above_128k_tokens: 0, input_cost_per_video_per_second_above_128k_tokens: 0, input_cost_per_audio_per_second_above_128k_tokens: 0, output_cost_per_token: 6e-7, output_cost_per_character: 0, output_cost_per_token_above_128k_tokens: 0, output_cost_per_character_above_128k_tokens: 0, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\", \"image\"], source: \"https://cloud.google.com/vertex-ai/generative-ai/pricing\", supports_tool_choice: !0, supports_parallel_function_calling: !0, supports_web_search: !0 },\n  \"gemini-2.0-flash-001\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 1e-6, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supports_tool_choice: !0, supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\", \"image\"], source: \"https://cloud.google.com/vertex-ai/generative-ai/pricing\", deprecation_date: \"2026-02-05\", supports_parallel_function_calling: !0, supports_web_search: !0 },\n  \"gemini-2.0-flash-thinking-exp\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 0, input_cost_per_video_per_second: 0, input_cost_per_audio_per_second: 0, input_cost_per_token: 0, input_cost_per_character: 0, input_cost_per_token_above_128k_tokens: 0, input_cost_per_character_above_128k_tokens: 0, input_cost_per_image_above_128k_tokens: 0, input_cost_per_video_per_second_above_128k_tokens: 0, input_cost_per_audio_per_second_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_character: 0, output_cost_per_token_above_128k_tokens: 0, output_cost_per_character_above_128k_tokens: 0, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\", \"image\"], source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\", supports_tool_choice: !0, supports_parallel_function_calling: !0, supports_web_search: !0 },\n  \"gemini-2.0-flash-thinking-exp-01-21\": { max_tokens: 65536, max_input_tokens: 1048576, max_output_tokens: 65536, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 0, input_cost_per_video_per_second: 0, input_cost_per_audio_per_second: 0, input_cost_per_token: 0, input_cost_per_character: 0, input_cost_per_token_above_128k_tokens: 0, input_cost_per_character_above_128k_tokens: 0, input_cost_per_image_above_128k_tokens: 0, input_cost_per_video_per_second_above_128k_tokens: 0, input_cost_per_audio_per_second_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_character: 0, output_cost_per_token_above_128k_tokens: 0, output_cost_per_character_above_128k_tokens: 0, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !1, supports_vision: !0, supports_response_schema: !1, supports_audio_output: !1, supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\", \"image\"], source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\", supports_tool_choice: !0, supports_parallel_function_calling: !0, supports_web_search: !0 },\n  \"gemini/gemini-2.5-pro-exp-03-25\": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 0, input_cost_per_token_above_200k_tokens: 0, output_cost_per_token: 0, output_cost_per_token_above_200k_tokens: 0, litellm_provider: \"gemini\", mode: \"chat\", rpm: 5, tpm: 25e4, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_audio_input: !0, supports_video_input: !0, supports_pdf_input: !0, supports_response_schema: !0, supports_tool_choice: !0, supported_endpoints: [\"/v1/chat/completions\", \"/v1/completions\"], supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\"], source: \"https://cloud.google.com/vertex-ai/generative-ai/pricing\", supports_web_search: !0 },\n  \"gemini/gemini-2.5-flash-preview-tts\": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 1e-6, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, output_cost_per_reasoning_token: 35e-7, litellm_provider: \"gemini\", mode: \"chat\", rpm: 10, tpm: 25e4, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_reasoning: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_endpoints: [\"/v1/chat/completions\", \"/v1/completions\"], supported_modalities: [\"text\"], supported_output_modalities: [\"audio\"], source: \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\", supports_web_search: !0 },\n  \"gemini/gemini-2.5-flash-preview-05-20\": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 1e-6, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, output_cost_per_reasoning_token: 35e-7, litellm_provider: \"gemini\", mode: \"chat\", rpm: 10, tpm: 25e4, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_reasoning: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_endpoints: [\"/v1/chat/completions\", \"/v1/completions\"], supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\"], source: \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\", supports_web_search: !0, supports_url_context: !0 },\n  \"gemini/gemini-2.5-flash-preview-04-17\": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 1e-6, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, output_cost_per_reasoning_token: 35e-7, litellm_provider: \"gemini\", mode: \"chat\", rpm: 10, tpm: 25e4, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_reasoning: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_endpoints: [\"/v1/chat/completions\", \"/v1/completions\"], supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\"], source: \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\", supports_web_search: !0 },\n  \"gemini-2.5-flash-preview-05-20\": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 1e-6, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, output_cost_per_reasoning_token: 35e-7, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_reasoning: !0, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_endpoints: [\"/v1/chat/completions\", \"/v1/completions\", \"/v1/batch\"], supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\"], source: \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\", supports_parallel_function_calling: !0, supports_web_search: !0, supports_url_context: !0 },\n  \"gemini-2.5-flash-preview-04-17\": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 1e-6, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, output_cost_per_reasoning_token: 35e-7, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_reasoning: !0, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_endpoints: [\"/v1/chat/completions\", \"/v1/completions\", \"/v1/batch\"], supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\"], source: \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\", supports_parallel_function_calling: !0, supports_web_search: !0 },\n  \"gemini-2.0-flash\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 1e-7, output_cost_per_token: 4e-7, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supports_audio_input: !0, supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\", \"image\"], supports_tool_choice: !0, source: \"https://ai.google.dev/pricing#2_0flash\", supports_parallel_function_calling: !0, supports_web_search: !0, supports_url_context: !0 },\n  \"gemini-2.0-flash-lite\": { max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 50, input_cost_per_audio_token: 75e-9, input_cost_per_token: 75e-9, output_cost_per_token: 3e-7, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\"], source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\", supports_tool_choice: !0, supports_parallel_function_calling: !0, supports_web_search: !0 },\n  \"gemini-2.0-flash-lite-001\": { max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 50, input_cost_per_audio_token: 75e-9, input_cost_per_token: 75e-9, output_cost_per_token: 3e-7, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\"], source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\", supports_tool_choice: !0, deprecation_date: \"2026-02-25\", supports_parallel_function_calling: !0, supports_web_search: !0 },\n  \"gemini-2.5-pro-preview-06-05\": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 125e-8, input_cost_per_token: 125e-8, input_cost_per_token_above_200k_tokens: 25e-7, output_cost_per_token: 1e-5, output_cost_per_token_above_200k_tokens: 15e-6, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_reasoning: !0, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_endpoints: [\"/v1/chat/completions\", \"/v1/completions\", \"/v1/batch\"], supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\"], source: \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\", supports_parallel_function_calling: !0, supports_web_search: !0 },\n  \"gemini-2.5-pro-preview-05-06\": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 125e-8, input_cost_per_token: 125e-8, input_cost_per_token_above_200k_tokens: 25e-7, output_cost_per_token: 1e-5, output_cost_per_token_above_200k_tokens: 15e-6, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_reasoning: !0, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_endpoints: [\"/v1/chat/completions\", \"/v1/completions\", \"/v1/batch\"], supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\"], supported_regions: [\"global\"], source: \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\", supports_parallel_function_calling: !0, supports_web_search: !0 },\n  \"gemini-2.5-pro-preview-03-25\": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 125e-8, input_cost_per_token: 125e-8, input_cost_per_token_above_200k_tokens: 25e-7, output_cost_per_token: 1e-5, output_cost_per_token_above_200k_tokens: 15e-6, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_reasoning: !0, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_endpoints: [\"/v1/chat/completions\", \"/v1/completions\", \"/v1/batch\"], supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\"], source: \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\", supports_parallel_function_calling: !0, supports_web_search: !0 },\n  \"gemini-2.0-flash-preview-image-generation\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 1e-7, output_cost_per_token: 4e-7, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supports_audio_input: !0, supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\", \"image\"], supports_tool_choice: !0, source: \"https://ai.google.dev/pricing#2_0flash\", supports_parallel_function_calling: !0, supports_web_search: !0 },\n  \"gemini-2.5-pro-preview-tts\": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 125e-8, input_cost_per_token_above_200k_tokens: 25e-7, output_cost_per_token: 1e-5, output_cost_per_token_above_200k_tokens: 15e-6, litellm_provider: \"vertex_ai-language-models\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_modalities: [\"text\"], supported_output_modalities: [\"audio\"], source: \"https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview\", supports_parallel_function_calling: !0, supports_web_search: !0 },\n  \"gemini/gemini-2.0-pro-exp-02-05\": { max_tokens: 8192, max_input_tokens: 2097152, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 0, input_cost_per_video_per_second: 0, input_cost_per_audio_per_second: 0, input_cost_per_token: 0, input_cost_per_character: 0, input_cost_per_token_above_128k_tokens: 0, input_cost_per_character_above_128k_tokens: 0, input_cost_per_image_above_128k_tokens: 0, input_cost_per_video_per_second_above_128k_tokens: 0, input_cost_per_audio_per_second_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_character: 0, output_cost_per_token_above_128k_tokens: 0, output_cost_per_character_above_128k_tokens: 0, litellm_provider: \"gemini\", mode: \"chat\", rpm: 2, tpm: 1e6, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_audio_input: !0, supports_video_input: !0, supports_pdf_input: !0, supports_response_schema: !0, supports_tool_choice: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/pricing\", supports_web_search: !0 },\n  \"gemini/gemini-2.0-flash-preview-image-generation\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 1e-7, output_cost_per_token: 4e-7, litellm_provider: \"gemini\", mode: \"chat\", rpm: 1e4, tpm: 1e7, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supports_audio_input: !0, supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\", \"image\"], supports_tool_choice: !0, source: \"https://ai.google.dev/pricing#2_0flash\", supports_web_search: !0 },\n  \"gemini/gemini-2.0-flash\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 1e-7, output_cost_per_token: 4e-7, litellm_provider: \"gemini\", mode: \"chat\", rpm: 1e4, tpm: 1e7, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supports_audio_input: !0, supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\", \"image\"], supports_tool_choice: !0, source: \"https://ai.google.dev/pricing#2_0flash\", supports_web_search: !0, supports_url_context: !0 },\n  \"gemini/gemini-2.0-flash-lite\": { max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 50, input_cost_per_audio_token: 75e-9, input_cost_per_token: 75e-9, output_cost_per_token: 3e-7, litellm_provider: \"gemini\", mode: \"chat\", tpm: 4e6, rpm: 4e3, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supports_tool_choice: !0, supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\"], source: \"https://ai.google.dev/gemini-api/docs/pricing#gemini-2.0-flash-lite\", supports_web_search: !0 },\n  \"gemini/gemini-2.0-flash-001\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 1e-7, output_cost_per_token: 4e-7, litellm_provider: \"gemini\", mode: \"chat\", rpm: 1e4, tpm: 1e7, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\", \"image\"], source: \"https://ai.google.dev/pricing#2_0flash\", supports_web_search: !0 },\n  \"gemini/gemini-2.5-pro-preview-tts\": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 125e-8, input_cost_per_token_above_200k_tokens: 25e-7, output_cost_per_token: 1e-5, output_cost_per_token_above_200k_tokens: 15e-6, litellm_provider: \"gemini\", mode: \"chat\", rpm: 1e4, tpm: 1e7, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_modalities: [\"text\"], supported_output_modalities: [\"audio\"], source: \"https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview\", supports_web_search: !0 },\n  \"gemini/gemini-2.5-pro-preview-06-05\": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 125e-8, input_cost_per_token_above_200k_tokens: 25e-7, output_cost_per_token: 1e-5, output_cost_per_token_above_200k_tokens: 15e-6, litellm_provider: \"gemini\", mode: \"chat\", rpm: 1e4, tpm: 1e7, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\"], source: \"https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview\", supports_web_search: !0, supports_url_context: !0 },\n  \"gemini/gemini-2.5-pro-preview-05-06\": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 125e-8, input_cost_per_token_above_200k_tokens: 25e-7, output_cost_per_token: 1e-5, output_cost_per_token_above_200k_tokens: 15e-6, litellm_provider: \"gemini\", mode: \"chat\", rpm: 1e4, tpm: 1e7, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\"], source: \"https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview\", supports_web_search: !0, supports_url_context: !0 },\n  \"gemini/gemini-2.5-pro-preview-03-25\": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 125e-8, input_cost_per_token_above_200k_tokens: 25e-7, output_cost_per_token: 1e-5, output_cost_per_token_above_200k_tokens: 15e-6, litellm_provider: \"gemini\", mode: \"chat\", rpm: 1e4, tpm: 1e7, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\"], source: \"https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview\", supports_web_search: !0 },\n  \"gemini/gemini-2.0-flash-exp\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 0, input_cost_per_video_per_second: 0, input_cost_per_audio_per_second: 0, input_cost_per_token: 0, input_cost_per_character: 0, input_cost_per_token_above_128k_tokens: 0, input_cost_per_character_above_128k_tokens: 0, input_cost_per_image_above_128k_tokens: 0, input_cost_per_video_per_second_above_128k_tokens: 0, input_cost_per_audio_per_second_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_character: 0, output_cost_per_token_above_128k_tokens: 0, output_cost_per_character_above_128k_tokens: 0, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, tpm: 4e6, rpm: 10, supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\", \"image\"], source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\", supports_tool_choice: !0, supports_web_search: !0 },\n  \"gemini/gemini-2.0-flash-lite-preview-02-05\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 75e-9, input_cost_per_token: 75e-9, output_cost_per_token: 3e-7, litellm_provider: \"gemini\", mode: \"chat\", rpm: 6e4, tpm: 1e7, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\"], source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash-lite\", supports_web_search: !0 },\n  \"gemini/gemini-2.0-flash-thinking-exp\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 65536, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 0, input_cost_per_video_per_second: 0, input_cost_per_audio_per_second: 0, input_cost_per_token: 0, input_cost_per_character: 0, input_cost_per_token_above_128k_tokens: 0, input_cost_per_character_above_128k_tokens: 0, input_cost_per_image_above_128k_tokens: 0, input_cost_per_video_per_second_above_128k_tokens: 0, input_cost_per_audio_per_second_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_character: 0, output_cost_per_token_above_128k_tokens: 0, output_cost_per_character_above_128k_tokens: 0, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, tpm: 4e6, rpm: 10, supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\", \"image\"], source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\", supports_tool_choice: !0, supports_web_search: !0 },\n  \"gemini/gemini-2.0-flash-thinking-exp-01-21\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 65536, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 0, input_cost_per_video_per_second: 0, input_cost_per_audio_per_second: 0, input_cost_per_token: 0, input_cost_per_character: 0, input_cost_per_token_above_128k_tokens: 0, input_cost_per_character_above_128k_tokens: 0, input_cost_per_image_above_128k_tokens: 0, input_cost_per_video_per_second_above_128k_tokens: 0, input_cost_per_audio_per_second_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_character: 0, output_cost_per_token_above_128k_tokens: 0, output_cost_per_character_above_128k_tokens: 0, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, tpm: 4e6, rpm: 10, supported_modalities: [\"text\", \"image\", \"audio\", \"video\"], supported_output_modalities: [\"text\", \"image\"], source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\", supports_tool_choice: !0, supports_web_search: !0 },\n  \"gemini/gemma-3-27b-it\": { max_tokens: 8192, max_input_tokens: 131072, max_output_tokens: 8192, input_cost_per_image: 0, input_cost_per_video_per_second: 0, input_cost_per_audio_per_second: 0, input_cost_per_token: 0, input_cost_per_character: 0, input_cost_per_token_above_128k_tokens: 0, input_cost_per_character_above_128k_tokens: 0, input_cost_per_image_above_128k_tokens: 0, input_cost_per_video_per_second_above_128k_tokens: 0, input_cost_per_audio_per_second_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_character: 0, output_cost_per_token_above_128k_tokens: 0, output_cost_per_character_above_128k_tokens: 0, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, source: \"https://aistudio.google.com\", supports_tool_choice: !0 },\n  \"gemini/learnlm-1.5-pro-experimental\": { max_tokens: 8192, max_input_tokens: 32767, max_output_tokens: 8192, input_cost_per_image: 0, input_cost_per_video_per_second: 0, input_cost_per_audio_per_second: 0, input_cost_per_token: 0, input_cost_per_character: 0, input_cost_per_token_above_128k_tokens: 0, input_cost_per_character_above_128k_tokens: 0, input_cost_per_image_above_128k_tokens: 0, input_cost_per_video_per_second_above_128k_tokens: 0, input_cost_per_audio_per_second_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_character: 0, output_cost_per_token_above_128k_tokens: 0, output_cost_per_character_above_128k_tokens: 0, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, source: \"https://aistudio.google.com\", supports_tool_choice: !0 },\n  \"vertex_ai/claude-3-sonnet\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"vertex_ai-anthropic_models\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"vertex_ai/claude-3-sonnet@20240229\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"vertex_ai-anthropic_models\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"vertex_ai/claude-3-5-sonnet\": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"vertex_ai-anthropic_models\", mode: \"chat\", supports_function_calling: !0, supports_pdf_input: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"vertex_ai/claude-3-5-sonnet@20240620\": { max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"vertex_ai-anthropic_models\", mode: \"chat\", supports_function_calling: !0, supports_pdf_input: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"vertex_ai/claude-3-5-sonnet-v2\": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"vertex_ai-anthropic_models\", mode: \"chat\", supports_function_calling: !0, supports_pdf_input: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"vertex_ai/claude-3-5-sonnet-v2@20241022\": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"vertex_ai-anthropic_models\", mode: \"chat\", supports_function_calling: !0, supports_pdf_input: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"vertex_ai/claude-3-7-sonnet@20250219\": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: \"vertex_ai-anthropic_models\", mode: \"chat\", supports_function_calling: !0, supports_pdf_input: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: \"2025-06-01\", supports_reasoning: !0, supports_tool_choice: !0 },\n  \"vertex_ai/claude-opus-4\": { max_tokens: 32e3, max_input_tokens: 2e5, max_output_tokens: 32e3, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 1875e-8, cache_read_input_token_cost: 15e-7, litellm_provider: \"vertex_ai-anthropic_models\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },\n  \"vertex_ai/claude-opus-4@20250514\": { max_tokens: 32e3, max_input_tokens: 2e5, max_output_tokens: 32e3, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 1875e-8, cache_read_input_token_cost: 15e-7, litellm_provider: \"vertex_ai-anthropic_models\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },\n  \"vertex_ai/claude-sonnet-4\": { max_tokens: 64e3, max_input_tokens: 2e5, max_output_tokens: 64e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: \"vertex_ai-anthropic_models\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },\n  \"vertex_ai/claude-sonnet-4@20250514\": { max_tokens: 64e3, max_input_tokens: 2e5, max_output_tokens: 64e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: \"vertex_ai-anthropic_models\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },\n  \"vertex_ai/claude-3-haiku\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 25e-8, output_cost_per_token: 125e-8, litellm_provider: \"vertex_ai-anthropic_models\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"vertex_ai/claude-3-haiku@20240307\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 25e-8, output_cost_per_token: 125e-8, litellm_provider: \"vertex_ai-anthropic_models\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"vertex_ai/claude-3-5-haiku\": { max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 1e-6, output_cost_per_token: 5e-6, litellm_provider: \"vertex_ai-anthropic_models\", mode: \"chat\", supports_function_calling: !0, supports_pdf_input: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"vertex_ai/claude-3-5-haiku@20241022\": { max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 1e-6, output_cost_per_token: 5e-6, litellm_provider: \"vertex_ai-anthropic_models\", mode: \"chat\", supports_function_calling: !0, supports_pdf_input: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"vertex_ai/claude-3-opus\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, litellm_provider: \"vertex_ai-anthropic_models\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"vertex_ai/claude-3-opus@20240229\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, litellm_provider: \"vertex_ai-anthropic_models\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"vertex_ai/meta/llama3-405b-instruct-maas\": { max_tokens: 32e3, max_input_tokens: 32e3, max_output_tokens: 32e3, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"vertex_ai-llama_models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\", supports_tool_choice: !0 },\n  \"vertex_ai/meta/llama-4-scout-17b-16e-instruct-maas\": { max_tokens: 1e7, max_input_tokens: 1e7, max_output_tokens: 1e7, input_cost_per_token: 25e-8, output_cost_per_token: 7e-7, litellm_provider: \"vertex_ai-llama_models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\", supports_tool_choice: !0, supports_function_calling: !0, supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\", \"code\"] },\n  \"vertex_ai/meta/llama-4-scout-17b-128e-instruct-maas\": { max_tokens: 1e7, max_input_tokens: 1e7, max_output_tokens: 1e7, input_cost_per_token: 25e-8, output_cost_per_token: 7e-7, litellm_provider: \"vertex_ai-llama_models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\", supports_tool_choice: !0, supports_function_calling: !0, supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\", \"code\"] },\n  \"vertex_ai/meta/llama-4-maverick-17b-128e-instruct-maas\": { max_tokens: 1e6, max_input_tokens: 1e6, max_output_tokens: 1e6, input_cost_per_token: 35e-8, output_cost_per_token: 115e-8, litellm_provider: \"vertex_ai-llama_models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\", supports_tool_choice: !0, supports_function_calling: !0, supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\", \"code\"] },\n  \"vertex_ai/meta/llama-4-maverick-17b-16e-instruct-maas\": { max_tokens: 1e6, max_input_tokens: 1e6, max_output_tokens: 1e6, input_cost_per_token: 35e-8, output_cost_per_token: 115e-8, litellm_provider: \"vertex_ai-llama_models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\", supports_tool_choice: !0, supports_function_calling: !0, supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\", \"code\"] },\n  \"vertex_ai/meta/llama3-70b-instruct-maas\": { max_tokens: 32e3, max_input_tokens: 32e3, max_output_tokens: 32e3, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"vertex_ai-llama_models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\", supports_tool_choice: !0 },\n  \"vertex_ai/meta/llama3-8b-instruct-maas\": { max_tokens: 32e3, max_input_tokens: 32e3, max_output_tokens: 32e3, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"vertex_ai-llama_models\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\", supports_tool_choice: !0 },\n  \"vertex_ai/meta/llama-3.2-90b-vision-instruct-maas\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"vertex_ai-llama_models\", mode: \"chat\", supports_system_messages: !0, supports_vision: !0, source: \"https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas\", supports_tool_choice: !0 },\n  \"vertex_ai/mistral-large@latest\": { max_tokens: 8191, max_input_tokens: 128e3, max_output_tokens: 8191, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: \"vertex_ai-mistral_models\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"vertex_ai/mistral-large@2411-001\": { max_tokens: 8191, max_input_tokens: 128e3, max_output_tokens: 8191, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: \"vertex_ai-mistral_models\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"vertex_ai/mistral-large-2411\": { max_tokens: 8191, max_input_tokens: 128e3, max_output_tokens: 8191, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: \"vertex_ai-mistral_models\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"vertex_ai/mistral-large@2407\": { max_tokens: 8191, max_input_tokens: 128e3, max_output_tokens: 8191, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: \"vertex_ai-mistral_models\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"vertex_ai/mistral-nemo@latest\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: \"vertex_ai-mistral_models\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"vertex_ai/mistral-small-2503@001\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 1e-6, output_cost_per_token: 3e-6, litellm_provider: \"vertex_ai-mistral_models\", supports_function_calling: !0, mode: \"chat\", supports_tool_choice: !0 },\n  \"vertex_ai/mistral-small-2503\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 1e-6, output_cost_per_token: 3e-6, litellm_provider: \"vertex_ai-mistral_models\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0 },\n  \"vertex_ai/jamba-1.5-mini@001\": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-7, output_cost_per_token: 4e-7, litellm_provider: \"vertex_ai-ai21_models\", mode: \"chat\", supports_tool_choice: !0 },\n  \"vertex_ai/jamba-1.5-large@001\": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, litellm_provider: \"vertex_ai-ai21_models\", mode: \"chat\", supports_tool_choice: !0 },\n  \"vertex_ai/jamba-1.5\": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-7, output_cost_per_token: 4e-7, litellm_provider: \"vertex_ai-ai21_models\", mode: \"chat\", supports_tool_choice: !0 },\n  \"vertex_ai/jamba-1.5-mini\": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-7, output_cost_per_token: 4e-7, litellm_provider: \"vertex_ai-ai21_models\", mode: \"chat\", supports_tool_choice: !0 },\n  \"vertex_ai/jamba-1.5-large\": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, litellm_provider: \"vertex_ai-ai21_models\", mode: \"chat\", supports_tool_choice: !0 },\n  \"vertex_ai/mistral-nemo@2407\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 3e-6, output_cost_per_token: 3e-6, litellm_provider: \"vertex_ai-mistral_models\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"vertex_ai/codestral@latest\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 2e-7, output_cost_per_token: 6e-7, litellm_provider: \"vertex_ai-mistral_models\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"vertex_ai/codestral@2405\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 2e-7, output_cost_per_token: 6e-7, litellm_provider: \"vertex_ai-mistral_models\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"vertex_ai/codestral-2501\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 2e-7, output_cost_per_token: 6e-7, litellm_provider: \"vertex_ai-mistral_models\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"vertex_ai/imagegeneration@006\": { output_cost_per_image: 0.02, litellm_provider: \"vertex_ai-image-models\", mode: \"image_generation\", source: \"https://cloud.google.com/vertex-ai/generative-ai/pricing\" },\n  \"vertex_ai/imagen-3.0-generate-002\": { output_cost_per_image: 0.04, litellm_provider: \"vertex_ai-image-models\", mode: \"image_generation\", source: \"https://cloud.google.com/vertex-ai/generative-ai/pricing\" },\n  \"vertex_ai/imagen-3.0-generate-001\": { output_cost_per_image: 0.04, litellm_provider: \"vertex_ai-image-models\", mode: \"image_generation\", source: \"https://cloud.google.com/vertex-ai/generative-ai/pricing\" },\n  \"vertex_ai/imagen-3.0-fast-generate-001\": { output_cost_per_image: 0.02, litellm_provider: \"vertex_ai-image-models\", mode: \"image_generation\", source: \"https://cloud.google.com/vertex-ai/generative-ai/pricing\" },\n  \"text-embedding-004\": { max_tokens: 2048, max_input_tokens: 2048, output_vector_size: 768, input_cost_per_character: 25e-9, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"vertex_ai-embedding-models\", mode: \"embedding\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\" },\n  \"gemini-embedding-001\": { max_tokens: 2048, max_input_tokens: 2048, output_vector_size: 3072, input_cost_per_token: 15e-8, output_cost_per_token: 0, litellm_provider: \"vertex_ai-embedding-models\", mode: \"embedding\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\" },\n  \"text-embedding-005\": { max_tokens: 2048, max_input_tokens: 2048, output_vector_size: 768, input_cost_per_character: 25e-9, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"vertex_ai-embedding-models\", mode: \"embedding\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\" },\n  \"text-multilingual-embedding-002\": { max_tokens: 2048, max_input_tokens: 2048, output_vector_size: 768, input_cost_per_character: 25e-9, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"vertex_ai-embedding-models\", mode: \"embedding\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\" },\n  multimodalembedding: ot,\n  \"multimodalembedding@001\": { max_tokens: 2048, max_input_tokens: 2048, output_vector_size: 768, input_cost_per_character: 2e-7, input_cost_per_image: 1e-4, input_cost_per_video_per_second: 5e-4, input_cost_per_video_per_second_above_8s_interval: 1e-3, input_cost_per_video_per_second_above_15s_interval: 2e-3, input_cost_per_token: 8e-7, output_cost_per_token: 0, litellm_provider: \"vertex_ai-embedding-models\", mode: \"embedding\", supported_endpoints: [\"/v1/embeddings\"], supported_modalities: [\"text\", \"image\", \"video\"], source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\" },\n  \"text-embedding-large-exp-03-07\": { max_tokens: 8192, max_input_tokens: 8192, output_vector_size: 3072, input_cost_per_character: 25e-9, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"vertex_ai-embedding-models\", mode: \"embedding\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\" },\n  \"textembedding-gecko\": { max_tokens: 3072, max_input_tokens: 3072, output_vector_size: 768, input_cost_per_character: 25e-9, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"vertex_ai-embedding-models\", mode: \"embedding\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"textembedding-gecko-multilingual\": { max_tokens: 3072, max_input_tokens: 3072, output_vector_size: 768, input_cost_per_character: 25e-9, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"vertex_ai-embedding-models\", mode: \"embedding\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"textembedding-gecko-multilingual@001\": { max_tokens: 3072, max_input_tokens: 3072, output_vector_size: 768, input_cost_per_character: 25e-9, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"vertex_ai-embedding-models\", mode: \"embedding\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"textembedding-gecko@001\": { max_tokens: 3072, max_input_tokens: 3072, output_vector_size: 768, input_cost_per_character: 25e-9, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"vertex_ai-embedding-models\", mode: \"embedding\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"textembedding-gecko@003\": { max_tokens: 3072, max_input_tokens: 3072, output_vector_size: 768, input_cost_per_character: 25e-9, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"vertex_ai-embedding-models\", mode: \"embedding\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"text-embedding-preview-0409\": { max_tokens: 3072, max_input_tokens: 3072, output_vector_size: 768, input_cost_per_token: 625e-11, input_cost_per_token_batch_requests: 5e-9, output_cost_per_token: 0, litellm_provider: \"vertex_ai-embedding-models\", mode: \"embedding\", source: \"https://cloud.google.com/vertex-ai/generative-ai/pricing\" },\n  \"text-multilingual-embedding-preview-0409\": { max_tokens: 3072, max_input_tokens: 3072, output_vector_size: 768, input_cost_per_token: 625e-11, output_cost_per_token: 0, litellm_provider: \"vertex_ai-embedding-models\", mode: \"embedding\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"palm/chat-bison\": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, litellm_provider: \"palm\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"palm/chat-bison-001\": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, litellm_provider: \"palm\", mode: \"chat\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"palm/text-bison\": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, litellm_provider: \"palm\", mode: \"completion\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"palm/text-bison-001\": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, litellm_provider: \"palm\", mode: \"completion\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"palm/text-bison-safety-off\": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, litellm_provider: \"palm\", mode: \"completion\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"palm/text-bison-safety-recitation-off\": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, litellm_provider: \"palm\", mode: \"completion\", source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\" },\n  \"gemini/gemini-1.5-flash-002\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, cache_read_input_token_cost: 1875e-11, cache_creation_input_token_cost: 1e-6, input_cost_per_token: 75e-9, input_cost_per_token_above_128k_tokens: 15e-8, output_cost_per_token: 3e-7, output_cost_per_token_above_128k_tokens: 6e-7, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_prompt_caching: !0, tpm: 4e6, rpm: 2e3, source: \"https://ai.google.dev/pricing\", deprecation_date: \"2025-09-24\", supports_tool_choice: !0 },\n  \"gemini/gemini-1.5-flash-001\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, cache_read_input_token_cost: 1875e-11, cache_creation_input_token_cost: 1e-6, input_cost_per_token: 75e-9, input_cost_per_token_above_128k_tokens: 15e-8, output_cost_per_token: 3e-7, output_cost_per_token_above_128k_tokens: 6e-7, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_prompt_caching: !0, tpm: 4e6, rpm: 2e3, source: \"https://ai.google.dev/pricing\", deprecation_date: \"2025-05-24\", supports_tool_choice: !0 },\n  \"gemini/gemini-1.5-flash\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 75e-9, input_cost_per_token_above_128k_tokens: 15e-8, output_cost_per_token: 3e-7, output_cost_per_token_above_128k_tokens: 6e-7, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, tpm: 4e6, rpm: 2e3, source: \"https://ai.google.dev/pricing\", supports_tool_choice: !0 },\n  \"gemini/gemini-1.5-flash-latest\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 75e-9, input_cost_per_token_above_128k_tokens: 15e-8, output_cost_per_token: 3e-7, output_cost_per_token_above_128k_tokens: 6e-7, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_prompt_caching: !0, tpm: 4e6, rpm: 2e3, source: \"https://ai.google.dev/pricing\", supports_tool_choice: !0 },\n  \"gemini/gemini-1.5-flash-8b\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 0, input_cost_per_token_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_token_above_128k_tokens: 0, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_prompt_caching: !0, tpm: 4e6, rpm: 4e3, source: \"https://ai.google.dev/pricing\", supports_tool_choice: !0 },\n  \"gemini/gemini-1.5-flash-8b-exp-0924\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 0, input_cost_per_token_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_token_above_128k_tokens: 0, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_prompt_caching: !0, tpm: 4e6, rpm: 4e3, source: \"https://ai.google.dev/pricing\", supports_tool_choice: !0 },\n  \"gemini/gemini-exp-1114\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 0, input_cost_per_token_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_token_above_128k_tokens: 0, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_tool_choice: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, tpm: 4e6, rpm: 1e3, source: \"https://ai.google.dev/pricing\", metadata: { notes: \"Rate limits not documented for gemini-exp-1114. Assuming same as gemini-1.5-pro.\", supports_tool_choice: !0 } },\n  \"gemini/gemini-exp-1206\": { max_tokens: 8192, max_input_tokens: 2097152, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 0, input_cost_per_token_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_token_above_128k_tokens: 0, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_tool_choice: !0, supports_vision: !0, supports_response_schema: !0, tpm: 4e6, rpm: 1e3, source: \"https://ai.google.dev/pricing\", metadata: { notes: \"Rate limits not documented for gemini-exp-1206. Assuming same as gemini-1.5-pro.\", supports_tool_choice: !0 } },\n  \"gemini/gemini-1.5-flash-exp-0827\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 0, input_cost_per_token_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_token_above_128k_tokens: 0, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, tpm: 4e6, rpm: 2e3, source: \"https://ai.google.dev/pricing\", supports_tool_choice: !0 },\n  \"gemini/gemini-1.5-flash-8b-exp-0827\": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 0, input_cost_per_token_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_token_above_128k_tokens: 0, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, tpm: 4e6, rpm: 4e3, source: \"https://ai.google.dev/pricing\", supports_tool_choice: !0 },\n  \"gemini/gemini-pro\": { max_tokens: 8192, max_input_tokens: 32760, max_output_tokens: 8192, input_cost_per_token: 35e-8, input_cost_per_token_above_128k_tokens: 7e-7, output_cost_per_token: 105e-8, output_cost_per_token_above_128k_tokens: 21e-7, litellm_provider: \"gemini\", mode: \"chat\", supports_function_calling: !0, rpd: 3e4, tpm: 12e4, rpm: 360, source: \"https://ai.google.dev/gemini-api/docs/models/gemini\", supports_tool_choice: !0 },\n  \"gemini/gemini-1.5-pro\": { max_tokens: 8192, max_input_tokens: 2097152, max_output_tokens: 8192, input_cost_per_token: 35e-7, input_cost_per_token_above_128k_tokens: 7e-6, output_cost_per_token: 105e-7, output_cost_per_token_above_128k_tokens: 21e-6, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_response_schema: !0, tpm: 4e6, rpm: 1e3, source: \"https://ai.google.dev/pricing\" },\n  \"gemini/gemini-1.5-pro-002\": { max_tokens: 8192, max_input_tokens: 2097152, max_output_tokens: 8192, input_cost_per_token: 35e-7, input_cost_per_token_above_128k_tokens: 7e-6, output_cost_per_token: 105e-7, output_cost_per_token_above_128k_tokens: 21e-6, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_response_schema: !0, supports_prompt_caching: !0, tpm: 4e6, rpm: 1e3, source: \"https://ai.google.dev/pricing\", deprecation_date: \"2025-09-24\" },\n  \"gemini/gemini-1.5-pro-001\": { max_tokens: 8192, max_input_tokens: 2097152, max_output_tokens: 8192, input_cost_per_token: 35e-7, input_cost_per_token_above_128k_tokens: 7e-6, output_cost_per_token: 105e-7, output_cost_per_token_above_128k_tokens: 21e-6, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_response_schema: !0, supports_prompt_caching: !0, tpm: 4e6, rpm: 1e3, source: \"https://ai.google.dev/pricing\", deprecation_date: \"2025-05-24\" },\n  \"gemini/gemini-1.5-pro-exp-0801\": { max_tokens: 8192, max_input_tokens: 2097152, max_output_tokens: 8192, input_cost_per_token: 35e-7, input_cost_per_token_above_128k_tokens: 7e-6, output_cost_per_token: 105e-7, output_cost_per_token_above_128k_tokens: 21e-6, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_response_schema: !0, tpm: 4e6, rpm: 1e3, source: \"https://ai.google.dev/pricing\" },\n  \"gemini/gemini-1.5-pro-exp-0827\": { max_tokens: 8192, max_input_tokens: 2097152, max_output_tokens: 8192, input_cost_per_token: 0, input_cost_per_token_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_token_above_128k_tokens: 0, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_response_schema: !0, tpm: 4e6, rpm: 1e3, source: \"https://ai.google.dev/pricing\" },\n  \"gemini/gemini-1.5-pro-latest\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, input_cost_per_token: 35e-7, input_cost_per_token_above_128k_tokens: 7e-6, output_cost_per_token: 105e-8, output_cost_per_token_above_128k_tokens: 21e-6, litellm_provider: \"gemini\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_response_schema: !0, tpm: 4e6, rpm: 1e3, source: \"https://ai.google.dev/pricing\" },\n  \"gemini/gemini-pro-vision\": { max_tokens: 2048, max_input_tokens: 30720, max_output_tokens: 2048, input_cost_per_token: 35e-8, input_cost_per_token_above_128k_tokens: 7e-7, output_cost_per_token: 105e-8, output_cost_per_token_above_128k_tokens: 21e-7, litellm_provider: \"gemini\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, rpd: 3e4, tpm: 12e4, rpm: 360, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0 },\n  \"gemini/gemini-gemma-2-27b-it\": { max_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 35e-8, output_cost_per_token: 105e-8, litellm_provider: \"gemini\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0 },\n  \"gemini/gemini-gemma-2-9b-it\": { max_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 35e-8, output_cost_per_token: 105e-8, litellm_provider: \"gemini\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, source: \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\", supports_tool_choice: !0 },\n  \"command-a-03-2025\": { max_tokens: 8e3, max_input_tokens: 256e3, max_output_tokens: 8e3, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, litellm_provider: \"cohere_chat\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"command-r\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, litellm_provider: \"cohere_chat\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"command-r-08-2024\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, litellm_provider: \"cohere_chat\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"command-r7b-12-2024\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 15e-8, output_cost_per_token: 375e-10, litellm_provider: \"cohere_chat\", mode: \"chat\", supports_function_calling: !0, source: \"https://docs.cohere.com/v2/docs/command-r7b\", supports_tool_choice: !0 },\n  \"command-light\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 3e-7, output_cost_per_token: 6e-7, litellm_provider: \"cohere_chat\", mode: \"chat\", supports_tool_choice: !0 },\n  \"command-r-plus\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, litellm_provider: \"cohere_chat\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"command-r-plus-08-2024\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, litellm_provider: \"cohere_chat\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"command-nightly\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 1e-6, output_cost_per_token: 2e-6, litellm_provider: \"cohere\", mode: \"completion\" },\n  command: _t,\n  \"rerank-v3.5\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, max_query_tokens: 2048, input_cost_per_token: 0, input_cost_per_query: 2e-3, output_cost_per_token: 0, litellm_provider: \"cohere\", mode: \"rerank\" },\n  \"rerank-english-v3.0\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, max_query_tokens: 2048, input_cost_per_token: 0, input_cost_per_query: 2e-3, output_cost_per_token: 0, litellm_provider: \"cohere\", mode: \"rerank\" },\n  \"rerank-multilingual-v3.0\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, max_query_tokens: 2048, input_cost_per_token: 0, input_cost_per_query: 2e-3, output_cost_per_token: 0, litellm_provider: \"cohere\", mode: \"rerank\" },\n  \"rerank-english-v2.0\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, max_query_tokens: 2048, input_cost_per_token: 0, input_cost_per_query: 2e-3, output_cost_per_token: 0, litellm_provider: \"cohere\", mode: \"rerank\" },\n  \"rerank-multilingual-v2.0\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, max_query_tokens: 2048, input_cost_per_token: 0, input_cost_per_query: 2e-3, output_cost_per_token: 0, litellm_provider: \"cohere\", mode: \"rerank\" },\n  \"embed-english-light-v3.0\": { max_tokens: 1024, max_input_tokens: 1024, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"cohere\", mode: \"embedding\" },\n  \"embed-multilingual-v3.0\": { max_tokens: 1024, max_input_tokens: 1024, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"cohere\", supports_embedding_image_input: !0, mode: \"embedding\" },\n  \"embed-english-v2.0\": { max_tokens: 4096, max_input_tokens: 4096, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"cohere\", mode: \"embedding\" },\n  \"embed-english-light-v2.0\": { max_tokens: 1024, max_input_tokens: 1024, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"cohere\", mode: \"embedding\" },\n  \"embed-multilingual-v2.0\": { max_tokens: 768, max_input_tokens: 768, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"cohere\", mode: \"embedding\" },\n  \"embed-english-v3.0\": { max_tokens: 1024, max_input_tokens: 1024, input_cost_per_token: 1e-7, input_cost_per_image: 1e-4, output_cost_per_token: 0, litellm_provider: \"cohere\", mode: \"embedding\", supports_image_input: !0, supports_embedding_image_input: !0, metadata: { notes: \"'supports_image_input' is a deprecated field. Use 'supports_embedding_image_input' instead.\" } },\n  \"replicate/meta/llama-2-13b\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 1e-7, output_cost_per_token: 5e-7, litellm_provider: \"replicate\", mode: \"chat\", supports_tool_choice: !0 },\n  \"replicate/meta/llama-2-13b-chat\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 1e-7, output_cost_per_token: 5e-7, litellm_provider: \"replicate\", mode: \"chat\", supports_tool_choice: !0 },\n  \"replicate/meta/llama-2-70b\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 65e-8, output_cost_per_token: 275e-8, litellm_provider: \"replicate\", mode: \"chat\", supports_tool_choice: !0 },\n  \"replicate/meta/llama-2-70b-chat\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 65e-8, output_cost_per_token: 275e-8, litellm_provider: \"replicate\", mode: \"chat\", supports_tool_choice: !0 },\n  \"replicate/meta/llama-2-7b\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 5e-8, output_cost_per_token: 25e-8, litellm_provider: \"replicate\", mode: \"chat\", supports_tool_choice: !0 },\n  \"replicate/meta/llama-2-7b-chat\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 5e-8, output_cost_per_token: 25e-8, litellm_provider: \"replicate\", mode: \"chat\", supports_tool_choice: !0 },\n  \"replicate/meta/llama-3-70b\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 65e-8, output_cost_per_token: 275e-8, litellm_provider: \"replicate\", mode: \"chat\", supports_tool_choice: !0 },\n  \"replicate/meta/llama-3-70b-instruct\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 65e-8, output_cost_per_token: 275e-8, litellm_provider: \"replicate\", mode: \"chat\", supports_tool_choice: !0 },\n  \"replicate/meta/llama-3-8b\": { max_tokens: 8086, max_input_tokens: 8086, max_output_tokens: 8086, input_cost_per_token: 5e-8, output_cost_per_token: 25e-8, litellm_provider: \"replicate\", mode: \"chat\", supports_tool_choice: !0 },\n  \"replicate/meta/llama-3-8b-instruct\": { max_tokens: 8086, max_input_tokens: 8086, max_output_tokens: 8086, input_cost_per_token: 5e-8, output_cost_per_token: 25e-8, litellm_provider: \"replicate\", mode: \"chat\", supports_tool_choice: !0 },\n  \"replicate/mistralai/mistral-7b-v0.1\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 5e-8, output_cost_per_token: 25e-8, litellm_provider: \"replicate\", mode: \"chat\", supports_tool_choice: !0 },\n  \"replicate/mistralai/mistral-7b-instruct-v0.2\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 5e-8, output_cost_per_token: 25e-8, litellm_provider: \"replicate\", mode: \"chat\", supports_tool_choice: !0 },\n  \"replicate/mistralai/mixtral-8x7b-instruct-v0.1\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 3e-7, output_cost_per_token: 1e-6, litellm_provider: \"replicate\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/deepseek/deepseek-r1\": { max_tokens: 8192, max_input_tokens: 65336, max_output_tokens: 8192, input_cost_per_token: 55e-8, input_cost_per_token_cache_hit: 14e-8, output_cost_per_token: 219e-8, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_assistant_prefill: !0, supports_reasoning: !0, supports_tool_choice: !0, supports_prompt_caching: !0 },\n  \"openrouter/deepseek/deepseek-chat\": { max_tokens: 8192, max_input_tokens: 65536, max_output_tokens: 8192, input_cost_per_token: 14e-8, output_cost_per_token: 28e-8, litellm_provider: \"openrouter\", supports_prompt_caching: !0, mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/deepseek/deepseek-coder\": { max_tokens: 8192, max_input_tokens: 66e3, max_output_tokens: 4096, input_cost_per_token: 14e-8, output_cost_per_token: 28e-8, litellm_provider: \"openrouter\", supports_prompt_caching: !0, mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/microsoft/wizardlm-2-8x22b:nitro\": { max_tokens: 65536, input_cost_per_token: 1e-6, output_cost_per_token: 1e-6, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/google/gemini-pro-1.5\": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, input_cost_per_token: 25e-7, output_cost_per_token: 75e-7, input_cost_per_image: 265e-5, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0 },\n  \"openrouter/google/gemini-2.0-flash-001\": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 1e-7, output_cost_per_token: 4e-7, litellm_provider: \"openrouter\", mode: \"chat\", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supports_tool_choice: !0 },\n  \"openrouter/mistralai/mixtral-8x22b-instruct\": { max_tokens: 65536, input_cost_per_token: 65e-8, output_cost_per_token: 65e-8, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/cohere/command-r-plus\": { max_tokens: 128e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/databricks/dbrx-instruct\": { max_tokens: 32768, input_cost_per_token: 6e-7, output_cost_per_token: 6e-7, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/anthropic/claude-3-haiku\": { max_tokens: 2e5, input_cost_per_token: 25e-8, output_cost_per_token: 125e-8, input_cost_per_image: 4e-4, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0 },\n  \"openrouter/anthropic/claude-3-5-haiku\": { max_tokens: 2e5, input_cost_per_token: 1e-6, output_cost_per_token: 5e-6, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"openrouter/anthropic/claude-3-haiku-20240307\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 25e-8, output_cost_per_token: 125e-8, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 264, supports_tool_choice: !0 },\n  \"openrouter/anthropic/claude-3-5-haiku-20241022\": { max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 1e-6, output_cost_per_token: 5e-6, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, tool_use_system_prompt_tokens: 264, supports_tool_choice: !0 },\n  \"openrouter/anthropic/claude-3.5-sonnet\": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"openrouter/anthropic/claude-3.5-sonnet:beta\": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_tool_choice: !0 },\n  \"openrouter/anthropic/claude-3.7-sonnet\": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, input_cost_per_image: 48e-4, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_reasoning: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_tool_choice: !0 },\n  \"openrouter/anthropic/claude-3.7-sonnet:beta\": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, input_cost_per_image: 48e-4, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_reasoning: !0, tool_use_system_prompt_tokens: 159, supports_tool_choice: !0 },\n  \"openrouter/anthropic/claude-3-sonnet\": { max_tokens: 2e5, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, input_cost_per_image: 48e-4, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0 },\n  \"openrouter/mistralai/mistral-large\": { max_tokens: 32e3, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"mistralai/mistral-small-3.1-24b-instruct\": { max_tokens: 32e3, input_cost_per_token: 1e-7, output_cost_per_token: 3e-7, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/cognitivecomputations/dolphin-mixtral-8x7b\": { max_tokens: 32769, input_cost_per_token: 5e-7, output_cost_per_token: 5e-7, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/google/gemini-pro-vision\": { max_tokens: 45875, input_cost_per_token: 125e-9, output_cost_per_token: 375e-9, input_cost_per_image: 25e-4, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0 },\n  \"openrouter/fireworks/firellava-13b\": { max_tokens: 4096, input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/meta-llama/llama-3-8b-instruct:free\": { max_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/meta-llama/llama-3-8b-instruct:extended\": { max_tokens: 16384, input_cost_per_token: 225e-9, output_cost_per_token: 225e-8, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/meta-llama/llama-3-70b-instruct:nitro\": { max_tokens: 8192, input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/meta-llama/llama-3-70b-instruct\": { max_tokens: 8192, input_cost_per_token: 59e-8, output_cost_per_token: 79e-8, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/openai/o1\": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, cache_read_input_token_cost: 75e-7, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_response_schema: !0, supports_tool_choice: !0 },\n  \"openrouter/openai/o1-mini\": { max_tokens: 65536, max_input_tokens: 128e3, max_output_tokens: 65536, input_cost_per_token: 3e-6, output_cost_per_token: 12e-6, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_tool_choice: !0 },\n  \"openrouter/openai/o1-mini-2024-09-12\": { max_tokens: 65536, max_input_tokens: 128e3, max_output_tokens: 65536, input_cost_per_token: 3e-6, output_cost_per_token: 12e-6, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_tool_choice: !0 },\n  \"openrouter/openai/o1-preview\": { max_tokens: 32768, max_input_tokens: 128e3, max_output_tokens: 32768, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_tool_choice: !0 },\n  \"openrouter/openai/o1-preview-2024-09-12\": { max_tokens: 32768, max_input_tokens: 128e3, max_output_tokens: 32768, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_tool_choice: !0 },\n  \"openrouter/openai/o3-mini\": { max_tokens: 65536, max_input_tokens: 128e3, max_output_tokens: 65536, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_reasoning: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_tool_choice: !0 },\n  \"openrouter/openai/o3-mini-high\": { max_tokens: 65536, max_input_tokens: 128e3, max_output_tokens: 65536, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_reasoning: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_tool_choice: !0 },\n  \"openrouter/openai/gpt-4o\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_tool_choice: !0 },\n  \"openrouter/openai/gpt-4o-2024-05-13\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 5e-6, output_cost_per_token: 15e-6, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_tool_choice: !0 },\n  \"openrouter/openai/gpt-4-vision-preview\": { max_tokens: 13e4, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, input_cost_per_image: 0.01445, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0 },\n  \"openrouter/openai/gpt-3.5-turbo\": { max_tokens: 4095, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/openai/gpt-3.5-turbo-16k\": { max_tokens: 16383, input_cost_per_token: 3e-6, output_cost_per_token: 4e-6, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/openai/gpt-4\": { max_tokens: 8192, input_cost_per_token: 3e-5, output_cost_per_token: 6e-5, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/anthropic/claude-instant-v1\": { max_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 163e-8, output_cost_per_token: 551e-8, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/anthropic/claude-2\": { max_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 1102e-8, output_cost_per_token: 3268e-8, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/anthropic/claude-3-opus\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, litellm_provider: \"openrouter\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 395, supports_tool_choice: !0 },\n  \"openrouter/google/palm-2-chat-bison\": { max_tokens: 25804, input_cost_per_token: 5e-7, output_cost_per_token: 5e-7, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/google/palm-2-codechat-bison\": { max_tokens: 20070, input_cost_per_token: 5e-7, output_cost_per_token: 5e-7, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/meta-llama/llama-2-13b-chat\": { max_tokens: 4096, input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/meta-llama/llama-2-70b-chat\": { max_tokens: 4096, input_cost_per_token: 15e-7, output_cost_per_token: 15e-7, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/meta-llama/codellama-34b-instruct\": { max_tokens: 8192, input_cost_per_token: 5e-7, output_cost_per_token: 5e-7, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/nousresearch/nous-hermes-llama2-13b\": { max_tokens: 4096, input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/mancer/weaver\": { max_tokens: 8e3, input_cost_per_token: 5625e-9, output_cost_per_token: 5625e-9, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/gryphe/mythomax-l2-13b\": { max_tokens: 8192, input_cost_per_token: 1875e-9, output_cost_per_token: 1875e-9, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/jondurbin/airoboros-l2-70b-2.1\": { max_tokens: 4096, input_cost_per_token: 13875e-9, output_cost_per_token: 13875e-9, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/undi95/remm-slerp-l2-13b\": { max_tokens: 6144, input_cost_per_token: 1875e-9, output_cost_per_token: 1875e-9, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/pygmalionai/mythalion-13b\": { max_tokens: 4096, input_cost_per_token: 1875e-9, output_cost_per_token: 1875e-9, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/mistralai/mistral-7b-instruct\": { max_tokens: 8192, input_cost_per_token: 13e-8, output_cost_per_token: 13e-8, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/mistralai/mistral-7b-instruct:free\": { max_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"openrouter/qwen/qwen-2.5-coder-32b-instruct\": { max_tokens: 33792, max_input_tokens: 33792, max_output_tokens: 33792, input_cost_per_token: 18e-8, output_cost_per_token: 18e-8, litellm_provider: \"openrouter\", mode: \"chat\", supports_tool_choice: !0 },\n  \"j2-ultra\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 15e-6, output_cost_per_token: 15e-6, litellm_provider: \"ai21\", mode: \"completion\" },\n  \"jamba-1.5-mini@001\": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-7, output_cost_per_token: 4e-7, litellm_provider: \"ai21\", mode: \"chat\", supports_tool_choice: !0 },\n  \"jamba-1.5-large@001\": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, litellm_provider: \"ai21\", mode: \"chat\", supports_tool_choice: !0 },\n  \"jamba-1.5\": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-7, output_cost_per_token: 4e-7, litellm_provider: \"ai21\", mode: \"chat\", supports_tool_choice: !0 },\n  \"jamba-1.5-mini\": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-7, output_cost_per_token: 4e-7, litellm_provider: \"ai21\", mode: \"chat\", supports_tool_choice: !0 },\n  \"jamba-1.5-large\": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, litellm_provider: \"ai21\", mode: \"chat\", supports_tool_choice: !0 },\n  \"jamba-large-1.6\": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, litellm_provider: \"ai21\", mode: \"chat\", supports_tool_choice: !0 },\n  \"jamba-mini-1.6\": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-7, output_cost_per_token: 4e-7, litellm_provider: \"ai21\", mode: \"chat\", supports_tool_choice: !0 },\n  \"j2-mid\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 1e-5, output_cost_per_token: 1e-5, litellm_provider: \"ai21\", mode: \"completion\" },\n  \"j2-light\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 3e-6, litellm_provider: \"ai21\", mode: \"completion\" },\n  dolphin: st,\n  chatdolphin: pt,\n  \"luminous-base\": { max_tokens: 2048, input_cost_per_token: 3e-5, output_cost_per_token: 33e-6, litellm_provider: \"aleph_alpha\", mode: \"completion\" },\n  \"luminous-base-control\": { max_tokens: 2048, input_cost_per_token: 375e-7, output_cost_per_token: 4125e-8, litellm_provider: \"aleph_alpha\", mode: \"chat\" },\n  \"luminous-extended\": { max_tokens: 2048, input_cost_per_token: 45e-6, output_cost_per_token: 495e-7, litellm_provider: \"aleph_alpha\", mode: \"completion\" },\n  \"luminous-extended-control\": { max_tokens: 2048, input_cost_per_token: 5625e-8, output_cost_per_token: 61875e-9, litellm_provider: \"aleph_alpha\", mode: \"chat\" },\n  \"luminous-supreme\": { max_tokens: 2048, input_cost_per_token: 175e-6, output_cost_per_token: 1925e-7, litellm_provider: \"aleph_alpha\", mode: \"completion\" },\n  \"luminous-supreme-control\": { max_tokens: 2048, input_cost_per_token: 21875e-8, output_cost_per_token: 240625e-9, litellm_provider: \"aleph_alpha\", mode: \"chat\" },\n  \"ai21.j2-mid-v1\": { max_tokens: 8191, max_input_tokens: 8191, max_output_tokens: 8191, input_cost_per_token: 125e-7, output_cost_per_token: 125e-7, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"ai21.j2-ultra-v1\": { max_tokens: 8191, max_input_tokens: 8191, max_output_tokens: 8191, input_cost_per_token: 188e-7, output_cost_per_token: 188e-7, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"ai21.jamba-instruct-v1:0\": { max_tokens: 4096, max_input_tokens: 7e4, max_output_tokens: 4096, input_cost_per_token: 5e-7, output_cost_per_token: 7e-7, litellm_provider: \"bedrock\", mode: \"chat\", supports_system_messages: !0 },\n  \"ai21.jamba-1-5-large-v1:0\": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"ai21.jamba-1-5-mini-v1:0\": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-7, output_cost_per_token: 4e-7, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"amazon.rerank-v1:0\": { max_tokens: 32e3, max_input_tokens: 32e3, max_output_tokens: 32e3, max_query_tokens: 32e3, max_document_chunks_per_query: 100, max_tokens_per_document_chunk: 512, input_cost_per_token: 0, input_cost_per_query: 1e-3, output_cost_per_token: 0, litellm_provider: \"bedrock\", mode: \"rerank\" },\n  \"amazon.titan-text-lite-v1\": { max_tokens: 4e3, max_input_tokens: 42e3, max_output_tokens: 4e3, input_cost_per_token: 3e-7, output_cost_per_token: 4e-7, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"amazon.titan-text-express-v1\": { max_tokens: 8e3, max_input_tokens: 42e3, max_output_tokens: 8e3, input_cost_per_token: 13e-7, output_cost_per_token: 17e-7, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"amazon.titan-text-premier-v1:0\": { max_tokens: 32e3, max_input_tokens: 42e3, max_output_tokens: 32e3, input_cost_per_token: 5e-7, output_cost_per_token: 15e-7, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"amazon.titan-embed-text-v1\": { max_tokens: 8192, max_input_tokens: 8192, output_vector_size: 1536, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"bedrock\", mode: \"embedding\" },\n  \"amazon.titan-embed-text-v2:0\": { max_tokens: 8192, max_input_tokens: 8192, output_vector_size: 1024, input_cost_per_token: 2e-7, output_cost_per_token: 0, litellm_provider: \"bedrock\", mode: \"embedding\" },\n  \"amazon.titan-embed-image-v1\": { max_tokens: 128, max_input_tokens: 128, output_vector_size: 1024, input_cost_per_token: 8e-7, input_cost_per_image: 6e-5, output_cost_per_token: 0, litellm_provider: \"bedrock\", supports_image_input: !0, supports_embedding_image_input: !0, mode: \"embedding\", source: \"https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/providers?model=amazon.titan-image-generator-v1\", metadata: { notes: \"'supports_image_input' is a deprecated field. Use 'supports_embedding_image_input' instead.\" } },\n  \"mistral.mistral-7b-instruct-v0:2\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 15e-8, output_cost_per_token: 2e-7, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"mistral.mixtral-8x7b-instruct-v0:1\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 45e-8, output_cost_per_token: 7e-7, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"mistral.mistral-large-2402-v1:0\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"mistral.mistral-large-2407-v1:0\": { max_tokens: 8191, max_input_tokens: 128e3, max_output_tokens: 8191, input_cost_per_token: 3e-6, output_cost_per_token: 9e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"mistral.mistral-small-2402-v1:0\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 1e-6, output_cost_per_token: 3e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 45e-8, output_cost_per_token: 7e-7, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 45e-8, output_cost_per_token: 7e-7, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 59e-8, output_cost_per_token: 91e-8, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 15e-8, output_cost_per_token: 2e-7, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 15e-8, output_cost_per_token: 2e-7, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 2e-7, output_cost_per_token: 26e-8, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-east-1/mistral.mistral-large-2402-v1:0\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"bedrock/us-west-2/mistral.mistral-large-2402-v1:0\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"bedrock/eu-west-3/mistral.mistral-large-2402-v1:0\": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 104e-7, output_cost_per_token: 312e-7, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0 },\n  \"amazon.nova-micro-v1:0\": { max_tokens: 1e4, max_input_tokens: 3e5, max_output_tokens: 1e4, input_cost_per_token: 35e-9, output_cost_per_token: 14e-8, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_prompt_caching: !0, supports_response_schema: !0 },\n  \"us.amazon.nova-micro-v1:0\": { max_tokens: 1e4, max_input_tokens: 3e5, max_output_tokens: 1e4, input_cost_per_token: 35e-9, output_cost_per_token: 14e-8, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_prompt_caching: !0, supports_response_schema: !0 },\n  \"eu.amazon.nova-micro-v1:0\": { max_tokens: 1e4, max_input_tokens: 3e5, max_output_tokens: 1e4, input_cost_per_token: 46e-9, output_cost_per_token: 184e-9, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_prompt_caching: !0, supports_response_schema: !0 },\n  \"amazon.nova-lite-v1:0\": { max_tokens: 1e4, max_input_tokens: 128e3, max_output_tokens: 1e4, input_cost_per_token: 6e-8, output_cost_per_token: 24e-8, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0 },\n  \"us.amazon.nova-lite-v1:0\": { max_tokens: 1e4, max_input_tokens: 128e3, max_output_tokens: 1e4, input_cost_per_token: 6e-8, output_cost_per_token: 24e-8, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0 },\n  \"eu.amazon.nova-lite-v1:0\": { max_tokens: 1e4, max_input_tokens: 128e3, max_output_tokens: 1e4, input_cost_per_token: 78e-9, output_cost_per_token: 312e-9, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0 },\n  \"amazon.nova-pro-v1:0\": { max_tokens: 1e4, max_input_tokens: 3e5, max_output_tokens: 1e4, input_cost_per_token: 8e-7, output_cost_per_token: 32e-7, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0 },\n  \"us.amazon.nova-pro-v1:0\": { max_tokens: 1e4, max_input_tokens: 3e5, max_output_tokens: 1e4, input_cost_per_token: 8e-7, output_cost_per_token: 32e-7, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0 },\n  \"1024-x-1024/50-steps/bedrock/amazon.nova-canvas-v1:0\": { max_input_tokens: 2600, output_cost_per_image: 0.06, litellm_provider: \"bedrock\", mode: \"image_generation\" },\n  \"eu.amazon.nova-pro-v1:0\": { max_tokens: 1e4, max_input_tokens: 3e5, max_output_tokens: 1e4, input_cost_per_token: 105e-8, output_cost_per_token: 42e-7, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, source: \"https://aws.amazon.com/bedrock/pricing/\" },\n  \"us.amazon.nova-premier-v1:0\": { max_tokens: 1e4, max_input_tokens: 1e6, max_output_tokens: 1e4, input_cost_per_token: 25e-7, output_cost_per_token: 125e-7, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !1, supports_response_schema: !0 },\n  \"anthropic.claude-3-sonnet-20240229-v1:0\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_pdf_input: !0, supports_tool_choice: !0 },\n  \"bedrock/invoke/anthropic.claude-3-5-sonnet-20240620-v1:0\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_tool_choice: !0, metadata: { notes: \"Anthropic via Invoke route does not currently support pdf input.\" } },\n  \"anthropic.claude-3-5-sonnet-20240620-v1:0\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_pdf_input: !0, supports_tool_choice: !0 },\n  \"anthropic.claude-opus-4-20250514-v1:0\": { max_tokens: 32e3, max_input_tokens: 2e5, max_output_tokens: 32e3, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 1875e-8, cache_read_input_token_cost: 15e-7, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },\n  \"anthropic.claude-sonnet-4-20250514-v1:0\": { max_tokens: 64e3, max_input_tokens: 2e5, max_output_tokens: 64e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },\n  \"anthropic.claude-3-7-sonnet-20250219-v1:0\": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_pdf_input: !0, supports_reasoning: !0, supports_tool_choice: !0 },\n  \"anthropic.claude-3-5-sonnet-20241022-v2:0\": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0 },\n  \"anthropic.claude-3-haiku-20240307-v1:0\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 25e-8, output_cost_per_token: 125e-8, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_pdf_input: !0, supports_tool_choice: !0 },\n  \"anthropic.claude-3-5-haiku-20241022-v1:0\": { max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 8e-7, output_cost_per_token: 4e-6, cache_creation_input_token_cost: 1e-6, cache_read_input_token_cost: 8e-8, litellm_provider: \"bedrock\", mode: \"chat\", supports_assistant_prefill: !0, supports_pdf_input: !0, supports_function_calling: !0, supports_response_schema: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },\n  \"anthropic.claude-3-opus-20240229-v1:0\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_tool_choice: !0 },\n  \"us.anthropic.claude-3-sonnet-20240229-v1:0\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_pdf_input: !0, supports_tool_choice: !0 },\n  \"us.anthropic.claude-3-5-sonnet-20240620-v1:0\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_pdf_input: !0, supports_tool_choice: !0 },\n  \"us.anthropic.claude-3-5-sonnet-20241022-v2:0\": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0 },\n  \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_pdf_input: !0, supports_tool_choice: !0, supports_reasoning: !0 },\n  \"us.anthropic.claude-opus-4-20250514-v1:0\": { max_tokens: 32e3, max_input_tokens: 2e5, max_output_tokens: 32e3, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 1875e-8, cache_read_input_token_cost: 15e-7, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },\n  \"us.anthropic.claude-sonnet-4-20250514-v1:0\": { max_tokens: 64e3, max_input_tokens: 2e5, max_output_tokens: 64e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },\n  \"us.anthropic.claude-3-haiku-20240307-v1:0\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 25e-8, output_cost_per_token: 125e-8, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_pdf_input: !0, supports_tool_choice: !0 },\n  \"us.anthropic.claude-3-5-haiku-20241022-v1:0\": { max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 8e-7, output_cost_per_token: 4e-6, cache_creation_input_token_cost: 1e-6, cache_read_input_token_cost: 8e-8, litellm_provider: \"bedrock\", mode: \"chat\", supports_assistant_prefill: !0, supports_pdf_input: !0, supports_function_calling: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0 },\n  \"us.anthropic.claude-3-opus-20240229-v1:0\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_tool_choice: !0 },\n  \"eu.anthropic.claude-3-sonnet-20240229-v1:0\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_pdf_input: !0, supports_tool_choice: !0 },\n  \"eu.anthropic.claude-3-5-sonnet-20240620-v1:0\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_pdf_input: !0, supports_tool_choice: !0 },\n  \"eu.anthropic.claude-3-5-sonnet-20241022-v2:0\": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0 },\n  \"eu.anthropic.claude-3-7-sonnet-20250219-v1:0\": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_pdf_input: !0, supports_tool_choice: !0, supports_reasoning: !0 },\n  \"eu.anthropic.claude-3-haiku-20240307-v1:0\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 25e-8, output_cost_per_token: 125e-8, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_pdf_input: !0, supports_tool_choice: !0 },\n  \"eu.anthropic.claude-opus-4-20250514-v1:0\": { max_tokens: 32e3, max_input_tokens: 2e5, max_output_tokens: 32e3, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 1875e-8, cache_read_input_token_cost: 15e-7, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },\n  \"eu.anthropic.claude-sonnet-4-20250514-v1:0\": { max_tokens: 64e3, max_input_tokens: 2e5, max_output_tokens: 64e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },\n  \"eu.anthropic.claude-3-5-haiku-20241022-v1:0\": { max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 25e-8, output_cost_per_token: 125e-8, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0 },\n  \"eu.anthropic.claude-3-opus-20240229-v1:0\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_tool_choice: !0 },\n  \"anthropic.claude-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/us-east-1/anthropic.claude-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-west-2/anthropic.claude-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/ap-northeast-1/anthropic.claude-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0455, output_cost_per_second: 0.0455, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.02527, output_cost_per_second: 0.02527, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/eu-central-1/anthropic.claude-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0415, output_cost_per_second: 0.0415, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.02305, output_cost_per_second: 0.02305, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/us-east-1/1-month-commitment/anthropic.claude-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0175, output_cost_per_second: 0.0175, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/us-east-1/6-month-commitment/anthropic.claude-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 972e-5, output_cost_per_second: 972e-5, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/us-west-2/1-month-commitment/anthropic.claude-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0175, output_cost_per_second: 0.0175, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/us-west-2/6-month-commitment/anthropic.claude-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 972e-5, output_cost_per_second: 972e-5, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"anthropic.claude-v2\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-east-1/anthropic.claude-v2\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-west-2/anthropic.claude-v2\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/ap-northeast-1/anthropic.claude-v2\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0455, output_cost_per_second: 0.0455, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.02527, output_cost_per_second: 0.02527, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/eu-central-1/anthropic.claude-v2\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0415, output_cost_per_second: 0.0415, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.02305, output_cost_per_second: 0.02305, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-east-1/1-month-commitment/anthropic.claude-v2\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0175, output_cost_per_second: 0.0175, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-east-1/6-month-commitment/anthropic.claude-v2\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 972e-5, output_cost_per_second: 972e-5, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-west-2/1-month-commitment/anthropic.claude-v2\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0175, output_cost_per_second: 0.0175, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-west-2/6-month-commitment/anthropic.claude-v2\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 972e-5, output_cost_per_second: 972e-5, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"anthropic.claude-v2:1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-east-1/anthropic.claude-v2:1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-west-2/anthropic.claude-v2:1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/ap-northeast-1/anthropic.claude-v2:1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0455, output_cost_per_second: 0.0455, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.02527, output_cost_per_second: 0.02527, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/eu-central-1/anthropic.claude-v2:1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0415, output_cost_per_second: 0.0415, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.02305, output_cost_per_second: 0.02305, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0175, output_cost_per_second: 0.0175, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 972e-5, output_cost_per_second: 972e-5, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0175, output_cost_per_second: 0.0175, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 972e-5, output_cost_per_second: 972e-5, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"anthropic.claude-instant-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-7, output_cost_per_token: 24e-7, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-east-1/anthropic.claude-instant-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-7, output_cost_per_token: 24e-7, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.011, output_cost_per_second: 0.011, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 611e-5, output_cost_per_second: 611e-5, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.011, output_cost_per_second: 0.011, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 611e-5, output_cost_per_second: 611e-5, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/us-west-2/anthropic.claude-instant-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-7, output_cost_per_token: 24e-7, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/ap-northeast-1/anthropic.claude-instant-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 223e-8, output_cost_per_token: 755e-8, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.01475, output_cost_per_second: 0.01475, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 8194e-6, output_cost_per_second: 8194e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/eu-central-1/anthropic.claude-instant-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 248e-8, output_cost_per_token: 838e-8, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.01635, output_cost_per_second: 0.01635, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1\": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 9083e-6, output_cost_per_second: 9083e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"cohere.rerank-v3-5:0\": { max_tokens: 32e3, max_input_tokens: 32e3, max_output_tokens: 32e3, max_query_tokens: 32e3, max_document_chunks_per_query: 100, max_tokens_per_document_chunk: 512, input_cost_per_token: 0, input_cost_per_query: 2e-3, output_cost_per_token: 0, litellm_provider: \"bedrock\", mode: \"rerank\" },\n  \"cohere.command-text-v14\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/*/1-month-commitment/cohere.command-text-v14\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_second: 0.011, output_cost_per_second: 0.011, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/*/6-month-commitment/cohere.command-text-v14\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_second: 66027e-7, output_cost_per_second: 66027e-7, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"cohere.command-light-text-v14\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 3e-7, output_cost_per_token: 6e-7, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/*/1-month-commitment/cohere.command-light-text-v14\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_second: 1902e-6, output_cost_per_second: 1902e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"bedrock/*/6-month-commitment/cohere.command-light-text-v14\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_second: 11416e-7, output_cost_per_second: 11416e-7, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"cohere.command-r-plus-v1:0\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"cohere.command-r-v1:0\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 5e-7, output_cost_per_token: 15e-7, litellm_provider: \"bedrock\", mode: \"chat\", supports_tool_choice: !0 },\n  \"cohere.embed-english-v3\": { max_tokens: 512, max_input_tokens: 512, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"bedrock\", mode: \"embedding\", supports_embedding_image_input: !0 },\n  \"cohere.embed-multilingual-v3\": { max_tokens: 512, max_input_tokens: 512, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"bedrock\", mode: \"embedding\", supports_embedding_image_input: !0 },\n  \"us.deepseek.r1-v1:0\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 135e-8, output_cost_per_token: 54e-7, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_reasoning: !0, supports_function_calling: !1, supports_tool_choice: !1 },\n  \"meta.llama3-3-70b-instruct-v1:0\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 72e-8, output_cost_per_token: 72e-8, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1 },\n  \"meta.llama2-13b-chat-v1\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 75e-8, output_cost_per_token: 1e-6, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"meta.llama2-70b-chat-v1\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 195e-8, output_cost_per_token: 256e-8, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"meta.llama3-8b-instruct-v1:0\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 3e-7, output_cost_per_token: 6e-7, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/us-east-1/meta.llama3-8b-instruct-v1:0\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 3e-7, output_cost_per_token: 6e-7, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/us-west-1/meta.llama3-8b-instruct-v1:0\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 3e-7, output_cost_per_token: 6e-7, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 36e-8, output_cost_per_token: 72e-8, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 35e-8, output_cost_per_token: 69e-8, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 32e-8, output_cost_per_token: 65e-8, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 39e-8, output_cost_per_token: 78e-8, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 5e-7, output_cost_per_token: 101e-8, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"meta.llama3-70b-instruct-v1:0\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 265e-8, output_cost_per_token: 35e-7, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/us-east-1/meta.llama3-70b-instruct-v1:0\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 265e-8, output_cost_per_token: 35e-7, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/us-west-1/meta.llama3-70b-instruct-v1:0\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 265e-8, output_cost_per_token: 35e-7, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 318e-8, output_cost_per_token: 42e-7, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 305e-8, output_cost_per_token: 403e-8, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 286e-8, output_cost_per_token: 378e-8, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 345e-8, output_cost_per_token: 455e-8, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 445e-8, output_cost_per_token: 588e-8, litellm_provider: \"bedrock\", mode: \"chat\" },\n  \"meta.llama3-1-8b-instruct-v1:0\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 22e-8, output_cost_per_token: 22e-8, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1 },\n  \"us.meta.llama3-1-8b-instruct-v1:0\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 22e-8, output_cost_per_token: 22e-8, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1 },\n  \"meta.llama3-1-70b-instruct-v1:0\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 99e-8, output_cost_per_token: 99e-8, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1 },\n  \"us.meta.llama3-1-70b-instruct-v1:0\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 99e-8, output_cost_per_token: 99e-8, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1 },\n  \"meta.llama3-1-405b-instruct-v1:0\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 532e-8, output_cost_per_token: 16e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1 },\n  \"us.meta.llama3-1-405b-instruct-v1:0\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 532e-8, output_cost_per_token: 16e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1 },\n  \"meta.llama3-2-1b-instruct-v1:0\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-7, output_cost_per_token: 1e-7, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1 },\n  \"us.meta.llama3-2-1b-instruct-v1:0\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-7, output_cost_per_token: 1e-7, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1 },\n  \"eu.meta.llama3-2-1b-instruct-v1:0\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 13e-8, output_cost_per_token: 13e-8, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1 },\n  \"meta.llama3-2-3b-instruct-v1:0\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1 },\n  \"us.meta.llama3-2-3b-instruct-v1:0\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1 },\n  \"eu.meta.llama3-2-3b-instruct-v1:0\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 19e-8, output_cost_per_token: 19e-8, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1 },\n  \"meta.llama3-2-11b-instruct-v1:0\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 35e-8, output_cost_per_token: 35e-8, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1, supports_vision: !0 },\n  \"us.meta.llama3-2-11b-instruct-v1:0\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 35e-8, output_cost_per_token: 35e-8, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1, supports_vision: !0 },\n  \"meta.llama3-2-90b-instruct-v1:0\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 2e-6, output_cost_per_token: 2e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1, supports_vision: !0 },\n  \"us.meta.llama3-2-90b-instruct-v1:0\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 2e-6, output_cost_per_token: 2e-6, litellm_provider: \"bedrock\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1, supports_vision: !0 },\n  \"us.meta.llama3-3-70b-instruct-v1:0\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 72e-8, output_cost_per_token: 72e-8, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1 },\n  \"meta.llama4-maverick-17b-instruct-v1:0\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 24e-8, input_cost_per_token_batches: 12e-8, output_cost_per_token: 97e-8, output_cost_per_token_batches: 485e-9, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1, supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\", \"code\"] },\n  \"us.meta.llama4-maverick-17b-instruct-v1:0\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 24e-8, input_cost_per_token_batches: 12e-8, output_cost_per_token: 97e-8, output_cost_per_token_batches: 485e-9, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1, supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\", \"code\"] },\n  \"meta.llama4-scout-17b-instruct-v1:0\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 17e-8, input_cost_per_token_batches: 85e-9, output_cost_per_token: 66e-8, output_cost_per_token_batches: 33e-8, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1, supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\", \"code\"] },\n  \"us.meta.llama4-scout-17b-instruct-v1:0\": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 17e-8, input_cost_per_token_batches: 85e-9, output_cost_per_token: 66e-8, output_cost_per_token_batches: 33e-8, litellm_provider: \"bedrock_converse\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !1, supported_modalities: [\"text\", \"image\"], supported_output_modalities: [\"text\", \"code\"] },\n  \"512-x-512/50-steps/stability.stable-diffusion-xl-v0\": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.018, litellm_provider: \"bedrock\", mode: \"image_generation\" },\n  \"512-x-512/max-steps/stability.stable-diffusion-xl-v0\": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.036, litellm_provider: \"bedrock\", mode: \"image_generation\" },\n  \"max-x-max/50-steps/stability.stable-diffusion-xl-v0\": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.036, litellm_provider: \"bedrock\", mode: \"image_generation\" },\n  \"max-x-max/max-steps/stability.stable-diffusion-xl-v0\": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.072, litellm_provider: \"bedrock\", mode: \"image_generation\" },\n  \"1024-x-1024/50-steps/stability.stable-diffusion-xl-v1\": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.04, litellm_provider: \"bedrock\", mode: \"image_generation\" },\n  \"1024-x-1024/max-steps/stability.stable-diffusion-xl-v1\": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.08, litellm_provider: \"bedrock\", mode: \"image_generation\" },\n  \"stability.sd3-large-v1:0\": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.08, litellm_provider: \"bedrock\", mode: \"image_generation\" },\n  \"stability.sd3-5-large-v1:0\": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.08, litellm_provider: \"bedrock\", mode: \"image_generation\" },\n  \"stability.stable-image-core-v1:0\": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.04, litellm_provider: \"bedrock\", mode: \"image_generation\" },\n  \"stability.stable-image-core-v1:1\": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.04, litellm_provider: \"bedrock\", mode: \"image_generation\" },\n  \"stability.stable-image-ultra-v1:0\": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.14, litellm_provider: \"bedrock\", mode: \"image_generation\" },\n  \"stability.stable-image-ultra-v1:1\": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.14, litellm_provider: \"bedrock\", mode: \"image_generation\" },\n  \"sagemaker/meta-textgeneration-llama-2-7b\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"sagemaker\", mode: \"completion\" },\n  \"sagemaker/meta-textgeneration-llama-2-7b-f\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"sagemaker\", mode: \"chat\" },\n  \"sagemaker/meta-textgeneration-llama-2-13b\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"sagemaker\", mode: \"completion\" },\n  \"sagemaker/meta-textgeneration-llama-2-13b-f\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"sagemaker\", mode: \"chat\" },\n  \"sagemaker/meta-textgeneration-llama-2-70b\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"sagemaker\", mode: \"completion\" },\n  \"sagemaker/meta-textgeneration-llama-2-70b-b-f\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"sagemaker\", mode: \"chat\" },\n  \"together-ai-up-to-4b\": { input_cost_per_token: 1e-7, output_cost_per_token: 1e-7, litellm_provider: \"together_ai\", mode: \"chat\" },\n  \"together-ai-4.1b-8b\": { input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: \"together_ai\", mode: \"chat\" },\n  \"together-ai-8.1b-21b\": { max_tokens: 1e3, input_cost_per_token: 3e-7, output_cost_per_token: 3e-7, litellm_provider: \"together_ai\", mode: \"chat\" },\n  \"together-ai-21.1b-41b\": { input_cost_per_token: 8e-7, output_cost_per_token: 8e-7, litellm_provider: \"together_ai\", mode: \"chat\" },\n  \"together-ai-41.1b-80b\": { input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: \"together_ai\", mode: \"chat\" },\n  \"together-ai-81.1b-110b\": { input_cost_per_token: 18e-7, output_cost_per_token: 18e-7, litellm_provider: \"together_ai\", mode: \"chat\" },\n  \"together-ai-embedding-up-to-150m\": { input_cost_per_token: 8e-9, output_cost_per_token: 0, litellm_provider: \"together_ai\", mode: \"embedding\" },\n  \"together-ai-embedding-151m-to-350m\": { input_cost_per_token: 16e-9, output_cost_per_token: 0, litellm_provider: \"together_ai\", mode: \"embedding\" },\n  \"together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\": { input_cost_per_token: 18e-8, output_cost_per_token: 18e-8, litellm_provider: \"together_ai\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, mode: \"chat\", supports_tool_choice: !0 },\n  \"together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\": { input_cost_per_token: 88e-8, output_cost_per_token: 88e-8, litellm_provider: \"together_ai\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, mode: \"chat\", supports_tool_choice: !0 },\n  \"together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\": { input_cost_per_token: 35e-7, output_cost_per_token: 35e-7, litellm_provider: \"together_ai\", supports_function_calling: !0, supports_parallel_function_calling: !0, mode: \"chat\", supports_tool_choice: !0 },\n  \"together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo\": { input_cost_per_token: 88e-8, output_cost_per_token: 88e-8, litellm_provider: \"together_ai\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, mode: \"chat\", supports_tool_choice: !0 },\n  \"together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\": { input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"together_ai\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, mode: \"chat\", supports_tool_choice: !0 },\n  \"together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1\": { input_cost_per_token: 6e-7, output_cost_per_token: 6e-7, litellm_provider: \"together_ai\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, mode: \"chat\", supports_tool_choice: !0 },\n  \"together_ai/mistralai/Mistral-7B-Instruct-v0.1\": { litellm_provider: \"together_ai\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, mode: \"chat\", supports_tool_choice: !0 },\n  \"together_ai/togethercomputer/CodeLlama-34b-Instruct\": { litellm_provider: \"together_ai\", supports_function_calling: !0, supports_parallel_function_calling: !0, mode: \"chat\", supports_tool_choice: !0 },\n  \"together_ai/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\": { litellm_provider: \"together_ai\", supports_function_calling: !0, supports_parallel_function_calling: !0, mode: \"chat\", supports_tool_choice: !0 },\n  \"together_ai/meta-llama/Llama-4-Scout-17B-16E-Instruct\": { litellm_provider: \"together_ai\", supports_function_calling: !0, supports_parallel_function_calling: !0, mode: \"chat\", supports_tool_choice: !0 },\n  \"together_ai/meta-llama/Llama-3.2-3B-Instruct-Turbo\": { litellm_provider: \"together_ai\", supports_function_calling: !0, supports_parallel_function_calling: !0, mode: \"chat\", supports_tool_choice: !0 },\n  \"together_ai/Qwen/Qwen2.5-7B-Instruct-Turbo\": { litellm_provider: \"together_ai\", supports_function_calling: !0, supports_parallel_function_calling: !0, mode: \"chat\", supports_tool_choice: !0 },\n  \"together_ai/Qwen/Qwen2.5-72B-Instruct-Turbo\": { litellm_provider: \"together_ai\", supports_function_calling: !0, supports_parallel_function_calling: !0, mode: \"chat\", supports_tool_choice: !0 },\n  \"together_ai/deepseek-ai/DeepSeek-V3\": { litellm_provider: \"together_ai\", supports_function_calling: !0, supports_parallel_function_calling: !0, mode: \"chat\", supports_tool_choice: !0 },\n  \"together_ai/mistralai/Mistral-Small-24B-Instruct-2501\": { litellm_provider: \"together_ai\", supports_function_calling: !0, supports_parallel_function_calling: !0, mode: \"chat\", supports_tool_choice: !0 },\n  \"ollama/codegemma\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"completion\" },\n  \"ollama/codegeex4\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"chat\", supports_function_calling: !1 },\n  \"ollama/deepseek-coder-v2-instruct\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"chat\", supports_function_calling: !0 },\n  \"ollama/deepseek-coder-v2-base\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"completion\", supports_function_calling: !0 },\n  \"ollama/deepseek-coder-v2-lite-instruct\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"chat\", supports_function_calling: !0 },\n  \"ollama/deepseek-coder-v2-lite-base\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"completion\", supports_function_calling: !0 },\n  \"ollama/internlm2_5-20b-chat\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"chat\", supports_function_calling: !0 },\n  \"ollama/llama2\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"chat\" },\n  \"ollama/llama2:7b\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"chat\" },\n  \"ollama/llama2:13b\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"chat\" },\n  \"ollama/llama2:70b\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"chat\" },\n  \"ollama/llama2-uncensored\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"completion\" },\n  \"ollama/llama3\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"chat\" },\n  \"ollama/llama3:8b\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"chat\" },\n  \"ollama/llama3:70b\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"chat\" },\n  \"ollama/llama3.1\": { max_tokens: 32768, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"chat\", supports_function_calling: !0 },\n  \"ollama/mistral-large-instruct-2407\": { max_tokens: 65536, max_input_tokens: 65536, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"chat\", supports_function_calling: !0 },\n  \"ollama/mistral\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"completion\", supports_function_calling: !0 },\n  \"ollama/mistral-7B-Instruct-v0.1\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"chat\", supports_function_calling: !0 },\n  \"ollama/mistral-7B-Instruct-v0.2\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"chat\", supports_function_calling: !0 },\n  \"ollama/mixtral-8x7B-Instruct-v0.1\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"chat\", supports_function_calling: !0 },\n  \"ollama/mixtral-8x22B-Instruct-v0.1\": { max_tokens: 65536, max_input_tokens: 65536, max_output_tokens: 65536, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"chat\", supports_function_calling: !0 },\n  \"ollama/codellama\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"completion\" },\n  \"ollama/orca-mini\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"completion\" },\n  \"ollama/vicuna\": { max_tokens: 2048, max_input_tokens: 2048, max_output_tokens: 2048, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"ollama\", mode: \"completion\" },\n  \"deepinfra/lizpreciatior/lzlv_70b_fp16_hf\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 7e-7, output_cost_per_token: 9e-7, litellm_provider: \"deepinfra\", mode: \"chat\", supports_tool_choice: !0 },\n  \"deepinfra/Gryphe/MythoMax-L2-13b\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 22e-8, output_cost_per_token: 22e-8, litellm_provider: \"deepinfra\", mode: \"chat\", supports_tool_choice: !0 },\n  \"deepinfra/mistralai/Mistral-7B-Instruct-v0.1\": { max_tokens: 8191, max_input_tokens: 32768, max_output_tokens: 8191, input_cost_per_token: 13e-8, output_cost_per_token: 13e-8, litellm_provider: \"deepinfra\", mode: \"chat\", supports_tool_choice: !0 },\n  \"deepinfra/meta-llama/Llama-2-70b-chat-hf\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 7e-7, output_cost_per_token: 9e-7, litellm_provider: \"deepinfra\", mode: \"chat\", supports_tool_choice: !0 },\n  \"deepinfra/cognitivecomputations/dolphin-2.6-mixtral-8x7b\": { max_tokens: 8191, max_input_tokens: 32768, max_output_tokens: 8191, input_cost_per_token: 27e-8, output_cost_per_token: 27e-8, litellm_provider: \"deepinfra\", mode: \"chat\", supports_tool_choice: !0 },\n  \"deepinfra/codellama/CodeLlama-34b-Instruct-hf\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 6e-7, output_cost_per_token: 6e-7, litellm_provider: \"deepinfra\", mode: \"chat\", supports_tool_choice: !0 },\n  \"deepinfra/deepinfra/mixtral\": { max_tokens: 4096, max_input_tokens: 32e3, max_output_tokens: 4096, input_cost_per_token: 27e-8, output_cost_per_token: 27e-8, litellm_provider: \"deepinfra\", mode: \"completion\" },\n  \"deepinfra/Phind/Phind-CodeLlama-34B-v2\": { max_tokens: 4096, max_input_tokens: 16384, max_output_tokens: 4096, input_cost_per_token: 6e-7, output_cost_per_token: 6e-7, litellm_provider: \"deepinfra\", mode: \"chat\", supports_tool_choice: !0 },\n  \"deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1\": { max_tokens: 8191, max_input_tokens: 32768, max_output_tokens: 8191, input_cost_per_token: 27e-8, output_cost_per_token: 27e-8, litellm_provider: \"deepinfra\", mode: \"chat\", supports_tool_choice: !0 },\n  \"deepinfra/deepinfra/airoboros-70b\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 7e-7, output_cost_per_token: 9e-7, litellm_provider: \"deepinfra\", mode: \"chat\", supports_tool_choice: !0 },\n  \"deepinfra/01-ai/Yi-34B-Chat\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 6e-7, output_cost_per_token: 6e-7, litellm_provider: \"deepinfra\", mode: \"chat\", supports_tool_choice: !0 },\n  \"deepinfra/01-ai/Yi-6B-200K\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 13e-8, output_cost_per_token: 13e-8, litellm_provider: \"deepinfra\", mode: \"completion\" },\n  \"deepinfra/jondurbin/airoboros-l2-70b-gpt4-1.4.1\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 7e-7, output_cost_per_token: 9e-7, litellm_provider: \"deepinfra\", mode: \"chat\", supports_tool_choice: !0 },\n  \"deepinfra/meta-llama/Llama-2-13b-chat-hf\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 22e-8, output_cost_per_token: 22e-8, litellm_provider: \"deepinfra\", mode: \"chat\", supports_tool_choice: !0 },\n  \"deepinfra/amazon/MistralLite\": { max_tokens: 8191, max_input_tokens: 32768, max_output_tokens: 8191, input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: \"deepinfra\", mode: \"chat\", supports_tool_choice: !0 },\n  \"deepinfra/meta-llama/Llama-2-7b-chat-hf\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 13e-8, output_cost_per_token: 13e-8, litellm_provider: \"deepinfra\", mode: \"chat\", supports_tool_choice: !0 },\n  \"deepinfra/meta-llama/Meta-Llama-3-8B-Instruct\": { max_tokens: 8191, max_input_tokens: 8191, max_output_tokens: 4096, input_cost_per_token: 8e-8, output_cost_per_token: 8e-8, litellm_provider: \"deepinfra\", mode: \"chat\", supports_tool_choice: !0 },\n  \"deepinfra/meta-llama/Meta-Llama-3-70B-Instruct\": { max_tokens: 8191, max_input_tokens: 8191, max_output_tokens: 4096, input_cost_per_token: 59e-8, output_cost_per_token: 79e-8, litellm_provider: \"deepinfra\", mode: \"chat\", supports_tool_choice: !0 },\n  \"deepinfra/meta-llama/Meta-Llama-3.1-405B-Instruct\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: \"deepinfra\", mode: \"chat\", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_tool_choice: !0 },\n  \"deepinfra/01-ai/Yi-34B-200K\": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 6e-7, output_cost_per_token: 6e-7, litellm_provider: \"deepinfra\", mode: \"completion\" },\n  \"deepinfra/openchat/openchat_3.5\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 13e-8, output_cost_per_token: 13e-8, litellm_provider: \"deepinfra\", mode: \"chat\", supports_tool_choice: !0 },\n  \"perplexity/codellama-34b-instruct\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 35e-8, output_cost_per_token: 14e-7, litellm_provider: \"perplexity\", mode: \"chat\" },\n  \"perplexity/codellama-70b-instruct\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 7e-7, output_cost_per_token: 28e-7, litellm_provider: \"perplexity\", mode: \"chat\" },\n  \"perplexity/llama-3.1-70b-instruct\": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 1e-6, output_cost_per_token: 1e-6, litellm_provider: \"perplexity\", mode: \"chat\" },\n  \"perplexity/llama-3.1-8b-instruct\": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: \"perplexity\", mode: \"chat\" },\n  \"perplexity/llama-3.1-sonar-huge-128k-online\": { max_tokens: 127072, max_input_tokens: 127072, max_output_tokens: 127072, input_cost_per_token: 5e-6, output_cost_per_token: 5e-6, litellm_provider: \"perplexity\", mode: \"chat\", deprecation_date: \"2025-02-22\" },\n  \"perplexity/llama-3.1-sonar-large-128k-online\": { max_tokens: 127072, max_input_tokens: 127072, max_output_tokens: 127072, input_cost_per_token: 1e-6, output_cost_per_token: 1e-6, litellm_provider: \"perplexity\", mode: \"chat\", deprecation_date: \"2025-02-22\" },\n  \"perplexity/llama-3.1-sonar-large-128k-chat\": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 1e-6, output_cost_per_token: 1e-6, litellm_provider: \"perplexity\", mode: \"chat\", deprecation_date: \"2025-02-22\" },\n  \"perplexity/llama-3.1-sonar-small-128k-chat\": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: \"perplexity\", mode: \"chat\", deprecation_date: \"2025-02-22\" },\n  \"perplexity/llama-3.1-sonar-small-128k-online\": { max_tokens: 127072, max_input_tokens: 127072, max_output_tokens: 127072, input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: \"perplexity\", mode: \"chat\", deprecation_date: \"2025-02-22\" },\n  \"perplexity/pplx-7b-chat\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 7e-8, output_cost_per_token: 28e-8, litellm_provider: \"perplexity\", mode: \"chat\" },\n  \"perplexity/pplx-70b-chat\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 7e-7, output_cost_per_token: 28e-7, litellm_provider: \"perplexity\", mode: \"chat\" },\n  \"perplexity/pplx-7b-online\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 28e-8, input_cost_per_request: 5e-3, litellm_provider: \"perplexity\", mode: \"chat\" },\n  \"perplexity/pplx-70b-online\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 28e-7, input_cost_per_request: 5e-3, litellm_provider: \"perplexity\", mode: \"chat\" },\n  \"perplexity/llama-2-70b-chat\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 7e-7, output_cost_per_token: 28e-7, litellm_provider: \"perplexity\", mode: \"chat\" },\n  \"perplexity/mistral-7b-instruct\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 7e-8, output_cost_per_token: 28e-8, litellm_provider: \"perplexity\", mode: \"chat\" },\n  \"perplexity/mixtral-8x7b-instruct\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 7e-8, output_cost_per_token: 28e-8, litellm_provider: \"perplexity\", mode: \"chat\" },\n  \"perplexity/sonar-small-chat\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 7e-8, output_cost_per_token: 28e-8, litellm_provider: \"perplexity\", mode: \"chat\" },\n  \"perplexity/sonar-small-online\": { max_tokens: 12e3, max_input_tokens: 12e3, max_output_tokens: 12e3, input_cost_per_token: 0, output_cost_per_token: 28e-8, input_cost_per_request: 5e-3, litellm_provider: \"perplexity\", mode: \"chat\" },\n  \"perplexity/sonar-medium-chat\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 6e-7, output_cost_per_token: 18e-7, litellm_provider: \"perplexity\", mode: \"chat\" },\n  \"perplexity/sonar-medium-online\": { max_tokens: 12e3, max_input_tokens: 12e3, max_output_tokens: 12e3, input_cost_per_token: 0, output_cost_per_token: 18e-7, input_cost_per_request: 5e-3, litellm_provider: \"perplexity\", mode: \"chat\" },\n  \"perplexity/sonar\": { max_tokens: 128e3, max_input_tokens: 128e3, input_cost_per_token: 1e-6, output_cost_per_token: 1e-6, litellm_provider: \"perplexity\", mode: \"chat\", search_context_cost_per_query: { search_context_size_low: 5e-3, search_context_size_medium: 8e-3, search_context_size_high: 0.012 }, supports_web_search: !0 },\n  \"perplexity/sonar-pro\": { max_tokens: 8e3, max_input_tokens: 2e5, max_output_tokens: 8e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: \"perplexity\", mode: \"chat\", search_context_cost_per_query: { search_context_size_low: 6e-3, search_context_size_medium: 0.01, search_context_size_high: 0.014 }, supports_web_search: !0 },\n  \"perplexity/sonar-reasoning\": { max_tokens: 128e3, max_input_tokens: 128e3, input_cost_per_token: 1e-6, output_cost_per_token: 5e-6, litellm_provider: \"perplexity\", mode: \"chat\", search_context_cost_per_query: { search_context_size_low: 5e-3, search_context_size_medium: 8e-3, search_context_size_high: 0.014 }, supports_web_search: !0, supports_reasoning: !0 },\n  \"perplexity/sonar-reasoning-pro\": { max_tokens: 128e3, max_input_tokens: 128e3, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, litellm_provider: \"perplexity\", mode: \"chat\", search_context_cost_per_query: { search_context_size_low: 6e-3, search_context_size_medium: 0.01, search_context_size_high: 0.014 }, supports_web_search: !0, supports_reasoning: !0 },\n  \"perplexity/sonar-deep-research\": { max_tokens: 128e3, max_input_tokens: 128e3, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, output_cost_per_reasoning_token: 3e-6, litellm_provider: \"perplexity\", mode: \"chat\", search_context_cost_per_query: { search_context_size_low: 5e-3, search_context_size_medium: 5e-3, search_context_size_high: 5e-3 }, supports_reasoning: !0, supports_web_search: !0 },\n  \"fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 1e-7, output_cost_per_token: 1e-7, litellm_provider: \"fireworks_ai\", mode: \"chat\", supports_function_calling: !1, supports_response_schema: !0, source: \"https://fireworks.ai/pricing\", supports_tool_choice: !1 },\n  \"fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 1e-7, output_cost_per_token: 1e-7, litellm_provider: \"fireworks_ai\", mode: \"chat\", supports_function_calling: !1, supports_response_schema: !0, source: \"https://fireworks.ai/pricing\", supports_tool_choice: !1 },\n  \"fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 1e-7, output_cost_per_token: 1e-7, litellm_provider: \"fireworks_ai\", mode: \"chat\", supports_function_calling: !1, supports_response_schema: !0, source: \"https://fireworks.ai/pricing\", supports_tool_choice: !1 },\n  \"fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: \"fireworks_ai\", mode: \"chat\", supports_function_calling: !1, supports_vision: !0, supports_response_schema: !0, source: \"https://fireworks.ai/pricing\", supports_tool_choice: !1 },\n  \"fireworks_ai/accounts/fireworks/models/llama-v3p2-90b-vision-instruct\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: \"fireworks_ai\", mode: \"chat\", supports_tool_choice: !1, supports_vision: !0, supports_response_schema: !0, source: \"https://fireworks.ai/pricing\" },\n  \"fireworks_ai/accounts/fireworks/models/firefunction-v2\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: \"fireworks_ai\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, source: \"https://fireworks.ai/pricing\", supports_tool_choice: !0 },\n  \"fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf\": { max_tokens: 65536, max_input_tokens: 65536, max_output_tokens: 65536, input_cost_per_token: 12e-7, output_cost_per_token: 12e-7, litellm_provider: \"fireworks_ai\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, source: \"https://fireworks.ai/pricing\", supports_tool_choice: !0 },\n  \"fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: \"fireworks_ai\", mode: \"chat\", supports_function_calling: !1, supports_response_schema: !0, source: \"https://fireworks.ai/pricing\", supports_tool_choice: !1 },\n  \"fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: \"fireworks_ai\", mode: \"chat\", supports_function_calling: !1, supports_response_schema: !0, source: \"https://fireworks.ai/pricing\", supports_tool_choice: !1 },\n  \"fireworks_ai/accounts/fireworks/models/yi-large\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 3e-6, output_cost_per_token: 3e-6, litellm_provider: \"fireworks_ai\", mode: \"chat\", supports_function_calling: !1, supports_response_schema: !0, source: \"https://fireworks.ai/pricing\", supports_tool_choice: !1 },\n  \"fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct\": { max_tokens: 65536, max_input_tokens: 65536, max_output_tokens: 65536, input_cost_per_token: 12e-7, output_cost_per_token: 12e-7, litellm_provider: \"fireworks_ai\", mode: \"chat\", supports_function_calling: !1, supports_response_schema: !0, source: \"https://fireworks.ai/pricing\", supports_tool_choice: !1 },\n  \"fireworks_ai/accounts/fireworks/models/deepseek-v3\": { max_tokens: 8192, max_input_tokens: 128e3, max_output_tokens: 8192, input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: \"fireworks_ai\", mode: \"chat\", supports_response_schema: !0, source: \"https://fireworks.ai/pricing\", supports_tool_choice: !1 },\n  \"fireworks_ai/accounts/fireworks/models/deepseek-r1\": { max_tokens: 20480, max_input_tokens: 128e3, max_output_tokens: 20480, input_cost_per_token: 3e-6, output_cost_per_token: 8e-6, litellm_provider: \"fireworks_ai\", mode: \"chat\", supports_response_schema: !0, source: \"https://fireworks.ai/pricing\", supports_tool_choice: !1 },\n  \"fireworks_ai/accounts/fireworks/models/deepseek-r1-basic\": { max_tokens: 20480, max_input_tokens: 128e3, max_output_tokens: 20480, input_cost_per_token: 55e-8, output_cost_per_token: 219e-8, litellm_provider: \"fireworks_ai\", mode: \"chat\", supports_response_schema: !0, source: \"https://fireworks.ai/pricing\", supports_tool_choice: !1 },\n  \"fireworks_ai/accounts/fireworks/models/deepseek-r1-0528\": { max_tokens: 16e4, max_input_tokens: 16e4, max_output_tokens: 16e4, input_cost_per_token: 3e-6, output_cost_per_token: 8e-6, litellm_provider: \"fireworks_ai\", mode: \"chat\", source: \"https://fireworks.ai/pricing\", supports_tool_choice: !1, supports_response_schema: !0 },\n  \"fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct\": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 3e-6, output_cost_per_token: 3e-6, litellm_provider: \"fireworks_ai\", mode: \"chat\", supports_response_schema: !0, source: \"https://fireworks.ai/pricing\", supports_tool_choice: !0, supports_function_calling: !0 },\n  \"fireworks_ai/accounts/fireworks/models/llama4-maverick-instruct-basic\": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 22e-8, output_cost_per_token: 88e-8, litellm_provider: \"fireworks_ai\", mode: \"chat\", supports_response_schema: !0, source: \"https://fireworks.ai/pricing\", supports_tool_choice: !1 },\n  \"fireworks_ai/accounts/fireworks/models/llama4-scout-instruct-basic\": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, litellm_provider: \"fireworks_ai\", mode: \"chat\", supports_response_schema: !0, source: \"https://fireworks.ai/pricing\", supports_tool_choice: !1 },\n  \"fireworks_ai/nomic-ai/nomic-embed-text-v1.5\": { max_tokens: 8192, max_input_tokens: 8192, input_cost_per_token: 8e-9, output_cost_per_token: 0, litellm_provider: \"fireworks_ai-embedding-models\", mode: \"embedding\", source: \"https://fireworks.ai/pricing\" },\n  \"fireworks_ai/nomic-ai/nomic-embed-text-v1\": { max_tokens: 8192, max_input_tokens: 8192, input_cost_per_token: 8e-9, output_cost_per_token: 0, litellm_provider: \"fireworks_ai-embedding-models\", mode: \"embedding\", source: \"https://fireworks.ai/pricing\" },\n  \"fireworks_ai/WhereIsAI/UAE-Large-V1\": { max_tokens: 512, max_input_tokens: 512, input_cost_per_token: 16e-9, output_cost_per_token: 0, litellm_provider: \"fireworks_ai-embedding-models\", mode: \"embedding\", source: \"https://fireworks.ai/pricing\" },\n  \"fireworks_ai/thenlper/gte-large\": { max_tokens: 512, max_input_tokens: 512, input_cost_per_token: 16e-9, output_cost_per_token: 0, litellm_provider: \"fireworks_ai-embedding-models\", mode: \"embedding\", source: \"https://fireworks.ai/pricing\" },\n  \"fireworks_ai/thenlper/gte-base\": { max_tokens: 512, max_input_tokens: 512, input_cost_per_token: 8e-9, output_cost_per_token: 0, litellm_provider: \"fireworks_ai-embedding-models\", mode: \"embedding\", source: \"https://fireworks.ai/pricing\" },\n  \"fireworks-ai-up-to-4b\": { input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: \"fireworks_ai\" },\n  \"fireworks-ai-4.1b-to-16b\": { input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: \"fireworks_ai\" },\n  \"fireworks-ai-above-16b\": { input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: \"fireworks_ai\" },\n  \"fireworks-ai-moe-up-to-56b\": { input_cost_per_token: 5e-7, output_cost_per_token: 5e-7, litellm_provider: \"fireworks_ai\" },\n  \"fireworks-ai-56b-to-176b\": { input_cost_per_token: 12e-7, output_cost_per_token: 12e-7, litellm_provider: \"fireworks_ai\" },\n  \"fireworks-ai-default\": { input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: \"fireworks_ai\" },\n  \"fireworks-ai-embedding-up-to-150m\": { input_cost_per_token: 8e-9, output_cost_per_token: 0, litellm_provider: \"fireworks_ai-embedding-models\" },\n  \"fireworks-ai-embedding-150m-to-350m\": { input_cost_per_token: 16e-9, output_cost_per_token: 0, litellm_provider: \"fireworks_ai-embedding-models\" },\n  \"anyscale/mistralai/Mistral-7B-Instruct-v0.1\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: \"anyscale\", mode: \"chat\", supports_function_calling: !0, source: \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mistral-7B-Instruct-v0.1\" },\n  \"anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: \"anyscale\", mode: \"chat\", supports_function_calling: !0, source: \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x7B-Instruct-v0.1\" },\n  \"anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1\": { max_tokens: 65536, max_input_tokens: 65536, max_output_tokens: 65536, input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: \"anyscale\", mode: \"chat\", supports_function_calling: !0, source: \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x22B-Instruct-v0.1\" },\n  \"anyscale/HuggingFaceH4/zephyr-7b-beta\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: \"anyscale\", mode: \"chat\" },\n  \"anyscale/google/gemma-7b-it\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: \"anyscale\", mode: \"chat\", source: \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/google-gemma-7b-it\" },\n  \"anyscale/meta-llama/Llama-2-7b-chat-hf\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: \"anyscale\", mode: \"chat\" },\n  \"anyscale/meta-llama/Llama-2-13b-chat-hf\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 25e-8, output_cost_per_token: 25e-8, litellm_provider: \"anyscale\", mode: \"chat\" },\n  \"anyscale/meta-llama/Llama-2-70b-chat-hf\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 1e-6, output_cost_per_token: 1e-6, litellm_provider: \"anyscale\", mode: \"chat\" },\n  \"anyscale/codellama/CodeLlama-34b-Instruct-hf\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 1e-6, output_cost_per_token: 1e-6, litellm_provider: \"anyscale\", mode: \"chat\" },\n  \"anyscale/codellama/CodeLlama-70b-Instruct-hf\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 1e-6, output_cost_per_token: 1e-6, litellm_provider: \"anyscale\", mode: \"chat\", source: \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/codellama-CodeLlama-70b-Instruct-hf\" },\n  \"anyscale/meta-llama/Meta-Llama-3-8B-Instruct\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: \"anyscale\", mode: \"chat\", source: \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-8B-Instruct\" },\n  \"anyscale/meta-llama/Meta-Llama-3-70B-Instruct\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 1e-6, output_cost_per_token: 1e-6, litellm_provider: \"anyscale\", mode: \"chat\", source: \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-70B-Instruct\" },\n  \"cloudflare/@cf/meta/llama-2-7b-chat-fp16\": { max_tokens: 3072, max_input_tokens: 3072, max_output_tokens: 3072, input_cost_per_token: 1923e-9, output_cost_per_token: 1923e-9, litellm_provider: \"cloudflare\", mode: \"chat\" },\n  \"cloudflare/@cf/meta/llama-2-7b-chat-int8\": { max_tokens: 2048, max_input_tokens: 2048, max_output_tokens: 2048, input_cost_per_token: 1923e-9, output_cost_per_token: 1923e-9, litellm_provider: \"cloudflare\", mode: \"chat\" },\n  \"cloudflare/@cf/mistral/mistral-7b-instruct-v0.1\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 1923e-9, output_cost_per_token: 1923e-9, litellm_provider: \"cloudflare\", mode: \"chat\" },\n  \"cloudflare/@hf/thebloke/codellama-7b-instruct-awq\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 1923e-9, output_cost_per_token: 1923e-9, litellm_provider: \"cloudflare\", mode: \"chat\" },\n  \"voyage/voyage-01\": { max_tokens: 4096, max_input_tokens: 4096, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"voyage\", mode: \"embedding\" },\n  \"voyage/voyage-lite-01\": { max_tokens: 4096, max_input_tokens: 4096, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"voyage\", mode: \"embedding\" },\n  \"voyage/voyage-large-2\": { max_tokens: 16e3, max_input_tokens: 16e3, input_cost_per_token: 12e-8, output_cost_per_token: 0, litellm_provider: \"voyage\", mode: \"embedding\" },\n  \"voyage/voyage-finance-2\": { max_tokens: 32e3, max_input_tokens: 32e3, input_cost_per_token: 12e-8, output_cost_per_token: 0, litellm_provider: \"voyage\", mode: \"embedding\" },\n  \"voyage/voyage-lite-02-instruct\": { max_tokens: 4e3, max_input_tokens: 4e3, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"voyage\", mode: \"embedding\" },\n  \"voyage/voyage-law-2\": { max_tokens: 16e3, max_input_tokens: 16e3, input_cost_per_token: 12e-8, output_cost_per_token: 0, litellm_provider: \"voyage\", mode: \"embedding\" },\n  \"voyage/voyage-code-2\": { max_tokens: 16e3, max_input_tokens: 16e3, input_cost_per_token: 12e-8, output_cost_per_token: 0, litellm_provider: \"voyage\", mode: \"embedding\" },\n  \"voyage/voyage-2\": { max_tokens: 4e3, max_input_tokens: 4e3, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: \"voyage\", mode: \"embedding\" },\n  \"voyage/voyage-3-large\": { max_tokens: 32e3, max_input_tokens: 32e3, input_cost_per_token: 18e-8, output_cost_per_token: 0, litellm_provider: \"voyage\", mode: \"embedding\" },\n  \"voyage/voyage-3\": { max_tokens: 32e3, max_input_tokens: 32e3, input_cost_per_token: 6e-8, output_cost_per_token: 0, litellm_provider: \"voyage\", mode: \"embedding\" },\n  \"voyage/voyage-3-lite\": { max_tokens: 32e3, max_input_tokens: 32e3, input_cost_per_token: 2e-8, output_cost_per_token: 0, litellm_provider: \"voyage\", mode: \"embedding\" },\n  \"voyage/voyage-code-3\": { max_tokens: 32e3, max_input_tokens: 32e3, input_cost_per_token: 18e-8, output_cost_per_token: 0, litellm_provider: \"voyage\", mode: \"embedding\" },\n  \"voyage/voyage-multimodal-3\": { max_tokens: 32e3, max_input_tokens: 32e3, input_cost_per_token: 12e-8, output_cost_per_token: 0, litellm_provider: \"voyage\", mode: \"embedding\" },\n  \"voyage/rerank-2\": { max_tokens: 16e3, max_input_tokens: 16e3, max_output_tokens: 16e3, max_query_tokens: 16e3, input_cost_per_token: 5e-8, input_cost_per_query: 5e-8, output_cost_per_token: 0, litellm_provider: \"voyage\", mode: \"rerank\" },\n  \"voyage/rerank-2-lite\": { max_tokens: 8e3, max_input_tokens: 8e3, max_output_tokens: 8e3, max_query_tokens: 8e3, input_cost_per_token: 2e-8, input_cost_per_query: 2e-8, output_cost_per_token: 0, litellm_provider: \"voyage\", mode: \"rerank\" },\n  \"databricks/databricks-claude-3-7-sonnet\": { max_tokens: 2e5, max_input_tokens: 2e5, max_output_tokens: 128e3, input_cost_per_token: 25e-7, input_dbu_cost_per_token: 3571e-8, output_cost_per_token: 17857e-9, output_db_cost_per_token: 214286e-9, litellm_provider: \"databricks\", mode: \"chat\", source: \"https://www.databricks.com/product/pricing/foundation-model-serving\", metadata: { notes: \"Input/output cost per token is dbu cost * $0.070, based on databricks Claude 3.7 conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\" }, supports_assistant_prefill: !0, supports_function_calling: !0, supports_tool_choice: !0, supports_reasoning: !0 },\n  \"databricks/databricks-meta-llama-3-1-405b-instruct\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 5e-6, input_dbu_cost_per_token: 71429e-9, output_cost_per_token: 1500002e-11, output_db_cost_per_token: 214286e-9, litellm_provider: \"databricks\", mode: \"chat\", source: \"https://www.databricks.com/product/pricing/foundation-model-serving\", metadata: { notes: \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\" }, supports_tool_choice: !0 },\n  \"databricks/databricks-meta-llama-3-1-70b-instruct\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 100002e-11, input_dbu_cost_per_token: 14286e-9, output_cost_per_token: 299999e-11, output_dbu_cost_per_token: 42857e-9, litellm_provider: \"databricks\", mode: \"chat\", source: \"https://www.databricks.com/product/pricing/foundation-model-serving\", metadata: { notes: \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\" }, supports_tool_choice: !0 },\n  \"databricks/databricks-meta-llama-3-3-70b-instruct\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 100002e-11, input_dbu_cost_per_token: 14286e-9, output_cost_per_token: 299999e-11, output_dbu_cost_per_token: 42857e-9, litellm_provider: \"databricks\", mode: \"chat\", source: \"https://www.databricks.com/product/pricing/foundation-model-serving\", metadata: { notes: \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\" }, supports_tool_choice: !0 },\n  \"databricks/databricks-llama-4-maverick\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 5e-6, input_dbu_cost_per_token: 7143e-8, output_cost_per_token: 15e-6, output_dbu_cost_per_token: 21429e-8, litellm_provider: \"databricks\", mode: \"chat\", source: \"https://www.databricks.com/product/pricing/foundation-model-serving\", metadata: { notes: \"Databricks documentation now provides both DBU costs (_dbu_cost_per_token) and dollar costs(_cost_per_token).\" }, supports_tool_choice: !0 },\n  \"databricks/databricks-dbrx-instruct\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 74998e-11, input_dbu_cost_per_token: 10714e-9, output_cost_per_token: 224901e-11, output_dbu_cost_per_token: 32143e-9, litellm_provider: \"databricks\", mode: \"chat\", source: \"https://www.databricks.com/product/pricing/foundation-model-serving\", metadata: { notes: \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\" }, supports_tool_choice: !0 },\n  \"databricks/databricks-meta-llama-3-70b-instruct\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 100002e-11, input_dbu_cost_per_token: 14286e-9, output_cost_per_token: 299999e-11, output_dbu_cost_per_token: 42857e-9, litellm_provider: \"databricks\", mode: \"chat\", source: \"https://www.databricks.com/product/pricing/foundation-model-serving\", metadata: { notes: \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\" }, supports_tool_choice: !0 },\n  \"databricks/databricks-llama-2-70b-chat\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 50001e-11, input_dbu_cost_per_token: 7143e-9, output_cost_per_token: 15e-7, output_dbu_cost_per_token: 21429e-9, litellm_provider: \"databricks\", mode: \"chat\", source: \"https://www.databricks.com/product/pricing/foundation-model-serving\", metadata: { notes: \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\" }, supports_tool_choice: !0 },\n  \"databricks/databricks-mixtral-8x7b-instruct\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 50001e-11, input_dbu_cost_per_token: 7143e-9, output_cost_per_token: 99902e-11, output_dbu_cost_per_token: 14286e-9, litellm_provider: \"databricks\", mode: \"chat\", source: \"https://www.databricks.com/product/pricing/foundation-model-serving\", metadata: { notes: \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\" }, supports_tool_choice: !0 },\n  \"databricks/databricks-mpt-30b-instruct\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 99902e-11, input_dbu_cost_per_token: 14286e-9, output_cost_per_token: 99902e-11, output_dbu_cost_per_token: 14286e-9, litellm_provider: \"databricks\", mode: \"chat\", source: \"https://www.databricks.com/product/pricing/foundation-model-serving\", metadata: { notes: \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\" }, supports_tool_choice: !0 },\n  \"databricks/databricks-mpt-7b-instruct\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 50001e-11, input_dbu_cost_per_token: 7143e-9, output_cost_per_token: 0, output_dbu_cost_per_token: 0, litellm_provider: \"databricks\", mode: \"chat\", source: \"https://www.databricks.com/product/pricing/foundation-model-serving\", metadata: { notes: \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\" }, supports_tool_choice: !0 },\n  \"databricks/databricks-bge-large-en\": { max_tokens: 512, max_input_tokens: 512, output_vector_size: 1024, input_cost_per_token: 10003e-11, input_dbu_cost_per_token: 1429e-9, output_cost_per_token: 0, output_dbu_cost_per_token: 0, litellm_provider: \"databricks\", mode: \"embedding\", source: \"https://www.databricks.com/product/pricing/foundation-model-serving\", metadata: { notes: \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\" } },\n  \"databricks/databricks-gte-large-en\": { max_tokens: 8192, max_input_tokens: 8192, output_vector_size: 1024, input_cost_per_token: 12999e-11, input_dbu_cost_per_token: 1857e-9, output_cost_per_token: 0, output_dbu_cost_per_token: 0, litellm_provider: \"databricks\", mode: \"embedding\", source: \"https://www.databricks.com/product/pricing/foundation-model-serving\", metadata: { notes: \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\" } },\n  \"sambanova/Meta-Llama-3.1-8B-Instruct\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 1e-7, output_cost_per_token: 2e-7, litellm_provider: \"sambanova\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !0, source: \"https://cloud.sambanova.ai/plans/pricing\" },\n  \"sambanova/Meta-Llama-3.1-405B-Instruct\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 5e-6, output_cost_per_token: 1e-5, litellm_provider: \"sambanova\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !0, source: \"https://cloud.sambanova.ai/plans/pricing\" },\n  \"sambanova/Meta-Llama-3.2-1B-Instruct\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 4e-8, output_cost_per_token: 8e-8, litellm_provider: \"sambanova\", mode: \"chat\", source: \"https://cloud.sambanova.ai/plans/pricing\" },\n  \"sambanova/Meta-Llama-3.2-3B-Instruct\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 8e-8, output_cost_per_token: 16e-8, litellm_provider: \"sambanova\", mode: \"chat\", source: \"https://cloud.sambanova.ai/plans/pricing\" },\n  \"sambanova/Llama-4-Maverick-17B-128E-Instruct\": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 63e-8, output_cost_per_token: 18e-7, litellm_provider: \"sambanova\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !0, supports_vision: !0, source: \"https://cloud.sambanova.ai/plans/pricing\", metadata: { notes: \"For vision models, images are converted to 6432 input tokens and are billed at that amount\" } },\n  \"sambanova/Llama-4-Scout-17B-16E-Instruct\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 4e-7, output_cost_per_token: 7e-7, litellm_provider: \"sambanova\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !0, source: \"https://cloud.sambanova.ai/plans/pricing\", metadata: { notes: \"For vision models, images are converted to 6432 input tokens and are billed at that amount\" } },\n  \"sambanova/Meta-Llama-3.3-70B-Instruct\": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 6e-7, output_cost_per_token: 12e-7, litellm_provider: \"sambanova\", mode: \"chat\", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0, source: \"https://cloud.sambanova.ai/plans/pricing\" },\n  \"sambanova/Meta-Llama-Guard-3-8B\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 3e-7, output_cost_per_token: 3e-7, litellm_provider: \"sambanova\", mode: \"chat\", source: \"https://cloud.sambanova.ai/plans/pricing\" },\n  \"sambanova/Qwen3-32B\": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 4e-7, output_cost_per_token: 8e-7, litellm_provider: \"sambanova\", supports_function_calling: !0, supports_tool_choice: !0, supports_reasoning: !0, mode: \"chat\", source: \"https://cloud.sambanova.ai/plans/pricing\" },\n  \"sambanova/QwQ-32B\": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 5e-7, output_cost_per_token: 1e-6, litellm_provider: \"sambanova\", mode: \"chat\", source: \"https://cloud.sambanova.ai/plans/pricing\" },\n  \"sambanova/Qwen2-Audio-7B-Instruct\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 5e-7, output_cost_per_token: 1e-4, litellm_provider: \"sambanova\", mode: \"chat\", supports_audio_input: !0, source: \"https://cloud.sambanova.ai/plans/pricing\" },\n  \"sambanova/DeepSeek-R1-Distill-Llama-70B\": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 7e-7, output_cost_per_token: 14e-7, litellm_provider: \"sambanova\", mode: \"chat\", source: \"https://cloud.sambanova.ai/plans/pricing\" },\n  \"sambanova/DeepSeek-R1\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 5e-6, output_cost_per_token: 7e-6, litellm_provider: \"sambanova\", mode: \"chat\", source: \"https://cloud.sambanova.ai/plans/pricing\" },\n  \"sambanova/DeepSeek-V3-0324\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 3e-6, output_cost_per_token: 45e-7, litellm_provider: \"sambanova\", mode: \"chat\", supports_function_calling: !0, supports_tool_choice: !0, supports_reasoning: !0, source: \"https://cloud.sambanova.ai/plans/pricing\" },\n  \"assemblyai/nano\": { mode: \"audio_transcription\", input_cost_per_second: 10278e-8, output_cost_per_second: 0, litellm_provider: \"assemblyai\" },\n  \"assemblyai/best\": { mode: \"audio_transcription\", input_cost_per_second: 3333e-8, output_cost_per_second: 0, litellm_provider: \"assemblyai\" },\n  \"jina-reranker-v2-base-multilingual\": { max_tokens: 1024, max_input_tokens: 1024, max_output_tokens: 1024, max_document_chunks_per_query: 2048, input_cost_per_token: 18e-9, output_cost_per_token: 18e-9, litellm_provider: \"jina_ai\", mode: \"rerank\" },\n  \"snowflake/deepseek-r1\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 8192, litellm_provider: \"snowflake\", supports_reasoning: !0, mode: \"chat\" },\n  \"snowflake/snowflake-arctic\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/claude-3-5-sonnet\": { supports_computer_use: !0, max_tokens: 18e3, max_input_tokens: 18e3, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/mistral-large\": { max_tokens: 32e3, max_input_tokens: 32e3, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/mistral-large2\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/reka-flash\": { max_tokens: 1e5, max_input_tokens: 1e5, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/reka-core\": { max_tokens: 32e3, max_input_tokens: 32e3, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/jamba-instruct\": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/jamba-1.5-mini\": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/jamba-1.5-large\": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/mixtral-8x7b\": { max_tokens: 32e3, max_input_tokens: 32e3, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/llama2-70b-chat\": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/llama3-8b\": { max_tokens: 8e3, max_input_tokens: 8e3, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/llama3-70b\": { max_tokens: 8e3, max_input_tokens: 8e3, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/llama3.1-8b\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/llama3.1-70b\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/llama3.3-70b\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/snowflake-llama-3.3-70b\": { max_tokens: 8e3, max_input_tokens: 8e3, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/llama3.1-405b\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/snowflake-llama-3.1-405b\": { max_tokens: 8e3, max_input_tokens: 8e3, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/llama3.2-1b\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/llama3.2-3b\": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/mistral-7b\": { max_tokens: 32e3, max_input_tokens: 32e3, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"snowflake/gemma-7b\": { max_tokens: 8e3, max_input_tokens: 8e3, max_output_tokens: 8192, litellm_provider: \"snowflake\", mode: \"chat\" },\n  \"nscale/meta-llama/Llama-4-Scout-17B-16E-Instruct\": { input_cost_per_token: 9e-8, output_cost_per_token: 29e-8, litellm_provider: \"nscale\", mode: \"chat\", source: \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\" },\n  \"nscale/Qwen/Qwen2.5-Coder-3B-Instruct\": { input_cost_per_token: 1e-8, output_cost_per_token: 3e-8, litellm_provider: \"nscale\", mode: \"chat\", source: \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\" },\n  \"nscale/Qwen/Qwen2.5-Coder-7B-Instruct\": { input_cost_per_token: 1e-8, output_cost_per_token: 3e-8, litellm_provider: \"nscale\", mode: \"chat\", source: \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\" },\n  \"nscale/Qwen/Qwen2.5-Coder-32B-Instruct\": { input_cost_per_token: 6e-8, output_cost_per_token: 2e-7, litellm_provider: \"nscale\", mode: \"chat\", source: \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\" },\n  \"nscale/Qwen/QwQ-32B\": { input_cost_per_token: 18e-8, output_cost_per_token: 2e-7, litellm_provider: \"nscale\", mode: \"chat\", source: \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\" },\n  \"nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-70B\": { input_cost_per_token: 375e-9, output_cost_per_token: 375e-9, litellm_provider: \"nscale\", mode: \"chat\", source: \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\", metadata: { notes: \"Pricing listed as $0.75/1M tokens total. Assumed 50/50 split for input/output.\" } },\n  \"nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-8B\": { input_cost_per_token: 25e-9, output_cost_per_token: 25e-9, litellm_provider: \"nscale\", mode: \"chat\", source: \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\", metadata: { notes: \"Pricing listed as $0.05/1M tokens total. Assumed 50/50 split for input/output.\" } },\n  \"nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\": { input_cost_per_token: 9e-8, output_cost_per_token: 9e-8, litellm_provider: \"nscale\", mode: \"chat\", source: \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\", metadata: { notes: \"Pricing listed as $0.18/1M tokens total. Assumed 50/50 split for input/output.\" } },\n  \"nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\": { input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: \"nscale\", mode: \"chat\", source: \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\", metadata: { notes: \"Pricing listed as $0.40/1M tokens total. Assumed 50/50 split for input/output.\" } },\n  \"nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\": { input_cost_per_token: 7e-8, output_cost_per_token: 7e-8, litellm_provider: \"nscale\", mode: \"chat\", source: \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\", metadata: { notes: \"Pricing listed as $0.14/1M tokens total. Assumed 50/50 split for input/output.\" } },\n  \"nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\": { input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: \"nscale\", mode: \"chat\", source: \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\", metadata: { notes: \"Pricing listed as $0.30/1M tokens total. Assumed 50/50 split for input/output.\" } },\n  \"nscale/mistralai/mixtral-8x22b-instruct-v0.1\": { input_cost_per_token: 6e-7, output_cost_per_token: 6e-7, litellm_provider: \"nscale\", mode: \"chat\", source: \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\", metadata: { notes: \"Pricing listed as $1.20/1M tokens total. Assumed 50/50 split for input/output.\" } },\n  \"nscale/meta-llama/Llama-3.1-8B-Instruct\": { input_cost_per_token: 3e-8, output_cost_per_token: 3e-8, litellm_provider: \"nscale\", mode: \"chat\", source: \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\", metadata: { notes: \"Pricing listed as $0.06/1M tokens total. Assumed 50/50 split for input/output.\" } },\n  \"nscale/meta-llama/Llama-3.3-70B-Instruct\": { input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: \"nscale\", mode: \"chat\", source: \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\", metadata: { notes: \"Pricing listed as $0.40/1M tokens total. Assumed 50/50 split for input/output.\" } },\n  \"nscale/black-forest-labs/FLUX.1-schnell\": { mode: \"image_generation\", input_cost_per_pixel: 13e-10, output_cost_per_pixel: 0, litellm_provider: \"nscale\", supported_endpoints: [\"/v1/images/generations\"], source: \"https://docs.nscale.com/docs/inference/serverless-models/current#image-models\" },\n  \"nscale/stabilityai/stable-diffusion-xl-base-1.0\": { mode: \"image_generation\", input_cost_per_pixel: 3e-9, output_cost_per_pixel: 0, litellm_provider: \"nscale\", supported_endpoints: [\"/v1/images/generations\"], source: \"https://docs.nscale.com/docs/inference/serverless-models/current#image-models\" },\n  \"featherless_ai/featherless-ai/Qwerky-72B\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 4096, litellm_provider: \"featherless_ai\", mode: \"chat\" },\n  \"featherless_ai/featherless-ai/Qwerky-QwQ-32B\": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 4096, litellm_provider: \"featherless_ai\", mode: \"chat\" },\n  \"deepgram/nova-3\": { mode: \"audio_transcription\", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 43e-4, calculation: \"$0.0043/60 seconds = $0.00007167 per second\" } },\n  \"deepgram/nova-3-general\": { mode: \"audio_transcription\", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 43e-4, calculation: \"$0.0043/60 seconds = $0.00007167 per second\" } },\n  \"deepgram/nova-3-medical\": { mode: \"audio_transcription\", input_cost_per_second: 8667e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 52e-4, calculation: \"$0.0052/60 seconds = $0.00008667 per second (multilingual)\" } },\n  \"deepgram/nova-2\": { mode: \"audio_transcription\", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 43e-4, calculation: \"$0.0043/60 seconds = $0.00007167 per second\" } },\n  \"deepgram/nova-2-general\": { mode: \"audio_transcription\", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 43e-4, calculation: \"$0.0043/60 seconds = $0.00007167 per second\" } },\n  \"deepgram/nova-2-meeting\": { mode: \"audio_transcription\", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 43e-4, calculation: \"$0.0043/60 seconds = $0.00007167 per second\" } },\n  \"deepgram/nova-2-phonecall\": { mode: \"audio_transcription\", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 43e-4, calculation: \"$0.0043/60 seconds = $0.00007167 per second\" } },\n  \"deepgram/nova-2-voicemail\": { mode: \"audio_transcription\", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 43e-4, calculation: \"$0.0043/60 seconds = $0.00007167 per second\" } },\n  \"deepgram/nova-2-finance\": { mode: \"audio_transcription\", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 43e-4, calculation: \"$0.0043/60 seconds = $0.00007167 per second\" } },\n  \"deepgram/nova-2-conversationalai\": { mode: \"audio_transcription\", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 43e-4, calculation: \"$0.0043/60 seconds = $0.00007167 per second\" } },\n  \"deepgram/nova-2-video\": { mode: \"audio_transcription\", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 43e-4, calculation: \"$0.0043/60 seconds = $0.00007167 per second\" } },\n  \"deepgram/nova-2-drivethru\": { mode: \"audio_transcription\", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 43e-4, calculation: \"$0.0043/60 seconds = $0.00007167 per second\" } },\n  \"deepgram/nova-2-automotive\": { mode: \"audio_transcription\", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 43e-4, calculation: \"$0.0043/60 seconds = $0.00007167 per second\" } },\n  \"deepgram/nova-2-atc\": { mode: \"audio_transcription\", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 43e-4, calculation: \"$0.0043/60 seconds = $0.00007167 per second\" } },\n  \"deepgram/nova\": { mode: \"audio_transcription\", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 43e-4, calculation: \"$0.0043/60 seconds = $0.00007167 per second\" } },\n  \"deepgram/nova-general\": { mode: \"audio_transcription\", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 43e-4, calculation: \"$0.0043/60 seconds = $0.00007167 per second\" } },\n  \"deepgram/nova-phonecall\": { mode: \"audio_transcription\", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 43e-4, calculation: \"$0.0043/60 seconds = $0.00007167 per second\" } },\n  \"deepgram/enhanced\": { mode: \"audio_transcription\", input_cost_per_second: 24167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 0.0145, calculation: \"$0.0145/60 seconds = $0.00024167 per second\" } },\n  \"deepgram/enhanced-general\": { mode: \"audio_transcription\", input_cost_per_second: 24167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 0.0145, calculation: \"$0.0145/60 seconds = $0.00024167 per second\" } },\n  \"deepgram/enhanced-meeting\": { mode: \"audio_transcription\", input_cost_per_second: 24167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 0.0145, calculation: \"$0.0145/60 seconds = $0.00024167 per second\" } },\n  \"deepgram/enhanced-phonecall\": { mode: \"audio_transcription\", input_cost_per_second: 24167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 0.0145, calculation: \"$0.0145/60 seconds = $0.00024167 per second\" } },\n  \"deepgram/enhanced-finance\": { mode: \"audio_transcription\", input_cost_per_second: 24167e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 0.0145, calculation: \"$0.0145/60 seconds = $0.00024167 per second\" } },\n  \"deepgram/base\": { mode: \"audio_transcription\", input_cost_per_second: 20833e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 0.0125, calculation: \"$0.0125/60 seconds = $0.00020833 per second\" } },\n  \"deepgram/base-general\": { mode: \"audio_transcription\", input_cost_per_second: 20833e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 0.0125, calculation: \"$0.0125/60 seconds = $0.00020833 per second\" } },\n  \"deepgram/base-meeting\": { mode: \"audio_transcription\", input_cost_per_second: 20833e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 0.0125, calculation: \"$0.0125/60 seconds = $0.00020833 per second\" } },\n  \"deepgram/base-phonecall\": { mode: \"audio_transcription\", input_cost_per_second: 20833e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 0.0125, calculation: \"$0.0125/60 seconds = $0.00020833 per second\" } },\n  \"deepgram/base-voicemail\": { mode: \"audio_transcription\", input_cost_per_second: 20833e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 0.0125, calculation: \"$0.0125/60 seconds = $0.00020833 per second\" } },\n  \"deepgram/base-finance\": { mode: \"audio_transcription\", input_cost_per_second: 20833e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 0.0125, calculation: \"$0.0125/60 seconds = $0.00020833 per second\" } },\n  \"deepgram/base-conversationalai\": { mode: \"audio_transcription\", input_cost_per_second: 20833e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 0.0125, calculation: \"$0.0125/60 seconds = $0.00020833 per second\" } },\n  \"deepgram/base-video\": { mode: \"audio_transcription\", input_cost_per_second: 20833e-8, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { original_pricing_per_minute: 0.0125, calculation: \"$0.0125/60 seconds = $0.00020833 per second\" } },\n  \"deepgram/whisper\": { mode: \"audio_transcription\", input_cost_per_second: 1e-4, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { notes: \"Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models\" } },\n  \"deepgram/whisper-tiny\": { mode: \"audio_transcription\", input_cost_per_second: 1e-4, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { notes: \"Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models\" } },\n  \"deepgram/whisper-base\": { mode: \"audio_transcription\", input_cost_per_second: 1e-4, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { notes: \"Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models\" } },\n  \"deepgram/whisper-small\": { mode: \"audio_transcription\", input_cost_per_second: 1e-4, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { notes: \"Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models\" } },\n  \"deepgram/whisper-medium\": { mode: \"audio_transcription\", input_cost_per_second: 1e-4, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { notes: \"Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models\" } },\n  \"deepgram/whisper-large\": { mode: \"audio_transcription\", input_cost_per_second: 1e-4, output_cost_per_second: 0, litellm_provider: \"deepgram\", supported_endpoints: [\"/v1/audio/transcriptions\"], source: \"https://deepgram.com/pricing\", metadata: { notes: \"Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models\" } }\n};\nlet g = {};\nconst v = class v {\n  constructor(t) {\n    this.service = t;\n  }\n  getModel(t, e = {}) {\n    return v.get(this.service, t, e);\n  }\n  async refresh() {\n    await v.refresh();\n  }\n  models() {\n    return v.getByService(this.service);\n  }\n  static get(t, e, o = {}) {\n    let _ = this.getByServiceModel(t, e);\n    return _ || (o.allowSimilar ? (_ = this.getByServiceModel(t, `${e}-latest`), _ || (_ = this.getByServiceModel(t, `${e}-beta`), _) || (_ = this.getByServiceModel(t, `${t}/${e}`), _) || (_ = this.getByServiceModel(t, `${t}/${e}-beta`), _) || (_ = this.getByServiceModel(t, e.replace(\"-beta\", \"\")), _) || (_ = this.getByServiceModel(t, e.replace(\"-thinking\", \"\")), _) || (_ = this.getByServiceModel(t, e.replace(\"-exp\", \"\")), _) || (_ = this.getByServiceModel(t, e.replace(\"-experimental\", \"\")), _) || (_ = this.getByServiceModel(t, e.replace(\"-thinking-exp\", \"\")), _) || (_ = this.getByServiceModel(t, e.replace(\"-preview\", \"\")), _) ? _ : null) : null);\n  }\n  static getAll() {\n    return this.factories(Q).filter(this.filter());\n  }\n  static getByService(t) {\n    return this.factories(Q).filter(this.filter(t));\n  }\n  static getByServiceModel(t, e) {\n    return this.getByService(t).find((o) => o.model === e) || null;\n  }\n  static filter(t) {\n    return (e) => e.mode !== \"chat\" && e.mode !== \"responses\" ? !1 : t === \"google\" && e.service === \"gemini\" ? !0 : t ? e.service === t : !0;\n  }\n  static factories(t) {\n    const e = Object.assign({}, t, g);\n    return Object.keys(e).map((o) => {\n      const _ = e[o], s = _.max_input_tokens || 0, r = _.max_output_tokens || 0, u = _.max_tokens ? _.max_tokens : s + r, n = _.input_cost_per_token || 0, c = _.output_cost_per_token || 0, i = _.output_cost_per_reasoning_token || 0, l = _.supported_modalities || [];\n      let F = o;\n      return o.includes(\"/\") && (F = o.split(\"/\").slice(1).join(\"/\")), {\n        service: _.litellm_provider || _.service,\n        mode: _.mode,\n        model: F,\n        max_tokens: u,\n        max_input_tokens: s,\n        max_output_tokens: r,\n        input_cost_per_token: n,\n        output_cost_per_token: c,\n        output_cost_per_reasoning_token: i,\n        supports_reasoning: _.supports_reasoning || !1,\n        supported_modalities: l\n      };\n    });\n  }\n  static async refresh(t) {\n    const o = await (await fetch(this.DEFAULT_BASE_URL)).json();\n    return this.factories(o).filter(this.filter(t));\n  }\n  static addCustom(t) {\n    g[`${t.service}/${t.model}`] = Object.assign({}, { mode: \"chat\" }, t);\n  }\n  static getCustom(t, e) {\n    return g[`${t}/${e}`] || null;\n  }\n  static getCustoms() {\n    return g;\n  }\n  static removeCustom(t, e) {\n    delete g[`${t}/${e}`];\n  }\n  static clearCustom() {\n    g = {};\n  }\n};\nv.DEFAULT_BASE_URL = \"https://raw.githubusercontent.com/BerriAI/litellm/refs/heads/main/model_prices_and_context_window.json\";\nlet B = v;\nconst Y = {\n  service: \"ollama\",\n  max_tokens: 1024\n}, R = j(\"llm.js:parsers\");\nfunction M(p) {\n  return function(t) {\n    try {\n      return t.split(\"```\" + p)[1].split(\"```\")[0].trim();\n    } catch (e) {\n      throw R.error(`error parsing code block of type ${p} from content`, t), e;\n    }\n  };\n}\nfunction rt(p) {\n  try {\n    return M(\"markdown\")(p);\n  } catch {\n    return M(\"md\")(p);\n  }\n}\nfunction W(p) {\n  try {\n    return JSON.parse(p);\n  } catch {\n    const e = M(\"json\");\n    try {\n      return JSON.parse(e(p));\n    } catch (o) {\n      throw R.error(\"error parsing json from content\", p), o;\n    }\n  }\n}\nfunction ut(p) {\n  return function(t) {\n    try {\n      const e = t.split(`<${p}>`)[1].split(`</${p}>`)[0].trim();\n      if (!e || e.length == 0)\n        throw new Error(`No content found inside of XML tag ${p}`);\n      return e;\n    } catch (e) {\n      throw R.error(`error parsing xml tag ${p} from content`, t), e;\n    }\n  };\n}\nconst H = /* @__PURE__ */ Object.freeze(/* @__PURE__ */ Object.defineProperty({\n  __proto__: null,\n  codeBlock: M,\n  json: W,\n  markdown: rt,\n  xml: ut\n}, Symbol.toStringTag, { value: \"Module\" })), nt = {}, it = j(\"llm.js:utils\");\nasync function J(p, t = \"Error while handling response\") {\n  if (p.ok) return !0;\n  let e;\n  try {\n    e = await p.json();\n  } catch {\n    let s = \"Unable to parse response\";\n    throw p.status && p.statusText && (s = `${p.status} ${p.statusText}`), new Error(s);\n  }\n  let o = t;\n  throw e.error && typeof e.error == \"string\" ? o = e.error : e.error && typeof e.error == \"object\" && e.error.type && e.error.message ? o = `${e.error.type}: ${e.error.message}` : e.error && typeof e.error == \"object\" && (o = JSON.stringify(e.error)), new Error(o);\n}\nasync function* at(p) {\n  const t = p.getReader(), e = new TextDecoder();\n  let o = \"\";\n  for (; ; ) {\n    let { done: _, value: s } = await t.read();\n    if (_) break;\n    let r = e.decode(s, { stream: !0 });\n    if (!r) continue;\n    const u = r.split(`\n`);\n    let n = [];\n    for (let i of u)\n      i.startsWith(\"event: \") || (i.startsWith(\"data: \") && (i = i.slice(6)), i.length !== 0 && n.push(i));\n    o = n.join(`\n`), n = [];\n    const c = o.split(`\n`);\n    for (const i of c)\n      try {\n        const l = JSON.parse(i);\n        if (yield l, l.type === \"message_stop\" || l.type === \"response.completed\" || l.done) {\n          _ = !0;\n          break;\n        }\n      } catch {\n        n.push(i);\n      }\n    o = n.join(`\n`);\n  }\n  if (o.length > 0)\n    try {\n      yield JSON.parse(o);\n    } catch {\n      it.error(\"Error parsing JSON LINE:\", o);\n    }\n}\nfunction ct(p, t) {\n  return p.filter((e) => e.role === t);\n}\nfunction lt(p, t) {\n  return p.filter((e) => e.role !== t);\n}\nfunction mt() {\n  return crypto.randomUUID();\n}\nfunction V(p) {\n  if (!p.name) throw new Error(\"Tool name is required\");\n  if (!p.description) throw new Error(\"Tool description is required\");\n  if (!p.input_schema) throw new Error(\"Tool input schema is required\");\n  return {\n    type: \"function\",\n    function: { name: p.name, description: p.description, parameters: p.input_schema }\n  };\n}\nfunction P(p) {\n  if (!p.function) throw new Error(\"Tool call function is required\");\n  if (p.function.id || (p.function.id = crypto.randomUUID()), !p.function.name) throw new Error(\"Tool call function name is required\");\n  if (!p.function.arguments) throw new Error(\"Tool call function arguments is required\");\n  let t = p.function.arguments;\n  return typeof t == \"string\" && (t = JSON.parse(t)), { id: p.function.id, name: p.function.name, input: t };\n}\nfunction D(p, t) {\n  for (const e of t)\n    if (p.includes(`${e}-`) || p.includes(`-${e}`)) return !1;\n  return !0;\n}\nfunction O() {\n  return typeof window < \"u\" && !G();\n}\nfunction G() {\n  return typeof process < \"u\" && !O();\n}\nO() || process.env;\nfunction m(...p) {\n  if (p.length === 0) return \".\";\n  const t = p[0];\n  if (t.startsWith(\"http://\") || t.startsWith(\"https://\")) {\n    const [s, ...r] = t.split(\"://\"), u = p.slice(1), c = [r.join(\"://\"), ...u].join(\"/\").replace(/\\/+/g, \"/\");\n    return `${s}://${c}`;\n  }\n  let o = [];\n  for (let s = 0, r = p.length; s < r; s++)\n    o = o.concat(p[s].split(\"/\"));\n  const _ = [];\n  for (let s = 0, r = o.length; s < r; s++) {\n    const u = o[s];\n    !u || u === \".\" || (u === \"..\" ? _.pop() : _.push(u));\n  }\n  return o[0] === \"\" && _.unshift(\"\"), _.join(\"/\") || (_.length ? \"/\" : \".\");\n}\nconst N = j(\"llm.js:index\"), w = class w {\n  constructor(t, e = {}) {\n    this.abortController = null, this.cache = {};\n    const o = this.constructor;\n    this.service = e.service ?? this.constructor.service, this.messages = [], t && typeof t == \"string\" ? this.user(t) : t && Array.isArray(t) && (this.messages = t), this.options = e, this.model = e.model ?? o.DEFAULT_MODEL, this.baseUrl = e.baseUrl ?? o.DEFAULT_BASE_URL, this.modelUsage = new B(this.service), this.stream = e.stream ?? !1, this.max_tokens = e.max_tokens ?? Y.max_tokens, this.extended = e.extended ?? !1, this.think = e.think ?? !1, this.qualityFilter = e.qualityFilter ?? {}, typeof e.temperature == \"number\" && (this.temperature = e.temperature), typeof e.max_thinking_tokens == \"number\" && (this.max_thinking_tokens = e.max_thinking_tokens), typeof e.parser == \"string\" && (this.parser = this.parsers[e.parser]), typeof e.json == \"boolean\" && (this.json = e.json), this.json && !this.parser && (this.parser = W), Array.isArray(e.tools) && (this.tools = e.tools), this.think && (this.extended = !0), this.tools && this.tools.length > 0 && (this.extended = !0), N.debug(`LLM ${this.service} constructor`);\n  }\n  get isLocal() {\n    return this.constructor.isLocal;\n  }\n  get apiKey() {\n    var t;\n    if (this.options.apiKey) return this.options.apiKey;\n    if (O()) {\n      if (localStorage.getItem(`${this.service.toUpperCase()}_API_KEY`)) return localStorage.getItem(`${this.service.toUpperCase()}_API_KEY`);\n    } else if (G() && typeof process < \"u\" && (t = process.env) != null && t[`${this.service.toUpperCase()}_API_KEY`])\n      return process.env[`${this.service.toUpperCase()}_API_KEY`];\n  }\n  get llmOptions() {\n    const t = {\n      model: this.model,\n      messages: this.parseMessages(this.messages),\n      stream: this.stream,\n      max_tokens: this.max_tokens,\n      think: this.think\n    };\n    return typeof this.max_thinking_tokens == \"number\" && (t.max_thinking_tokens = this.max_thinking_tokens), typeof this.temperature == \"number\" && (t.temperature = this.temperature), this.tools && (t.tools = this.tools), t;\n  }\n  get llmHeaders() {\n    const t = {\n      \"Content-Type\": \"application/json\"\n    };\n    return this.constructor.isBearerAuth ? t.Authorization = `Bearer ${this.apiKey}` : this.apiKey && (t[\"x-api-key\"] = this.apiKey), t;\n  }\n  get chatUrl() {\n    return m(this.baseUrl, \"api/chat\");\n  }\n  get modelsUrl() {\n    return m(this.baseUrl, \"api/tags\");\n  }\n  getChatUrl(t) {\n    return this.chatUrl;\n  }\n  getModelsUrl() {\n    return this.modelsUrl;\n  }\n  get parsers() {\n    return {\n      thinking: this.parseThinkingChunk.bind(this),\n      content: this.parseContentChunk.bind(this),\n      usage: this.parseTokenUsage.bind(this),\n      tool_calls: this.parseToolsChunk.bind(this)\n    };\n  }\n  addMessage(t, e) {\n    this.messages.push({ role: t, content: e });\n  }\n  user(t) {\n    this.addMessage(\"user\", t);\n  }\n  assistant(t) {\n    this.addMessage(\"assistant\", t);\n  }\n  system(t) {\n    this.addMessage(\"system\", t);\n  }\n  thinking(t) {\n    this.addMessage(\"thinking\", t);\n  }\n  toolCall(t) {\n    this.addMessage(\"tool_call\", t);\n  }\n  async chat(t, e) {\n    return this.user(t), await this.send(e);\n  }\n  abort() {\n    this.abortController && this.abortController.abort();\n  }\n  async send(t) {\n    const e = { ...this.llmOptions, ...t || {} }, o = this.parseOptions(JSON.parse(JSON.stringify(e)));\n    this.resetCache(), o.tools && o.tools.length > 0 && (this.extended = !0), N.debug(`LLM ${this.service} send`), this.abortController = new AbortController();\n    const _ = await fetch(this.getChatUrl(o), {\n      method: \"POST\",\n      body: JSON.stringify(o),\n      headers: this.llmHeaders,\n      signal: this.abortController.signal,\n      mode: \"cors\",\n      credentials: \"omit\"\n    });\n    if (await J(_, \"Failed to send request\"), this.stream) {\n      const s = _.body;\n      if (!s) throw new Error(\"No body found\");\n      return this.extended ? this.extendedStreamResponse(s, e) : this.streamResponse(s);\n    }\n    try {\n      const s = await _.json();\n      return this.extended ? this.extendedResponse(s, e) : this.response(s);\n    } finally {\n      this.abortController = null;\n    }\n  }\n  response(t) {\n    let e = this.parseContent(t);\n    return this.parser && (e = this.parser(e)), e && this.assistant(e), e;\n  }\n  extendedResponse(t, e) {\n    const o = {\n      service: this.service,\n      options: e\n    }, _ = this.parseTokenUsage(t);\n    if (_ && (o.usage = this.parseUsage(_)), e.think) {\n      const r = this.parseThinking(t);\n      r && (o.thinking = r, this.thinking(r));\n    }\n    let s = this.parseContent(t);\n    if (this.parser && (s = this.parser(s)), s && this.assistant(s), this.tools && this.tools.length > 0) {\n      o.tool_calls = this.parseTools(t);\n      for (const r of o.tool_calls)\n        r && Object.keys(r).length > 0 && this.toolCall(r);\n    }\n    return o.content = s, o.messages = JSON.parse(JSON.stringify(this.messages)), o;\n  }\n  async *streamResponse(t) {\n    const e = this.streamResponses(t, { content: this.parseContentChunk.bind(this) });\n    for await (const o of e)\n      o.type === \"content\" && (yield o.content);\n    this.abortController = null;\n  }\n  async *streamResponses(t, e) {\n    const o = await at(t);\n    let _ = { type: \"buffers\" };\n    for await (const s of o)\n      for (const [r, u] of Object.entries(e)) {\n        const n = u(s);\n        if (n)\n          if (r === \"usage\")\n            _[r] = n, yield { type: r, content: n };\n          else if (r === \"tool_calls\") {\n            if (!Array.isArray(n) || n.length === 0) continue;\n            _[r] || (_[r] = []), _[r].push(...n), yield { type: r, content: n };\n          } else\n            _[r] || (_[r] = \"\"), _[r] += n, yield { type: r, content: n };\n      }\n    return this.saveBuffers(_), _;\n  }\n  saveBuffers(t) {\n    for (let [e, o] of Object.entries(t))\n      if (e === \"thinking\")\n        this.thinking(o);\n      else if (e === \"tool_calls\")\n        for (const _ of o)\n          _ && Object.keys(_).length > 0 && this.toolCall(_);\n      else e === \"content\" && (this.parser && (o = this.parser(o), t[e] = o), o && this.assistant(o));\n  }\n  async *restream(t, e) {\n    for (; ; ) {\n      const { value: o, done: _ } = await t.next();\n      if (e && o && e(o), _) break;\n      yield o;\n    }\n  }\n  extendedStreamResponse(t, e) {\n    let o, _ = \"\", s = \"\", r = [];\n    const u = async () => {\n      const i = JSON.parse(JSON.stringify(this.messages)), l = { service: this.service, options: e, usage: o, messages: i, content: s };\n      return _ && (l.thinking = _), r.length > 0 && (l.tool_calls = r), this.abortController = null, l;\n    }, n = this.streamResponses(t, this.parsers), c = this.restream(n, (i) => {\n      if (i.type === \"usage\" && i.content && typeof i.content == \"object\") {\n        const l = i.content;\n        o = this.parseUsage(l);\n      }\n      i.type === \"tool_calls\" && i.content && Array.isArray(i.content) && r.push(...i.content), i.type === \"buffers\" && (i.thinking && (_ = i.thinking), i.content && (s = i.content));\n    });\n    return { service: this.service, options: e, stream: c, complete: u, think: this.think ?? !1 };\n  }\n  async fetchModels() {\n    const t = { headers: this.llmHeaders };\n    N.debug(`LLM ${this.service} fetchModels`);\n    const e = await fetch(this.getModelsUrl(), t);\n    await J(e, \"Failed to fetch models\");\n    const o = await e.json();\n    let _ = [];\n    if (Array.isArray(o) ? _ = o : Array.isArray(o.models) ? _ = o.models : Array.isArray(o.data) && (_ = o.data), !_) throw new Error(\"No models found\");\n    return _.map(this.parseModel);\n  }\n  async verifyConnection() {\n    return (await this.fetchModels()).length > 0;\n  }\n  async getModels(t = {}) {\n    return (await this.fetchModels()).map((o) => {\n      let _ = B.get(this.service, o.model, t);\n      if (!_)\n        if (t.allowUnknown)\n          _ = { input_cost_per_token: 0, output_cost_per_token: 0, output_cost_per_reasoning_token: 0 };\n        else\n          throw new Error(`model info not found for ${o.model}`);\n      return this.isLocal && (_.input_cost_per_token = 0, _.output_cost_per_token = 0, _.output_cost_per_reasoning_token = 0), { ..._, name: o.name, model: o.model, created: o.created, service: this.service, raw: o };\n    }).filter(this.filterQualityModel);\n  }\n  filterQualityModel(t) {\n    return !0;\n  }\n  async getQualityModels() {\n    return this.getModels({ allowUnknown: !0, allowSimilar: !0, topModels: !0 });\n  }\n  async refreshModelUsage() {\n    await this.modelUsage.refresh();\n  }\n  parseContent(t) {\n    throw new Error(\"parseContent not implemented\");\n  }\n  parseTools(t) {\n    return [];\n  }\n  parseToolsChunk(t) {\n    return this.parseTools(t);\n  }\n  parseContentChunk(t) {\n    return this.parseContent(t);\n  }\n  parseThinking(t) {\n    return \"\";\n  }\n  parseThinkingChunk(t) {\n    return this.parseThinking(t);\n  }\n  parseModel(t) {\n    throw new Error(\"parseModel not implemented\");\n  }\n  parseMessages(t) {\n    return t.map((e) => ((e.role === \"thinking\" || e.role === \"tool_call\") && (e.role = \"assistant\"), e));\n  }\n  parseOptions(t) {\n    return t || {};\n  }\n  parseTokenUsage(t) {\n    return t;\n  }\n  parseUsage(t) {\n    const e = this.modelUsage.getModel(this.model, this.qualityFilter);\n    let o = (e == null ? void 0 : e.input_cost_per_token) || 0, _ = (e == null ? void 0 : e.output_cost_per_token) || 0;\n    this.isLocal && (o = 0, _ = 0);\n    const s = t.input_tokens * o, r = t.output_tokens * _, u = s + r;\n    return {\n      ...t,\n      local: this.isLocal,\n      total_tokens: t.input_tokens + t.output_tokens,\n      input_cost: s,\n      output_cost: r,\n      total_cost: u\n    };\n  }\n  resetCache() {\n    this.cache = {};\n  }\n};\nw.parsers = H, w.isLocal = !1, w.isBearerAuth = !1;\nlet d = w;\nconst k = class k extends d {\n  get chatUrl() {\n    return m(this.baseUrl, \"messages\");\n  }\n  get modelsUrl() {\n    return m(this.baseUrl, \"models\");\n  }\n  get llmHeaders() {\n    const t = Object.assign({\n      \"anthropic-version\": k.API_VERSION\n    }, super.llmHeaders);\n    return O() && (t[\"anthropic-dangerous-direct-browser-access\"] = \"true\"), t;\n  }\n  parseOptions(t) {\n    if (t.think) {\n      const e = Math.floor((t.max_tokens || 0) / 2);\n      t.thinking = { type: \"enabled\", budget_tokens: e };\n    }\n    return typeof t.max_thinking_tokens == \"number\" && (t.thinking.budget_tokens = t.max_thinking_tokens, delete t.max_thinking_tokens), delete t.think, t;\n  }\n  parseThinking(t) {\n    const e = t.content ?? [];\n    for (const o of e)\n      if (o.type === \"thinking\" && o.thinking)\n        return o.thinking;\n    return \"\";\n  }\n  parseThinkingChunk(t) {\n    if (!t || t.type !== \"content_block_delta\" || !t.delta) return \"\";\n    const e = t.delta;\n    return e.type !== \"thinking_delta\" || !e.thinking ? \"\" : e.thinking;\n  }\n  parseTokenUsage(t) {\n    var _, s, r, u, n, c;\n    if (!t) return null;\n    const e = ((s = (_ = t.message) == null ? void 0 : _.usage) == null ? void 0 : s.input_tokens) || ((r = t.usage) == null ? void 0 : r.input_tokens), o = ((n = (u = t.message) == null ? void 0 : u.usage) == null ? void 0 : n.output_tokens) || ((c = t.usage) == null ? void 0 : c.output_tokens);\n    return typeof e != \"number\" || typeof o != \"number\" ? null : { input_tokens: e, output_tokens: o };\n  }\n  parseContent(t) {\n    const e = t.content ?? [];\n    for (const o of e)\n      if (!(o.type !== \"text\" || !o.text))\n        return o.text;\n    return \"\";\n  }\n  parseContentChunk(t) {\n    return t.type !== \"content_block_delta\" || !t.delta || t.delta.type !== \"text_delta\" || !t.delta.text ? \"\" : t.delta.text;\n  }\n  parseToolsChunk(t) {\n    if (t.type === \"content_block_start\" && t.content_block && t.content_block.type === \"tool_use\" && (this.cache.tool_call = t.content_block), this.cache.tool_call && t.type === \"content_block_delta\" && t.delta && t.delta.type === \"input_json_delta\" && (this.cache.tool_call_input || (this.cache.tool_call_input = \"\"), this.cache.tool_call_input += t.delta.partial_json), !this.cache.tool_call) return [];\n    if (!this.cache.tool_call_input) return [];\n    try {\n      const e = JSON.parse(this.cache.tool_call_input), o = { id: this.cache.tool_call.id, name: this.cache.tool_call.name, input: e };\n      return delete this.cache.tool_call, delete this.cache.tool_call_input, [o];\n    } catch {\n      return [];\n    }\n  }\n  parseTools(t) {\n    if (!t || !t.content || !Array.isArray(t.content)) return [];\n    const e = [];\n    for (const o of t.content)\n      o.type !== \"tool_use\" || !o.id || !o.name || !o.input || e.push({ id: o.id, name: o.name, input: o.input });\n    return e;\n  }\n  parseModel(t) {\n    return { name: t.display_name, model: t.id, created: new Date(t.created_at) };\n  }\n  filterQualityModel(t) {\n    return !(t.mode !== \"chat\" || t.model.startsWith(\"claude-2\"));\n  }\n};\nk.service = \"anthropic\", k.DEFAULT_BASE_URL = \"https://api.anthropic.com/v1\", k.DEFAULT_MODEL = \"claude-opus-4-20250514\", k.API_VERSION = \"2023-06-01\";\nlet C = k;\nconst f = class f extends d {\n  get chatUrl() {\n    return m(this.baseUrl, \"api/chat\");\n  }\n  get modelsUrl() {\n    return m(this.baseUrl, \"api/tags\");\n  }\n  get llmHeaders() {\n    const t = super.llmHeaders;\n    return delete t[\"x-api-key\"], t;\n  }\n  parseOptions(t) {\n    if (t.max_tokens) {\n      const e = t.max_tokens;\n      delete t.max_tokens, t.options || (t.options = {}), t.options.num_predict = e;\n    }\n    if (t.tools) {\n      const e = t.tools.map((o) => V(o));\n      t.tools = e;\n    }\n    return delete t.apiKey, t;\n  }\n  parseThinking(t) {\n    return !t || !t.message || !t.message.thinking ? \"\" : t.message.thinking;\n  }\n  parseTokenUsage(t) {\n    return !t || typeof t.prompt_eval_count != \"number\" || typeof t.eval_count != \"number\" ? null : { input_tokens: t.prompt_eval_count, output_tokens: t.eval_count };\n  }\n  parseContent(t) {\n    return !t || !t.message || !t.message.content ? \"\" : t.message.content;\n  }\n  parseContentChunk(t) {\n    return !t || !t.message || !t.message.content || t.message.role !== \"assistant\" ? \"\" : t.message.content;\n  }\n  parseTools(t) {\n    return !t || !t.message || !t.message.tool_calls ? [] : t.message.tool_calls.map((e) => P(e));\n  }\n  parseModel(t) {\n    return { name: t.model, model: t.model, created: new Date(t.modified_at) };\n  }\n  async verifyConnection() {\n    return await (await fetch(`${this.baseUrl}`)).text() === \"Ollama is running\";\n  }\n};\nf.service = \"ollama\", f.DEFAULT_BASE_URL = \"http://localhost:11434\", f.DEFAULT_MODEL = \"gemma3:4b\", f.isLocal = !0;\nlet A = f;\nconst b = class b extends d {\n  get chatUrl() {\n    return m(this.baseUrl, \"responses\");\n  }\n  get modelsUrl() {\n    return m(this.baseUrl, \"models\");\n  }\n  parseOptions(t) {\n    if (t.input = t.messages, delete t.messages, t.max_tokens) {\n      const e = t.max_tokens;\n      delete t.max_tokens, t.max_output_tokens = e;\n    }\n    if (t.tools) {\n      const e = t.tools.map((o) => dt(o));\n      t.tools = e;\n    }\n    return t.think && !t.reasoning && (t.reasoning = { effort: \"medium\", summary: \"detailed\" }), delete t.think, t;\n  }\n  parseContent(t) {\n    if (!t || !t.output || !Array.isArray(t.output) || t.object !== \"response\" || t.status !== \"completed\") return \"\";\n    for (const e of t.output)\n      if (!(e.type !== \"message\" || e.role !== \"assistant\" || e.status !== \"completed\" || !e.content || !Array.isArray(e.content))) {\n        for (const o of e.content)\n          if (!(o.type !== \"output_text\" || !o.text))\n            return o.text;\n      }\n    return \"\";\n  }\n  parseTokenUsage(t) {\n    return t.response && t.type === \"response.completed\" && (t = t.response), !t || !t.usage || !t.usage.input_tokens || !t.usage.output_tokens ? null : {\n      input_tokens: t.usage.input_tokens,\n      output_tokens: t.usage.output_tokens\n    };\n  }\n  parseTools(t) {\n    if (!t || !t.output || !Array.isArray(t.output)) return [];\n    if (t.object !== \"response\" || t.status !== \"completed\") return [];\n    const e = [];\n    for (const o of t.output)\n      o.type !== \"function_call\" || o.status !== \"completed\" || !o.call_id || !o.name || !o.arguments || e.push({\n        id: o.call_id,\n        name: o.name,\n        input: JSON.parse(o.arguments)\n      });\n    return e;\n  }\n  parseToolsChunk(t) {\n    if (t.type === \"response.output_item.added\" && t.item && t.item.type === \"function_call\" && (this.cache.tool_call = t.item), this.cache.tool_call && t.type === \"response.function_call_arguments.done\" && (this.cache.tool_call_input = t.arguments), !this.cache.tool_call) return [];\n    if (!this.cache.tool_call_input) return [];\n    try {\n      const e = JSON.parse(this.cache.tool_call_input), o = { id: this.cache.tool_call.id, name: this.cache.tool_call.name, input: e };\n      return delete this.cache.tool_call, delete this.cache.tool_call_input, [o];\n    } catch {\n      return [];\n    }\n  }\n  parseThinking(t) {\n    if (!t || !t.output || !Array.isArray(t.output) || t.object !== \"response\" || t.status !== \"completed\") return \"\";\n    for (const e of t.output)\n      if (!(e.type !== \"reasoning\" || !e.summary || !Array.isArray(e.summary))) {\n        for (const o of e.summary)\n          if (!(o.type !== \"summary_text\" || !o.text))\n            return o.text;\n      }\n    return \"\";\n  }\n  parseThinkingChunk(t) {\n    return !t || t.type !== \"response.reasoning_summary_text.delta\" || !t.delta ? \"\" : t.delta;\n  }\n  parseContentChunk(t) {\n    return !t || !t.delta || t.type !== \"response.output_text.delta\" ? \"\" : t.delta;\n  }\n  parseModel(t) {\n    return {\n      name: t.model,\n      model: t.id,\n      created: new Date(t.created * 1e3)\n    };\n  }\n  filterQualityModel(t) {\n    const e = [\n      \"audio\",\n      \"image\",\n      \"davinci\",\n      \"babbage\",\n      \"dall-e\",\n      \"tts\",\n      \"whisper\",\n      \"embedding\",\n      \"vision\",\n      \"moderation\",\n      \"realtime\",\n      \"computer-use\",\n      \"transcribe\",\n      \"instruct\",\n      \"codex\"\n    ];\n    return D(t.model, e);\n  }\n};\nb.service = \"openai\", b.DEFAULT_BASE_URL = \"https://api.openai.com/v1\", b.DEFAULT_MODEL = \"gpt-4o-mini\", b.isBearerAuth = !0;\nlet T = b;\nfunction dt(p) {\n  return {\n    name: p.name,\n    parameters: Object.assign({}, p.input_schema, { additionalProperties: !1 }),\n    strict: !0,\n    type: \"function\",\n    description: p.description\n  };\n}\nconst z = class z extends d {\n  get chatUrl() {\n    return m(this.baseUrl, \"chat/completions\");\n  }\n  get modelsUrl() {\n    return m(this.baseUrl, \"models\");\n  }\n  getChatUrl(t) {\n    return m(this.baseUrl, \"models\", `${t.model}:generateContent?key=${this.apiKey}`);\n  }\n  getModelsUrl() {\n    return `${this.modelsUrl}?key=${this.apiKey}`;\n  }\n  parseOptions(t) {\n    const e = JSON.parse(JSON.stringify(t.messages || [])).map((s) => (s.role === \"assistant\" && (s.role = \"model\"), s)), o = ct(e, \"system\"), _ = lt(e, \"system\");\n    return delete t.messages, o.length > 0 && (t.system_instruction = { parts: o.map((s) => ({ text: s.content })) }), _.length > 0 && (t.contents = _.map((s) => ({ role: s.role, parts: [{ text: s.content }] }))), t.generationConfig || (t.generationConfig = {}), typeof t.temperature == \"number\" && (t.generationConfig.temperature = t.temperature), typeof t.max_tokens == \"number\" && (t.generationConfig.maxOutputTokens = t.max_tokens), t.generationConfig.maxOutputTokens || (t.generationConfig.maxOutputTokens = this.max_tokens), t.tools && (t.tools = [{ functionDeclarations: t.tools.map((s) => ({\n      name: s.name,\n      description: s.description,\n      parameters: s.input_schema\n    })) }]), t.think && (t.generationConfig || (t.generationConfig = {}), t.generationConfig.thinkingConfig = { includeThoughts: !0 }, delete t.think), delete t.think, delete t.max_tokens, delete t.temperature, delete t.stream, t;\n  }\n  get llmHeaders() {\n    const t = super.llmHeaders;\n    return delete t[\"x-api-key\"], t;\n  }\n  parseContent(t) {\n    var o, _, s;\n    if (!((s = (_ = (o = t == null ? void 0 : t.candidates) == null ? void 0 : o[0]) == null ? void 0 : _.content) != null && s.parts)) return \"\";\n    const e = t.candidates[0].content.parts;\n    for (const r of e)\n      if (!r.thought)\n        return r.text;\n    return \"\";\n  }\n  parseTokenUsage(t) {\n    var o, _;\n    if (!((o = t == null ? void 0 : t.usageMetadata) != null && o.promptTokenCount) || !((_ = t == null ? void 0 : t.usageMetadata) != null && _.candidatesTokenCount)) return null;\n    const e = t.usageMetadata;\n    return { input_tokens: e.promptTokenCount, output_tokens: e.candidatesTokenCount };\n  }\n  parseModel(t) {\n    return {\n      name: t.displayName,\n      model: t.name.replace(/^models\\//, \"\"),\n      created: /* @__PURE__ */ new Date()\n      // :(\n    };\n  }\n  parseTools(t) {\n    var o, _, s, r, u;\n    if (!((u = (r = (s = (_ = (o = t == null ? void 0 : t.candidates) == null ? void 0 : o[0]) == null ? void 0 : _.content) == null ? void 0 : s.parts) == null ? void 0 : r[0]) != null && u.functionCall)) return [];\n    const e = t.candidates[0].content.parts[0].functionCall;\n    return [{ id: mt(), name: e.name, input: e.args }];\n  }\n  parseThinking(t) {\n    var o, _, s;\n    if (!((s = (_ = (o = t == null ? void 0 : t.candidates) == null ? void 0 : o[0]) == null ? void 0 : _.content) != null && s.parts)) return \"\";\n    const e = t.candidates[0].content.parts;\n    for (const r of e)\n      if (r.thought === !0)\n        return r.text;\n    return \"\";\n  }\n  filterQualityModel(t) {\n    const e = [\"embedding\", \"vision\", \"learnlm\", \"image-generation\", \"gemma-3\", \"gemma-3n\", \"gemini-1.5\", \"embedding\"];\n    return D(t.model, e);\n  }\n};\nz.service = \"google\", z.DEFAULT_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/\", z.DEFAULT_MODEL = \"gemini-2.5-flash-preview-05-20\";\nlet U = z;\nconst h = class h extends d {\n  get chatUrl() {\n    return m(this.baseUrl, \"chat/completions\");\n  }\n  get modelsUrl() {\n    return m(this.baseUrl, \"models\");\n  }\n  parseOptions(t) {\n    if (t.think && !t.reasoning_effort && (t.reasoning_effort = \"high\"), delete t.think, t.tools) {\n      const e = t.tools.map((o) => V(o));\n      t.tools = e;\n    }\n    return t.stream && (t.stream_options = { include_usage: !0 }), t;\n  }\n  parseContent(t) {\n    return !t || !t.choices || !t.choices[0] || !t.choices[0].message ? \"\" : t.choices[0].message.content;\n  }\n  parseContentChunk(t) {\n    return !t || !t.choices || !t.choices[0] || !t.choices[0].delta || !t.choices[0].delta.content ? \"\" : t.choices[0].delta.content;\n  }\n  parseThinking(t) {\n    const e = this.constructor.KEY_REASONING_CONTENT;\n    return !t || !t.choices || !t.choices[0] || !t.choices[0].message || !t.choices[0].message[e] ? \"\" : t.choices[0].message[e];\n  }\n  parseThinkingChunk(t) {\n    const e = this.constructor.KEY_REASONING_CONTENT;\n    return !t || !t.choices || !t.choices[0] || !t.choices[0].delta || !t.choices[0].delta[e] ? \"\" : t.choices[0].delta[e];\n  }\n  parseTokenUsage(t) {\n    return !t || !t.usage || !t.usage.prompt_tokens || !t.usage.completion_tokens ? null : {\n      input_tokens: t.usage.prompt_tokens,\n      output_tokens: t.usage.completion_tokens\n    };\n  }\n  parseModel(t) {\n    let e = t.created ? new Date(t.created * 1e3) : /* @__PURE__ */ new Date();\n    return { name: t.model, model: t.id, created: e };\n  }\n  parseTools(t) {\n    return !t || !t.choices || !t.choices[0] || !t.choices[0].message || !t.choices[0].message.tool_calls ? [] : t.choices[0].message.tool_calls.map((e) => P(e));\n  }\n  parseToolsChunk(t) {\n    return !t || !t.choices || !t.choices[0] || !t.choices[0].delta || !t.choices[0].delta.tool_calls ? [] : t.choices[0].delta.tool_calls.map((e) => P(e));\n  }\n  filterQualityModel(t) {\n    const e = [\"audio\", \"vision\", \"image\"];\n    return D(t.model, e);\n  }\n};\nh.service = \"openai\", h.DEFAULT_BASE_URL = \"\", h.DEFAULT_MODEL = \"\", h.isBearerAuth = !0, h.KEY_REASONING_CONTENT = \"reasoning_content\";\nlet x = h;\nconst q = class q extends x {\n};\nq.service = \"xai\", q.DEFAULT_BASE_URL = \"https://api.x.ai/v1/\", q.DEFAULT_MODEL = \"grok-3\";\nlet E = q;\nconst y = class y extends x {\n  parseOptions(t) {\n    return t = super.parseOptions(t), t.reasoning_effort === \"high\" && (delete t.reasoning_effort, t.reasoning_format || (t.reasoning_format = \"parsed\")), t;\n  }\n  // groq wraps usage in x_groq for streaming\n  parseTokenUsage(t) {\n    return !t || (!t.usage && t.x_groq && t.x_groq.usage && (t = t.x_groq), !t || !t.usage) || !t.usage.prompt_tokens || !t.usage.completion_tokens ? null : {\n      input_tokens: t.usage.prompt_tokens,\n      output_tokens: t.usage.completion_tokens\n    };\n  }\n  filterQualityModel(t) {\n    return D(t.model, [\"whisper\", \"tts\"]);\n  }\n};\ny.service = \"groq\", y.DEFAULT_BASE_URL = \"https://api.groq.com/openai/v1/\", y.DEFAULT_MODEL = \"deepseek-r1-distill-llama-70b\", y.KEY_REASONING_CONTENT = \"reasoning\";\nlet I = y;\nconst $ = class $ extends x {\n};\n$.service = \"deepseek\", $.DEFAULT_BASE_URL = \"https://api.deepseek.com/v1/\", $.DEFAULT_MODEL = \"deepseek-chat\";\nlet S = $, L = [C, A, T, U, E, I, S];\nfunction kt(p, t) {\n  let e, o;\n  typeof p == \"string\" || Array.isArray(p) ? (e = p, o = t || {}) : typeof p == \"object\" && p !== null ? (e = void 0, o = p) : (e = void 0, o = {});\n  let _;\n  const s = (o == null ? void 0 : o.service) ?? Y.service;\n  let r = L.find((n) => n.service === s);\n  return r || (r = x), _ = new r(e, o), new.target ? _ : _.send();\n}\nconst a = kt;\na.parsers = H;\na.services = L;\na.ModelUsage = B;\na.Anthropic = C;\na.Ollama = A;\na.OpenAI = T;\na.Google = U;\na.xAI = E;\na.Groq = I;\na.DeepSeek = S;\na.APIv1 = x;\na.LLM = d;\na.register = (p) => {\n  L.push(p);\n};\na.unregister = (p) => {\n  L = L.filter((t) => t !== p);\n};\nexport {\n  a as default\n};\n//# sourceMappingURL=index.mjs.map\n","import LLM from '@themaximalist/llm.js'\n\nclass AskJenna {\n    constructor(options, prompts) {\n        this.options = options;\n        this.prompts = prompts;\n    }\n\n    fill_input(el) {\n        if (!this.prompts[el.name]) {\n            return;\n        }\n        const status = el.disabled;\n        const previousValue = el.value;\n        el.value = '';  // Clear the input field\n        el.disabled = true;  // Disable the input field to prevent changes while processing\n        console.log(\"Field\", el.value);\n        this.extendedLLM(el.name).then((result) => {\n            console.log(result);\n            el.value = this.deconstructJson(result);\n            el.disabled = status;\n        }).catch(err => {\n            el.value = previousValue;  // Restore previous value on error\n            el.disabled = status;  // Restore previous disabled state\n            console.error(err);\n        });\n    }\n\n    deconstructJson(json) {\n        if (typeof json == 'string') {\n            return json;\n        }\n        if (typeof json == 'object' && Object.keys(json).length === 1) {\n            const key = Object.keys(json)[0];\n            return this.deconstructJson(json[key]);\n        }\n        if (Array.isArray(json) && json.length === 1) {\n            return this.deconstructJson(json[0]);\n        }\n        return json;\n    }\n\n    async extendedLLM(name) {\n        if (this.prompts[name]?.dynamic_content) {\n            const response = await fetch(this.prompts[name].dynamic_content);\n            const div = document.createElement('div');\n            div.innerHTML = await response.text();\n            const nodeToRemove = div.querySelector('div#cms-top');\n            if (nodeToRemove) {\n                nodeToRemove.remove();\n            }\n            div.querySelectorAll('meta, style, script, template, nav').forEach(node => node.remove());\n            const content = this.htmlToMDContent(div);\n            return LLM(`Here is HTML content: ${content}\\n\\n${this.prompts[name].prompt}`, this.options);\n        }\n        return LLM(this.prompts[name].prompt, this.options);\n    }\n\n    htmlToMDContent (element) {\n        function traverse(node) {\n            if (node.nodeType === Node.TEXT_NODE) {\n            return node.textContent;\n            }\n            if (node.nodeType !== Node.ELEMENT_NODE) {\n            return '';\n            }\n            let md = '';\n            switch (node.tagName.toLowerCase()) {\n            case 'h1':\n                md += '# ' + Array.from(node.childNodes).map(traverse).join('').trim() + '\\n\\n';\n                break;\n            case 'h2':\n                md += '## ' + Array.from(node.childNodes).map(traverse).join('').trim() + '\\n\\n';\n                break;\n            case 'h3':\n                md += '### ' + Array.from(node.childNodes).map(traverse).join('').trim() + '\\n\\n';\n                break;\n            case 'h4':\n                md += '#### ' + Array.from(node.childNodes).map(traverse).join('').trim() + '\\n\\n';\n                break;\n            case 'h5':\n                md += '##### ' + Array.from(node.childNodes).map(traverse).join('').trim() + '\\n\\n';\n                break;\n            case 'h6':\n                md += '###### ' + Array.from(node.childNodes).map(traverse).join('').trim() + '\\n\\n';\n                break;\n            case 'strong':\n            case 'b':\n                md += '**' + Array.from(node.childNodes).map(traverse).join('') + '**';\n                break;\n            case 'em':\n            case 'i':\n                md += '*' + Array.from(node.childNodes).map(traverse).join('') + '*';\n                break;\n            case 'code':\n                md += '`' + Array.from(node.childNodes).map(traverse).join('') + '`';\n                break;\n            case 'pre':\n                md += '```\\n' + Array.from(node.childNodes).map(traverse).join('') + '\\n```\\n\\n';\n                break;\n            case 'ul':\n                md += Array.from(node.children).map(li => '- ' + traverse(li).trim()).join('\\n') + '\\n\\n';\n                break;\n            case 'ol':\n                md += Array.from(node.children).map((li, i) => `${i + 1}. ${traverse(li).trim()}`).join('\\n') + '\\n\\n';\n                break;\n            case 'li':\n                md += Array.from(node.childNodes).map(traverse).join('');\n                break;\n            case 'a':\n                const href = node.getAttribute('href') || '';\n                md += `[${Array.from(node.childNodes).map(traverse).join('')}](${href})`;\n                break;\n            case 'img':\n                const alt = node.getAttribute('alt') || '';\n                const src = node.getAttribute('src') || '';\n                md += `![${alt}](${src})`;\n                break;\n            case 'blockquote':\n                md += '> ' + Array.from(node.childNodes).map(traverse).join('').replace(/\\n/g, '\\n> ') + '\\n\\n';\n                break;\n            case 'br':\n                md += '  \\n';\n                break;\n            case 'p':\n                md += Array.from(node.childNodes).map(traverse).join('').trim() + '\\n\\n';\n                break;\n            default:\n                md += Array.from(node.childNodes).map(traverse).join('');\n            }\n            return md;\n        }\n        return traverse(element).replace(/\\n{3,}/g, '\\n\\n').trim();\n    }\n\n    async ask(question) {\n        try {\n            const response = await this.llm.chat({\n                messages: [\n                    { role: \"system\", content: \"You are Jenna, a helpful assistant.\" },\n                    { role: \"user\", content: question }\n                ]\n            });\n            return response.choices[0].message.content;\n        } catch (error) {\n            console.error(\"Error asking Jenna:\", error);\n            throw new Error(\"Failed to get a response from Jenna.\");\n        }\n    }\n}\n\nexport { AskJenna };","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","import { AskJenna } from './ask_jenna';\n\n\ndocument.addEventListener('DOMContentLoaded', () => {\n    const jenna_config = JSON.parse(document.getElementById('ask_jenna_settings').textContent);\n    const jenna_scripts = JSON.parse(document.getElementById('ask_jenna_scripts').textContent);\n\n    const llm = new AskJenna(jenna_config, jenna_scripts);\n    for (let field of Object.keys(jenna_scripts)) {\n        console.log(field);\n        const el = document.querySelector(`input[name=\"${field}\"]:not([disabled]),textarea[name=\"${field}\"]:not([disabled])`);\n        if (el) {\n            console.log(\"adding listener\");\n            el.addEventListener('dblclick', (ev) => {\n                console.log(\"dblClick on \", ev.target.name);\n                llm.fill_input(ev.target, jenna_scripts[ev.target.name]?.prompt);\n            })\n        }\n    }\n    }\n)"],"names":[],"sourceRoot":""}