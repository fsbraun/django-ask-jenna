/******/ (() => { // webpackBootstrap
/******/ 	"use strict";
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/@themaximalist/llm.js/dist/index.mjs":
/*!***********************************************************!*\
  !*** ./node_modules/@themaximalist/llm.js/dist/index.mjs ***!
  \***********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ a)
/* harmony export */ });
class X {
  constructor() {
    this.loggers = /* @__PURE__ */ new Map(), this.patterns = [], this.isNode = typeof process < "u" && process.env, this.colors = [
      "#e6194b",
      "#3cb44b",
      "#ffe119",
      "#4363d8",
      "#f58231",
      "#911eb4",
      "#46f0f0",
      "#f032e6",
      "#bcf60c",
      "#fabebe",
      "#008080",
      "#e6beff",
      "#9a6324",
      "#fffac8",
      "#800000",
      "#aaffc3",
      "#808000",
      "#ffd8b1",
      "#000075",
      "#808080"
    ], this.updatePatterns();
  }
  updatePatterns() {
    let t = "";
    this.isNode ? t = typeof process < "u" && process.env.DEBUG || "" : (typeof localStorage < "u" && (t = localStorage.getItem("DEBUG") || ""), typeof globalThis < "u" && globalThis.DEBUG && (t = globalThis.DEBUG)), this.patterns = t.split(",").map((e) => e.trim()).filter(Boolean);
    for (const [e, o] of this.loggers)
      o.enabled = this.isEnabled(e);
  }
  isEnabled(t) {
    if (this.patterns.length === 0) return !1;
    for (const e of this.patterns)
      if (e.startsWith("-")) {
        const o = e.slice(1);
        if (this.matchPattern(t, o))
          return !1;
      } else if (this.matchPattern(t, e))
        return !0;
    return !1;
  }
  matchPattern(t, e) {
    if (e === "*" || e === t) return !0;
    const o = e.replace(/\*/g, ".*").replace(/\?/g, ".").replace(/\+/g, "\\+").replace(/\[/g, "\\[").replace(/\]/g, "\\]").replace(/\(/g, "\\(").replace(/\)/g, "\\)").replace(/\{/g, "\\{").replace(/\}/g, "\\}").replace(/\^/g, "\\^").replace(/\$/g, "\\$").replace(/\|/g, "\\|");
    return new RegExp(`^${o}$`).test(t);
  }
  getColor(t) {
    let e = 0;
    for (let o = 0; o < t.length; o++) {
      const _ = t.charCodeAt(o);
      e = (e << 5) - e + _, e = e & e;
    }
    return this.colors[Math.abs(e) % this.colors.length];
  }
  formatMessage(t, e, o, _) {
    const s = Date.now(), r = this.loggers.get(t);
    let u = t, n = "";
    r.lastTime && (n = `+${s - r.lastTime}ms`), r.lastTime = s, this.isNode ? (u = `\x1B[${this.getAnsiColor(r.color)}m${t}\x1B[0m`, n && (u += ` \x1B[90m${n}\x1B[0m`)) : n && (u += ` ${n}`);
    const c = e !== "debug" ? `[${e.toUpperCase()}]` : "";
    return `${u}${c ? " " + c : ""} ${o}`;
  }
  getAnsiColor(t) {
    return {
      "#e6194b": "31",
      // red
      "#3cb44b": "32",
      // green  
      "#ffe119": "33",
      // yellow
      "#4363d8": "34",
      // blue
      "#f58231": "35",
      // magenta
      "#911eb4": "36"
      // cyan
    }[t] || "37";
  }
  log(t, e, o, ..._) {
    const s = this.loggers.get(t);
    if (!s || !s.enabled) return;
    (typeof o == "object" || Array.isArray(o)) && (o = JSON.stringify(o));
    for (let u = 0; u < _.length; u++)
      (typeof _[u] == "object" || Array.isArray(_[u])) && (_[u] = JSON.stringify(_[u]));
    const r = this.formatMessage(t, e, o, _);
    if (this.isNode) {
      const u = e === "debug" ? process.stderr : process.stdout;
      u.write(r + " "), _.length > 0 && u.write(_.map(
        (n) => typeof n == "object" ? JSON.stringify(n, null, 2) : String(n)
      ).join(" ")), u.write(`
`);
    } else {
      const u = `color: ${s.color}; font-weight: bold;`;
      e === "warn" ? console.warn(`%c${r}`, u, ..._) : e === "error" ? console.error(`%c${r}`, u, ..._) : console.log(`%c${r}`, u, ..._);
    }
  }
  createLogger(t) {
    this.loggers.has(t) || this.loggers.set(t, {
      enabled: this.isEnabled(t),
      color: this.getColor(t)
    });
    const e = this.loggers.get(t), o = (_, ...s) => {
      this.log(t, "debug", _, ...s);
    };
    return o.debug = (_, ...s) => {
      this.log(t, "debug", _, ...s);
    }, o.warn = (_, ...s) => {
      this.log(t, "warn", _, ...s);
    }, o.error = (_, ...s) => {
      this.log(t, "error", _, ...s);
    }, o.namespace = t, Object.defineProperty(o, "enabled", {
      get: () => e.enabled
    }), o;
  }
  // Update patterns when environment changes
  refresh() {
    this.updatePatterns();
  }
}
const K = new X();
function j(p) {
  return K.createLogger(p);
}
j.refresh = () => K.refresh();
const Z = { max_tokens: "LEGACY parameter. set to max_output_tokens if provider specifies it. IF not set to max_input_tokens, if provider specifies it.", max_input_tokens: "max input tokens, if the provider specifies it. if not default to max_tokens", max_output_tokens: "max output tokens, if the provider specifies it. if not default to max_tokens", input_cost_per_token: 0, output_cost_per_token: 0, output_cost_per_reasoning_token: 0, litellm_provider: "one of https://docs.litellm.ai/docs/providers", mode: "one of: chat, embedding, completion, image_generation, audio_transcription, audio_speech, image_generation, moderation, rerank", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_audio_input: !0, supports_audio_output: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_system_messages: !0, supports_reasoning: !0, supports_web_search: !0, search_context_cost_per_query: { search_context_size_low: 0, search_context_size_medium: 0, search_context_size_high: 0 }, supported_regions: ["global", "us-west-2", "eu-west-1", "ap-southeast-1", "ap-northeast-1"], deprecation_date: "date when the model becomes deprecated in the format YYYY-MM-DD" }, tt = { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, cache_read_input_token_cost: 75e-7, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 }, et = { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, cache_read_input_token_cost: 5e-7, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0, supported_endpoints: ["/v1/responses", "/v1/chat/completions", "/v1/completions", "/v1/batch"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"] }, ot = { max_tokens: 2048, max_input_tokens: 2048, output_vector_size: 768, input_cost_per_character: 2e-7, input_cost_per_image: 1e-4, input_cost_per_video_per_second: 5e-4, input_cost_per_video_per_second_above_8s_interval: 1e-3, input_cost_per_video_per_second_above_15s_interval: 2e-3, input_cost_per_token: 8e-7, output_cost_per_token: 0, litellm_provider: "vertex_ai-embedding-models", mode: "embedding", supported_endpoints: ["/v1/embeddings"], supported_modalities: ["text", "image", "video"], source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models" }, _t = { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 1e-6, output_cost_per_token: 2e-6, litellm_provider: "cohere", mode: "completion" }, st = { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 5e-7, output_cost_per_token: 5e-7, litellm_provider: "nlp_cloud", mode: "completion" }, pt = { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 5e-7, output_cost_per_token: 5e-7, litellm_provider: "nlp_cloud", mode: "chat" }, Q = {
  sample_spec: Z,
  "omni-moderation-latest": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 0, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "openai", mode: "moderation" },
  "omni-moderation-latest-intents": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 0, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "openai", mode: "moderation" },
  "omni-moderation-2024-09-26": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 0, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "openai", mode: "moderation" },
  "gpt-4": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 3e-5, output_cost_per_token: 6e-5, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4.1": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, input_cost_per_token_batches: 1e-6, output_cost_per_token_batches: 4e-6, cache_read_input_token_cost: 5e-7, litellm_provider: "openai", mode: "chat", supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0 },
  "gpt-4.1-2025-04-14": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, input_cost_per_token_batches: 1e-6, output_cost_per_token_batches: 4e-6, cache_read_input_token_cost: 5e-7, litellm_provider: "openai", mode: "chat", supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0 },
  "gpt-4.1-mini": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 4e-7, output_cost_per_token: 16e-7, input_cost_per_token_batches: 2e-7, output_cost_per_token_batches: 8e-7, cache_read_input_token_cost: 1e-7, litellm_provider: "openai", mode: "chat", supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0 },
  "gpt-4.1-mini-2025-04-14": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 4e-7, output_cost_per_token: 16e-7, input_cost_per_token_batches: 2e-7, output_cost_per_token_batches: 8e-7, cache_read_input_token_cost: 1e-7, litellm_provider: "openai", mode: "chat", supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0 },
  "gpt-4.1-nano": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 1e-7, output_cost_per_token: 4e-7, input_cost_per_token_batches: 5e-8, output_cost_per_token_batches: 2e-7, cache_read_input_token_cost: 25e-9, litellm_provider: "openai", mode: "chat", supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0 },
  "gpt-4.1-nano-2025-04-14": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 1e-7, output_cost_per_token: 4e-7, input_cost_per_token_batches: 5e-8, output_cost_per_token_batches: 2e-7, cache_read_input_token_cost: 25e-9, litellm_provider: "openai", mode: "chat", supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0 },
  "gpt-4o": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, input_cost_per_token_batches: 125e-8, output_cost_per_token_batches: 5e-6, cache_read_input_token_cost: 125e-8, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "watsonx/ibm/granite-3-8b-instruct": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 2e-4, output_cost_per_token: 2e-4, litellm_provider: "watsonx", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0, supports_parallel_function_calling: !1, supports_vision: !1, supports_audio_input: !1, supports_audio_output: !1, supports_prompt_caching: !0, supports_response_schema: !0, supports_system_messages: !0 },
  "gpt-4o-search-preview-2025-03-11": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, input_cost_per_token_batches: 125e-8, output_cost_per_token_batches: 5e-6, cache_read_input_token_cost: 125e-8, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4o-search-preview": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, input_cost_per_token_batches: 125e-8, output_cost_per_token_batches: 5e-6, cache_read_input_token_cost: 125e-8, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_web_search: !0, search_context_cost_per_query: { search_context_size_low: 0.03, search_context_size_medium: 0.035, search_context_size_high: 0.05 } },
  "gpt-4.5-preview": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 75e-6, output_cost_per_token: 15e-5, input_cost_per_token_batches: 375e-7, output_cost_per_token_batches: 75e-6, cache_read_input_token_cost: 375e-7, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4.5-preview-2025-02-27": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 75e-6, output_cost_per_token: 15e-5, input_cost_per_token_batches: 375e-7, output_cost_per_token_batches: 75e-6, cache_read_input_token_cost: 375e-7, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, deprecation_date: "2025-07-14" },
  "gpt-4o-audio-preview": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, input_cost_per_audio_token: 1e-4, output_cost_per_token: 1e-5, output_cost_per_audio_token: 2e-4, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4o-audio-preview-2024-12-17": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, input_cost_per_audio_token: 4e-5, output_cost_per_token: 1e-5, output_cost_per_audio_token: 8e-5, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4o-audio-preview-2024-10-01": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, input_cost_per_audio_token: 1e-4, output_cost_per_token: 1e-5, output_cost_per_audio_token: 2e-4, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4o-audio-preview-2025-06-03": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, input_cost_per_audio_token: 4e-5, output_cost_per_token: 1e-5, output_cost_per_audio_token: 8e-5, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4o-mini-audio-preview": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 15e-8, input_cost_per_audio_token: 1e-5, output_cost_per_token: 6e-7, output_cost_per_audio_token: 2e-5, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4o-mini-audio-preview-2024-12-17": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 15e-8, input_cost_per_audio_token: 1e-5, output_cost_per_token: 6e-7, output_cost_per_audio_token: 2e-5, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4o-mini": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, input_cost_per_token_batches: 75e-9, output_cost_per_token_batches: 3e-7, cache_read_input_token_cost: 75e-9, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4o-mini-search-preview-2025-03-11": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, input_cost_per_token_batches: 75e-9, output_cost_per_token_batches: 3e-7, cache_read_input_token_cost: 75e-9, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4o-mini-search-preview": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, input_cost_per_token_batches: 75e-9, output_cost_per_token_batches: 3e-7, cache_read_input_token_cost: 75e-9, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_web_search: !0, search_context_cost_per_query: { search_context_size_low: 0.025, search_context_size_medium: 0.0275, search_context_size_high: 0.03 } },
  "gpt-4o-mini-2024-07-18": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, input_cost_per_token_batches: 75e-9, output_cost_per_token_batches: 3e-7, cache_read_input_token_cost: 75e-9, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, search_context_cost_per_query: { search_context_size_low: 30, search_context_size_medium: 35, search_context_size_high: 50 } },
  "codex-mini-latest": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 15e-7, output_cost_per_token: 6e-6, cache_read_input_token_cost: 375e-9, litellm_provider: "openai", mode: "responses", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supported_endpoints: ["/v1/responses"] },
  "o1-pro": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 15e-5, output_cost_per_token: 6e-4, input_cost_per_token_batches: 75e-6, output_cost_per_token_batches: 3e-4, litellm_provider: "openai", mode: "responses", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_native_streaming: !1, supports_reasoning: !0, supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supported_endpoints: ["/v1/responses", "/v1/batch"] },
  "o1-pro-2025-03-19": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 15e-5, output_cost_per_token: 6e-4, input_cost_per_token_batches: 75e-6, output_cost_per_token_batches: 3e-4, litellm_provider: "openai", mode: "responses", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_native_streaming: !1, supports_reasoning: !0, supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supported_endpoints: ["/v1/responses", "/v1/batch"] },
  o1: tt,
  "o1-mini": { max_tokens: 65536, max_input_tokens: 128e3, max_output_tokens: 65536, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, cache_read_input_token_cost: 55e-8, litellm_provider: "openai", mode: "chat", supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0 },
  "computer-use-preview": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 3e-6, output_cost_per_token: 12e-6, litellm_provider: "azure", mode: "chat", supported_endpoints: ["/v1/responses"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !1, supports_system_messages: !0, supports_tool_choice: !0, supports_reasoning: !0 },
  "o3-pro": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 2e-5, input_cost_per_token_batches: 1e-5, output_cost_per_token_batches: 4e-5, output_cost_per_token: 8e-5, litellm_provider: "openai", mode: "responses", supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0, supported_endpoints: ["/v1/responses", "/v1/batch"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"] },
  "o3-pro-2025-06-10": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 2e-5, input_cost_per_token_batches: 1e-5, output_cost_per_token_batches: 4e-5, output_cost_per_token: 8e-5, litellm_provider: "openai", mode: "responses", supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0, supported_endpoints: ["/v1/responses", "/v1/batch"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"] },
  o3: et,
  "o3-2025-04-16": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, cache_read_input_token_cost: 5e-7, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0, supported_endpoints: ["/v1/responses", "/v1/chat/completions", "/v1/completions", "/v1/batch"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"] },
  "o3-mini": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, cache_read_input_token_cost: 55e-8, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !1, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },
  "o3-mini-2025-01-31": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, cache_read_input_token_cost: 55e-8, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !1, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },
  "o4-mini": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, cache_read_input_token_cost: 275e-9, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },
  "o4-mini-2025-04-16": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, cache_read_input_token_cost: 275e-9, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },
  "o1-mini-2024-09-12": { max_tokens: 65536, max_input_tokens: 128e3, max_output_tokens: 65536, input_cost_per_token: 3e-6, output_cost_per_token: 12e-6, cache_read_input_token_cost: 15e-7, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_vision: !0, supports_reasoning: !0, supports_prompt_caching: !0 },
  "o1-preview": { max_tokens: 32768, max_input_tokens: 128e3, max_output_tokens: 32768, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, cache_read_input_token_cost: 75e-7, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_vision: !0, supports_reasoning: !0, supports_prompt_caching: !0 },
  "o1-preview-2024-09-12": { max_tokens: 32768, max_input_tokens: 128e3, max_output_tokens: 32768, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, cache_read_input_token_cost: 75e-7, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_vision: !0, supports_reasoning: !0, supports_prompt_caching: !0 },
  "o1-2024-12-17": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, cache_read_input_token_cost: 75e-7, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },
  "chatgpt-4o-latest": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 5e-6, output_cost_per_token: 15e-6, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4o-2024-05-13": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 5e-6, output_cost_per_token: 15e-6, input_cost_per_token_batches: 25e-7, output_cost_per_token_batches: 75e-7, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4o-2024-08-06": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, input_cost_per_token_batches: 125e-8, output_cost_per_token_batches: 5e-6, cache_read_input_token_cost: 125e-8, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4o-2024-11-20": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, input_cost_per_token_batches: 125e-8, output_cost_per_token_batches: 5e-6, cache_read_input_token_cost: 125e-8, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4o-realtime-preview-2024-10-01": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 5e-6, input_cost_per_audio_token: 1e-4, cache_read_input_token_cost: 25e-7, cache_creation_input_audio_token_cost: 2e-5, output_cost_per_token: 2e-5, output_cost_per_audio_token: 2e-4, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4o-realtime-preview": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 5e-6, input_cost_per_audio_token: 4e-5, cache_read_input_token_cost: 25e-7, output_cost_per_token: 2e-5, output_cost_per_audio_token: 8e-5, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4o-realtime-preview-2024-12-17": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 5e-6, input_cost_per_audio_token: 4e-5, cache_read_input_token_cost: 25e-7, output_cost_per_token: 2e-5, output_cost_per_audio_token: 8e-5, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4o-mini-realtime-preview": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 6e-7, input_cost_per_audio_token: 1e-5, cache_read_input_token_cost: 3e-7, cache_creation_input_audio_token_cost: 3e-7, output_cost_per_token: 24e-7, output_cost_per_audio_token: 2e-5, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4o-mini-realtime-preview-2024-12-17": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 6e-7, input_cost_per_audio_token: 1e-5, cache_read_input_token_cost: 3e-7, cache_creation_input_audio_token_cost: 3e-7, output_cost_per_token: 24e-7, output_cost_per_audio_token: 2e-5, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4-turbo-preview": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4-0314": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 3e-5, output_cost_per_token: 6e-5, litellm_provider: "openai", mode: "chat", supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4-0613": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 3e-5, output_cost_per_token: 6e-5, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_prompt_caching: !0, supports_system_messages: !0, deprecation_date: "2025-06-06", supports_tool_choice: !0 },
  "gpt-4-32k": { max_tokens: 4096, max_input_tokens: 32768, max_output_tokens: 4096, input_cost_per_token: 6e-5, output_cost_per_token: 12e-5, litellm_provider: "openai", mode: "chat", supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4-32k-0314": { max_tokens: 4096, max_input_tokens: 32768, max_output_tokens: 4096, input_cost_per_token: 6e-5, output_cost_per_token: 12e-5, litellm_provider: "openai", mode: "chat", supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4-32k-0613": { max_tokens: 4096, max_input_tokens: 32768, max_output_tokens: 4096, input_cost_per_token: 6e-5, output_cost_per_token: 12e-5, litellm_provider: "openai", mode: "chat", supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4-turbo": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4-turbo-2024-04-09": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4-1106-preview": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4-0125-preview": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-4-vision-preview": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: "openai", mode: "chat", supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_system_messages: !0, deprecation_date: "2024-12-06", supports_tool_choice: !0 },
  "gpt-4-1106-vision-preview": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: "openai", mode: "chat", supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_system_messages: !0, deprecation_date: "2024-12-06", supports_tool_choice: !0 },
  "gpt-3.5-turbo": { max_tokens: 4097, max_input_tokens: 16385, max_output_tokens: 4096, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-3.5-turbo-0301": { max_tokens: 4097, max_input_tokens: 4097, max_output_tokens: 4096, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: "openai", mode: "chat", supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-3.5-turbo-0613": { max_tokens: 4097, max_input_tokens: 4097, max_output_tokens: 4096, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-3.5-turbo-1106": { max_tokens: 16385, max_input_tokens: 16385, max_output_tokens: 4096, input_cost_per_token: 1e-6, output_cost_per_token: 2e-6, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-3.5-turbo-0125": { max_tokens: 16385, max_input_tokens: 16385, max_output_tokens: 4096, input_cost_per_token: 5e-7, output_cost_per_token: 15e-7, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-3.5-turbo-16k": { max_tokens: 16385, max_input_tokens: 16385, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 4e-6, litellm_provider: "openai", mode: "chat", supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "gpt-3.5-turbo-16k-0613": { max_tokens: 16385, max_input_tokens: 16385, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 4e-6, litellm_provider: "openai", mode: "chat", supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "ft:gpt-3.5-turbo": { max_tokens: 4096, max_input_tokens: 16385, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 6e-6, input_cost_per_token_batches: 15e-7, output_cost_per_token_batches: 3e-6, litellm_provider: "openai", mode: "chat", supports_system_messages: !0, supports_tool_choice: !0 },
  "ft:gpt-3.5-turbo-0125": { max_tokens: 4096, max_input_tokens: 16385, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 6e-6, litellm_provider: "openai", mode: "chat", supports_system_messages: !0, supports_tool_choice: !0 },
  "ft:gpt-3.5-turbo-1106": { max_tokens: 4096, max_input_tokens: 16385, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 6e-6, litellm_provider: "openai", mode: "chat", supports_system_messages: !0, supports_tool_choice: !0 },
  "ft:gpt-3.5-turbo-0613": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 6e-6, litellm_provider: "openai", mode: "chat", supports_system_messages: !0, supports_tool_choice: !0 },
  "ft:gpt-4-0613": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 3e-5, output_cost_per_token: 6e-5, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, source: "OpenAI needs to add pricing for this ft model, will be updated when added by OpenAI. Defaulting to base model pricing", supports_system_messages: !0, supports_tool_choice: !0 },
  "ft:gpt-4o-2024-08-06": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 375e-8, output_cost_per_token: 15e-6, input_cost_per_token_batches: 1875e-9, output_cost_per_token_batches: 75e-7, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "ft:gpt-4o-2024-11-20": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 375e-8, cache_creation_input_token_cost: 1875e-9, output_cost_per_token: 15e-6, litellm_provider: "openai", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "ft:gpt-4o-mini-2024-07-18": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 3e-7, output_cost_per_token: 12e-7, input_cost_per_token_batches: 15e-8, output_cost_per_token_batches: 6e-7, cache_read_input_token_cost: 15e-8, litellm_provider: "openai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "ft:davinci-002": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 4096, input_cost_per_token: 2e-6, output_cost_per_token: 2e-6, input_cost_per_token_batches: 1e-6, output_cost_per_token_batches: 1e-6, litellm_provider: "text-completion-openai", mode: "completion" },
  "ft:babbage-002": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 4096, input_cost_per_token: 4e-7, output_cost_per_token: 4e-7, input_cost_per_token_batches: 2e-7, output_cost_per_token_batches: 2e-7, litellm_provider: "text-completion-openai", mode: "completion" },
  "text-embedding-3-large": { max_tokens: 8191, max_input_tokens: 8191, output_vector_size: 3072, input_cost_per_token: 13e-8, output_cost_per_token: 0, input_cost_per_token_batches: 65e-9, output_cost_per_token_batches: 0, litellm_provider: "openai", mode: "embedding" },
  "text-embedding-3-small": { max_tokens: 8191, max_input_tokens: 8191, output_vector_size: 1536, input_cost_per_token: 2e-8, output_cost_per_token: 0, input_cost_per_token_batches: 1e-8, output_cost_per_token_batches: 0, litellm_provider: "openai", mode: "embedding" },
  "text-embedding-ada-002": { max_tokens: 8191, max_input_tokens: 8191, output_vector_size: 1536, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "openai", mode: "embedding" },
  "text-embedding-ada-002-v2": { max_tokens: 8191, max_input_tokens: 8191, input_cost_per_token: 1e-7, output_cost_per_token: 0, input_cost_per_token_batches: 5e-8, output_cost_per_token_batches: 0, litellm_provider: "openai", mode: "embedding" },
  "text-moderation-stable": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 0, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "openai", mode: "moderation" },
  "text-moderation-007": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 0, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "openai", mode: "moderation" },
  "text-moderation-latest": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 0, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "openai", mode: "moderation" },
  "256-x-256/dall-e-2": { mode: "image_generation", input_cost_per_pixel: 24414e-11, output_cost_per_pixel: 0, litellm_provider: "openai" },
  "512-x-512/dall-e-2": { mode: "image_generation", input_cost_per_pixel: 686e-10, output_cost_per_pixel: 0, litellm_provider: "openai" },
  "1024-x-1024/dall-e-2": { mode: "image_generation", input_cost_per_pixel: 19e-9, output_cost_per_pixel: 0, litellm_provider: "openai" },
  "hd/1024-x-1792/dall-e-3": { mode: "image_generation", input_cost_per_pixel: 6539e-11, output_cost_per_pixel: 0, litellm_provider: "openai" },
  "hd/1792-x-1024/dall-e-3": { mode: "image_generation", input_cost_per_pixel: 6539e-11, output_cost_per_pixel: 0, litellm_provider: "openai" },
  "hd/1024-x-1024/dall-e-3": { mode: "image_generation", input_cost_per_pixel: 7629e-11, output_cost_per_pixel: 0, litellm_provider: "openai" },
  "standard/1024-x-1792/dall-e-3": { mode: "image_generation", input_cost_per_pixel: 4359e-11, output_cost_per_pixel: 0, litellm_provider: "openai" },
  "standard/1792-x-1024/dall-e-3": { mode: "image_generation", input_cost_per_pixel: 4359e-11, output_cost_per_pixel: 0, litellm_provider: "openai" },
  "standard/1024-x-1024/dall-e-3": { mode: "image_generation", input_cost_per_pixel: 381469e-13, output_cost_per_pixel: 0, litellm_provider: "openai" },
  "gpt-image-1": { mode: "image_generation", input_cost_per_pixel: 40054321e-15, output_cost_per_pixel: 0, litellm_provider: "openai", supported_endpoints: ["/v1/images/generations"] },
  "low/1024-x-1024/gpt-image-1": { mode: "image_generation", input_cost_per_pixel: 10490417e-15, output_cost_per_pixel: 0, litellm_provider: "openai", supported_endpoints: ["/v1/images/generations"] },
  "medium/1024-x-1024/gpt-image-1": { mode: "image_generation", input_cost_per_pixel: 40054321e-15, output_cost_per_pixel: 0, litellm_provider: "openai", supported_endpoints: ["/v1/images/generations"] },
  "high/1024-x-1024/gpt-image-1": { mode: "image_generation", input_cost_per_pixel: 159263611e-15, output_cost_per_pixel: 0, litellm_provider: "openai", supported_endpoints: ["/v1/images/generations"] },
  "low/1024-x-1536/gpt-image-1": { mode: "image_generation", input_cost_per_pixel: 10172526e-15, output_cost_per_pixel: 0, litellm_provider: "openai", supported_endpoints: ["/v1/images/generations"] },
  "medium/1024-x-1536/gpt-image-1": { mode: "image_generation", input_cost_per_pixel: 40054321e-15, output_cost_per_pixel: 0, litellm_provider: "openai", supported_endpoints: ["/v1/images/generations"] },
  "high/1024-x-1536/gpt-image-1": { mode: "image_generation", input_cost_per_pixel: 158945719e-15, output_cost_per_pixel: 0, litellm_provider: "openai", supported_endpoints: ["/v1/images/generations"] },
  "low/1536-x-1024/gpt-image-1": { mode: "image_generation", input_cost_per_pixel: 10172526e-15, output_cost_per_pixel: 0, litellm_provider: "openai", supported_endpoints: ["/v1/images/generations"] },
  "medium/1536-x-1024/gpt-image-1": { mode: "image_generation", input_cost_per_pixel: 40054321e-15, output_cost_per_pixel: 0, litellm_provider: "openai", supported_endpoints: ["/v1/images/generations"] },
  "high/1536-x-1024/gpt-image-1": { mode: "image_generation", input_cost_per_pixel: 158945719e-15, output_cost_per_pixel: 0, litellm_provider: "openai", supported_endpoints: ["/v1/images/generations"] },
  "gpt-4o-transcribe": { mode: "audio_transcription", max_input_tokens: 16e3, max_output_tokens: 2e3, input_cost_per_token: 25e-7, input_cost_per_audio_token: 6e-6, output_cost_per_token: 1e-5, litellm_provider: "openai", supported_endpoints: ["/v1/audio/transcriptions"] },
  "gpt-4o-mini-transcribe": { mode: "audio_transcription", max_input_tokens: 16e3, max_output_tokens: 2e3, input_cost_per_token: 125e-8, input_cost_per_audio_token: 3e-6, output_cost_per_token: 5e-6, litellm_provider: "openai", supported_endpoints: ["/v1/audio/transcriptions"] },
  "whisper-1": { mode: "audio_transcription", input_cost_per_second: 1e-4, output_cost_per_second: 1e-4, litellm_provider: "openai", supported_endpoints: ["/v1/audio/transcriptions"] },
  "tts-1": { mode: "audio_speech", input_cost_per_character: 15e-6, litellm_provider: "openai", supported_endpoints: ["/v1/audio/speech"] },
  "tts-1-hd": { mode: "audio_speech", input_cost_per_character: 3e-5, litellm_provider: "openai", supported_endpoints: ["/v1/audio/speech"] },
  "gpt-4o-mini-tts": { mode: "audio_speech", input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, output_cost_per_audio_token: 12e-6, output_cost_per_second: 25e-5, litellm_provider: "openai", supported_modalities: ["text", "audio"], supported_output_modalities: ["audio"], supported_endpoints: ["/v1/audio/speech"] },
  "azure/gpt-4o-mini-tts": { mode: "audio_speech", input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, output_cost_per_audio_token: 12e-6, output_cost_per_second: 25e-5, litellm_provider: "azure", supported_modalities: ["text", "audio"], supported_output_modalities: ["audio"], supported_endpoints: ["/v1/audio/speech"] },
  "azure/computer-use-preview": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 3e-6, output_cost_per_token: 12e-6, litellm_provider: "azure", mode: "chat", supported_endpoints: ["/v1/responses"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !1, supports_system_messages: !0, supports_tool_choice: !0, supports_reasoning: !0 },
  "azure/gpt-4o-audio-preview-2024-12-17": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, input_cost_per_audio_token: 4e-5, output_cost_per_token: 1e-5, output_cost_per_audio_token: 8e-5, litellm_provider: "azure", mode: "chat", supported_endpoints: ["/v1/chat/completions"], supported_modalities: ["text", "audio"], supported_output_modalities: ["text", "audio"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !1, supports_vision: !1, supports_prompt_caching: !1, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0, supports_reasoning: !1 },
  "azure/gpt-4o-mini-audio-preview-2024-12-17": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, input_cost_per_audio_token: 4e-5, output_cost_per_token: 1e-5, output_cost_per_audio_token: 8e-5, litellm_provider: "azure", mode: "chat", supported_endpoints: ["/v1/chat/completions"], supported_modalities: ["text", "audio"], supported_output_modalities: ["text", "audio"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !1, supports_vision: !1, supports_prompt_caching: !1, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0, supports_reasoning: !1 },
  "azure/gpt-4.1": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, input_cost_per_token_batches: 1e-6, output_cost_per_token_batches: 4e-6, cache_read_input_token_cost: 5e-7, litellm_provider: "azure", mode: "chat", supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0, supports_web_search: !0, search_context_cost_per_query: { search_context_size_low: 0.03, search_context_size_medium: 0.035, search_context_size_high: 0.05 } },
  "azure/gpt-4.1-2025-04-14": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, input_cost_per_token_batches: 1e-6, output_cost_per_token_batches: 4e-6, cache_read_input_token_cost: 5e-7, litellm_provider: "azure", mode: "chat", supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0, supports_web_search: !0, search_context_cost_per_query: { search_context_size_low: 0.03, search_context_size_medium: 0.035, search_context_size_high: 0.05 } },
  "azure/gpt-4.1-mini": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 4e-7, output_cost_per_token: 16e-7, input_cost_per_token_batches: 2e-7, output_cost_per_token_batches: 8e-7, cache_read_input_token_cost: 1e-7, litellm_provider: "azure", mode: "chat", supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0, supports_web_search: !0, search_context_cost_per_query: { search_context_size_low: 0.025, search_context_size_medium: 0.0275, search_context_size_high: 0.03 } },
  "azure/gpt-4.1-mini-2025-04-14": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 4e-7, output_cost_per_token: 16e-7, input_cost_per_token_batches: 2e-7, output_cost_per_token_batches: 8e-7, cache_read_input_token_cost: 1e-7, litellm_provider: "azure", mode: "chat", supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0, supports_web_search: !0, search_context_cost_per_query: { search_context_size_low: 0.025, search_context_size_medium: 0.0275, search_context_size_high: 0.03 } },
  "azure/gpt-4.1-nano": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 1e-7, output_cost_per_token: 4e-7, input_cost_per_token_batches: 5e-8, output_cost_per_token_batches: 2e-7, cache_read_input_token_cost: 25e-9, litellm_provider: "azure", mode: "chat", supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0 },
  "azure/gpt-4.1-nano-2025-04-14": { max_tokens: 32768, max_input_tokens: 1047576, max_output_tokens: 32768, input_cost_per_token: 1e-7, output_cost_per_token: 4e-7, input_cost_per_token_batches: 5e-8, output_cost_per_token_batches: 2e-7, cache_read_input_token_cost: 25e-9, litellm_provider: "azure", mode: "chat", supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0, supports_native_streaming: !0 },
  "azure/o3": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 1e-5, output_cost_per_token: 4e-5, cache_read_input_token_cost: 25e-7, litellm_provider: "azure", mode: "chat", supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },
  "azure/o3-2025-04-16": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 1e-5, output_cost_per_token: 4e-5, cache_read_input_token_cost: 25e-7, litellm_provider: "azure", mode: "chat", supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },
  "azure/o4-mini": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, cache_read_input_token_cost: 275e-9, litellm_provider: "azure", mode: "chat", supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"], supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },
  "azure/gpt-4o-mini-realtime-preview-2024-12-17": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 6e-7, input_cost_per_audio_token: 1e-5, cache_read_input_token_cost: 3e-7, cache_creation_input_audio_token_cost: 3e-7, output_cost_per_token: 24e-7, output_cost_per_audio_token: 2e-5, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "azure/eu/gpt-4o-mini-realtime-preview-2024-12-17": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 66e-8, input_cost_per_audio_token: 11e-6, cache_read_input_token_cost: 33e-8, cache_creation_input_audio_token_cost: 33e-8, output_cost_per_token: 264e-8, output_cost_per_audio_token: 22e-6, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "azure/us/gpt-4o-mini-realtime-preview-2024-12-17": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 66e-8, input_cost_per_audio_token: 11e-6, cache_read_input_token_cost: 33e-8, cache_creation_input_audio_token_cost: 33e-8, output_cost_per_token: 264e-8, output_cost_per_audio_token: 22e-6, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "azure/gpt-4o-realtime-preview-2024-12-17": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 5e-6, input_cost_per_audio_token: 4e-5, cache_read_input_token_cost: 25e-7, output_cost_per_token: 2e-5, output_cost_per_audio_token: 8e-5, litellm_provider: "azure", mode: "chat", supported_modalities: ["text", "audio"], supported_output_modalities: ["text", "audio"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "azure/us/gpt-4o-realtime-preview-2024-12-17": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 55e-7, input_cost_per_audio_token: 44e-6, cache_read_input_token_cost: 275e-8, cache_read_input_audio_token_cost: 25e-7, output_cost_per_token: 22e-6, output_cost_per_audio_token: 8e-5, litellm_provider: "azure", mode: "chat", supported_modalities: ["text", "audio"], supported_output_modalities: ["text", "audio"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "azure/eu/gpt-4o-realtime-preview-2024-12-17": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 55e-7, input_cost_per_audio_token: 44e-6, cache_read_input_token_cost: 275e-8, cache_read_input_audio_token_cost: 25e-7, output_cost_per_token: 22e-6, output_cost_per_audio_token: 8e-5, litellm_provider: "azure", mode: "chat", supported_modalities: ["text", "audio"], supported_output_modalities: ["text", "audio"], supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "azure/gpt-4o-realtime-preview-2024-10-01": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 5e-6, input_cost_per_audio_token: 1e-4, cache_read_input_token_cost: 25e-7, cache_creation_input_audio_token_cost: 2e-5, output_cost_per_token: 2e-5, output_cost_per_audio_token: 2e-4, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "azure/us/gpt-4o-realtime-preview-2024-10-01": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 55e-7, input_cost_per_audio_token: 11e-5, cache_read_input_token_cost: 275e-8, cache_creation_input_audio_token_cost: 22e-6, output_cost_per_token: 22e-6, output_cost_per_audio_token: 22e-5, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "azure/eu/gpt-4o-realtime-preview-2024-10-01": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 55e-7, input_cost_per_audio_token: 11e-5, cache_read_input_token_cost: 275e-8, cache_creation_input_audio_token_cost: 22e-6, output_cost_per_token: 22e-6, output_cost_per_audio_token: 22e-5, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_audio_input: !0, supports_audio_output: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "azure/o4-mini-2025-04-16": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, cache_read_input_token_cost: 275e-9, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !1, supports_vision: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },
  "azure/o3-mini-2025-01-31": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, cache_read_input_token_cost: 55e-8, litellm_provider: "azure", mode: "chat", supports_reasoning: !0, supports_vision: !1, supports_prompt_caching: !0, supports_tool_choice: !0 },
  "azure/us/o3-mini-2025-01-31": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 121e-8, input_cost_per_token_batches: 605e-9, output_cost_per_token: 484e-8, output_cost_per_token_batches: 242e-8, cache_read_input_token_cost: 605e-9, litellm_provider: "azure", mode: "chat", supports_vision: !1, supports_reasoning: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },
  "azure/eu/o3-mini-2025-01-31": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 121e-8, input_cost_per_token_batches: 605e-9, output_cost_per_token: 484e-8, output_cost_per_token_batches: 242e-8, cache_read_input_token_cost: 605e-9, litellm_provider: "azure", mode: "chat", supports_vision: !1, supports_reasoning: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },
  "azure/tts-1": { mode: "audio_speech", input_cost_per_character: 15e-6, litellm_provider: "azure" },
  "azure/tts-1-hd": { mode: "audio_speech", input_cost_per_character: 3e-5, litellm_provider: "azure" },
  "azure/whisper-1": { mode: "audio_transcription", input_cost_per_second: 1e-4, output_cost_per_second: 1e-4, litellm_provider: "azure" },
  "azure/gpt-4o-transcribe": { mode: "audio_transcription", max_input_tokens: 16e3, max_output_tokens: 2e3, input_cost_per_token: 25e-7, input_cost_per_audio_token: 6e-6, output_cost_per_token: 1e-5, litellm_provider: "azure", supported_endpoints: ["/v1/audio/transcriptions"] },
  "azure/gpt-4o-mini-transcribe": { mode: "audio_transcription", max_input_tokens: 16e3, max_output_tokens: 2e3, input_cost_per_token: 125e-8, input_cost_per_audio_token: 3e-6, output_cost_per_token: 5e-6, litellm_provider: "azure", supported_endpoints: ["/v1/audio/transcriptions"] },
  "azure/o3-mini": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, cache_read_input_token_cost: 55e-8, litellm_provider: "azure", mode: "chat", supports_vision: !1, supports_prompt_caching: !0, supports_reasoning: !0, supports_response_schema: !0, supports_tool_choice: !0 },
  "azure/o1-mini": { max_tokens: 65536, max_input_tokens: 128e3, max_output_tokens: 65536, input_cost_per_token: 121e-8, output_cost_per_token: 484e-8, cache_read_input_token_cost: 605e-9, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_reasoning: !0, supports_prompt_caching: !0 },
  "azure/o1-mini-2024-09-12": { max_tokens: 65536, max_input_tokens: 128e3, max_output_tokens: 65536, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, cache_read_input_token_cost: 55e-8, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_reasoning: !0, supports_prompt_caching: !0 },
  "azure/us/o1-mini-2024-09-12": { max_tokens: 65536, max_input_tokens: 128e3, max_output_tokens: 65536, input_cost_per_token: 121e-8, input_cost_per_token_batches: 605e-9, output_cost_per_token: 484e-8, output_cost_per_token_batches: 242e-8, cache_read_input_token_cost: 605e-9, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_prompt_caching: !0 },
  "azure/eu/o1-mini-2024-09-12": { max_tokens: 65536, max_input_tokens: 128e3, max_output_tokens: 65536, input_cost_per_token: 121e-8, input_cost_per_token_batches: 605e-9, output_cost_per_token: 484e-8, output_cost_per_token_batches: 242e-8, cache_read_input_token_cost: 605e-9, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_prompt_caching: !0 },
  "azure/o1": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, cache_read_input_token_cost: 75e-7, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_reasoning: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },
  "azure/o1-2024-12-17": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, cache_read_input_token_cost: 75e-7, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_reasoning: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },
  "azure/us/o1-2024-12-17": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 165e-7, output_cost_per_token: 66e-6, cache_read_input_token_cost: 825e-8, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },
  "azure/eu/o1-2024-12-17": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 165e-7, output_cost_per_token: 66e-6, cache_read_input_token_cost: 825e-8, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },
  "azure/codex-mini-latest": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 15e-7, output_cost_per_token: 6e-6, cache_read_input_token_cost: 375e-9, litellm_provider: "azure", mode: "responses", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supported_modalities: ["text", "image"], supported_output_modalities: ["text"], supported_endpoints: ["/v1/responses"] },
  "azure/o1-preview": { max_tokens: 32768, max_input_tokens: 128e3, max_output_tokens: 32768, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, cache_read_input_token_cost: 75e-7, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_reasoning: !0, supports_prompt_caching: !0 },
  "azure/o1-preview-2024-09-12": { max_tokens: 32768, max_input_tokens: 128e3, max_output_tokens: 32768, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, cache_read_input_token_cost: 75e-7, litellm_provider: "azure", mode: "chat", supports_pdf_input: !0, supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_reasoning: !0, supports_prompt_caching: !0 },
  "azure/us/o1-preview-2024-09-12": { max_tokens: 32768, max_input_tokens: 128e3, max_output_tokens: 32768, input_cost_per_token: 165e-7, output_cost_per_token: 66e-6, cache_read_input_token_cost: 825e-8, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_prompt_caching: !0 },
  "azure/eu/o1-preview-2024-09-12": { max_tokens: 32768, max_input_tokens: 128e3, max_output_tokens: 32768, input_cost_per_token: 165e-7, output_cost_per_token: 66e-6, cache_read_input_token_cost: 825e-8, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_prompt_caching: !0 },
  "azure/gpt-4.5-preview": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 75e-6, output_cost_per_token: 15e-5, input_cost_per_token_batches: 375e-7, output_cost_per_token_batches: 75e-6, cache_read_input_token_cost: 375e-7, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_tool_choice: !0 },
  "azure/gpt-4o": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, cache_read_input_token_cost: 125e-8, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },
  "azure/global/gpt-4o-2024-11-20": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, cache_read_input_token_cost: 125e-8, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },
  "azure/gpt-4o-2024-08-06": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, cache_read_input_token_cost: 125e-8, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },
  "azure/global/gpt-4o-2024-08-06": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, cache_read_input_token_cost: 125e-8, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },
  "azure/gpt-4o-2024-11-20": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 275e-8, output_cost_per_token: 11e-6, cache_read_input_token_cost: 125e-8, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },
  "azure/us/gpt-4o-2024-11-20": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 275e-8, cache_creation_input_token_cost: 138e-8, output_cost_per_token: 11e-6, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_tool_choice: !0 },
  "azure/eu/gpt-4o-2024-11-20": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 275e-8, cache_creation_input_token_cost: 138e-8, output_cost_per_token: 11e-6, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_tool_choice: !0 },
  "azure/gpt-4o-2024-05-13": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 5e-6, output_cost_per_token: 15e-6, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },
  "azure/global-standard/gpt-4o-2024-08-06": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, cache_read_input_token_cost: 125e-8, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0, deprecation_date: "2025-08-20" },
  "azure/us/gpt-4o-2024-08-06": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 275e-8, output_cost_per_token: 11e-6, cache_read_input_token_cost: 1375e-9, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },
  "azure/eu/gpt-4o-2024-08-06": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 275e-8, output_cost_per_token: 11e-6, cache_read_input_token_cost: 1375e-9, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },
  "azure/global-standard/gpt-4o-2024-11-20": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, cache_read_input_token_cost: 125e-8, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_tool_choice: !0, deprecation_date: "2025-12-20" },
  "azure/global-standard/gpt-4o-mini": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_tool_choice: !0 },
  "azure/gpt-4o-mini": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 165e-9, output_cost_per_token: 66e-8, cache_read_input_token_cost: 75e-9, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },
  "azure/gpt-4o-mini-2024-07-18": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 165e-9, output_cost_per_token: 66e-8, cache_read_input_token_cost: 75e-9, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },
  "azure/us/gpt-4o-mini-2024-07-18": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 165e-9, output_cost_per_token: 66e-8, cache_read_input_token_cost: 83e-9, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },
  "azure/eu/gpt-4o-mini-2024-07-18": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 165e-9, output_cost_per_token: 66e-8, cache_read_input_token_cost: 83e-9, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },
  "azure/gpt-4-turbo-2024-04-09": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_tool_choice: !0 },
  "azure/gpt-4-0125-preview": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_tool_choice: !0 },
  "azure/gpt-4-1106-preview": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_tool_choice: !0 },
  "azure/gpt-4-0613": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 3e-5, output_cost_per_token: 6e-5, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "azure/gpt-4-32k-0613": { max_tokens: 4096, max_input_tokens: 32768, max_output_tokens: 4096, input_cost_per_token: 6e-5, output_cost_per_token: 12e-5, litellm_provider: "azure", mode: "chat", supports_tool_choice: !0 },
  "azure/gpt-4-32k": { max_tokens: 4096, max_input_tokens: 32768, max_output_tokens: 4096, input_cost_per_token: 6e-5, output_cost_per_token: 12e-5, litellm_provider: "azure", mode: "chat", supports_tool_choice: !0 },
  "azure/gpt-4": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 3e-5, output_cost_per_token: 6e-5, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "azure/gpt-4-turbo": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_tool_choice: !0 },
  "azure/gpt-4-turbo-vision-preview": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, litellm_provider: "azure", mode: "chat", supports_vision: !0, supports_tool_choice: !0 },
  "azure/gpt-35-turbo-16k-0613": { max_tokens: 4096, max_input_tokens: 16385, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 4e-6, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "azure/gpt-35-turbo-1106": { max_tokens: 4096, max_input_tokens: 16384, max_output_tokens: 4096, input_cost_per_token: 1e-6, output_cost_per_token: 2e-6, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, deprecation_date: "2025-03-31", supports_tool_choice: !0 },
  "azure/gpt-35-turbo-0613": { max_tokens: 4097, max_input_tokens: 4097, max_output_tokens: 4096, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, deprecation_date: "2025-02-13", supports_tool_choice: !0 },
  "azure/gpt-35-turbo-0301": { max_tokens: 4097, max_input_tokens: 4097, max_output_tokens: 4096, input_cost_per_token: 2e-7, output_cost_per_token: 2e-6, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, deprecation_date: "2025-02-13", supports_tool_choice: !0 },
  "azure/gpt-35-turbo-0125": { max_tokens: 4096, max_input_tokens: 16384, max_output_tokens: 4096, input_cost_per_token: 5e-7, output_cost_per_token: 15e-7, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, deprecation_date: "2025-05-31", supports_tool_choice: !0 },
  "azure/gpt-3.5-turbo-0125": { max_tokens: 4096, max_input_tokens: 16384, max_output_tokens: 4096, input_cost_per_token: 5e-7, output_cost_per_token: 15e-7, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, deprecation_date: "2025-03-31", supports_tool_choice: !0 },
  "azure/gpt-35-turbo-16k": { max_tokens: 4096, max_input_tokens: 16385, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 4e-6, litellm_provider: "azure", mode: "chat", supports_tool_choice: !0 },
  "azure/gpt-35-turbo": { max_tokens: 4096, max_input_tokens: 4097, max_output_tokens: 4096, input_cost_per_token: 5e-7, output_cost_per_token: 15e-7, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "azure/gpt-3.5-turbo": { max_tokens: 4096, max_input_tokens: 4097, max_output_tokens: 4096, input_cost_per_token: 5e-7, output_cost_per_token: 15e-7, litellm_provider: "azure", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "azure/gpt-3.5-turbo-instruct-0914": { max_tokens: 4097, max_input_tokens: 4097, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: "azure_text", mode: "completion" },
  "azure/gpt-35-turbo-instruct": { max_tokens: 4097, max_input_tokens: 4097, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: "azure_text", mode: "completion" },
  "azure/gpt-35-turbo-instruct-0914": { max_tokens: 4097, max_input_tokens: 4097, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: "azure_text", mode: "completion" },
  "azure/mistral-large-latest": { max_tokens: 32e3, max_input_tokens: 32e3, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "azure", mode: "chat", supports_function_calling: !0 },
  "azure/mistral-large-2402": { max_tokens: 32e3, max_input_tokens: 32e3, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "azure", mode: "chat", supports_function_calling: !0 },
  "azure/command-r-plus": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "azure", mode: "chat", supports_function_calling: !0 },
  "azure/ada": { max_tokens: 8191, max_input_tokens: 8191, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "azure", mode: "embedding" },
  "azure/text-embedding-ada-002": { max_tokens: 8191, max_input_tokens: 8191, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "azure", mode: "embedding" },
  "azure/text-embedding-3-large": { max_tokens: 8191, max_input_tokens: 8191, input_cost_per_token: 13e-8, output_cost_per_token: 0, litellm_provider: "azure", mode: "embedding" },
  "azure/text-embedding-3-small": { max_tokens: 8191, max_input_tokens: 8191, input_cost_per_token: 2e-8, output_cost_per_token: 0, litellm_provider: "azure", mode: "embedding" },
  "azure/gpt-image-1": { mode: "image_generation", input_cost_per_pixel: 40054321e-15, output_cost_per_pixel: 0, litellm_provider: "azure", supported_endpoints: ["/v1/images/generations"] },
  "azure/low/1024-x-1024/gpt-image-1": { mode: "image_generation", input_cost_per_pixel: 10490417e-15, output_cost_per_pixel: 0, litellm_provider: "azure", supported_endpoints: ["/v1/images/generations"] },
  "azure/medium/1024-x-1024/gpt-image-1": { mode: "image_generation", input_cost_per_pixel: 40054321e-15, output_cost_per_pixel: 0, litellm_provider: "azure", supported_endpoints: ["/v1/images/generations"] },
  "azure/high/1024-x-1024/gpt-image-1": { mode: "image_generation", input_cost_per_pixel: 159263611e-15, output_cost_per_pixel: 0, litellm_provider: "azure", supported_endpoints: ["/v1/images/generations"] },
  "azure/low/1024-x-1536/gpt-image-1": { mode: "image_generation", input_cost_per_pixel: 10172526e-15, output_cost_per_pixel: 0, litellm_provider: "azure", supported_endpoints: ["/v1/images/generations"] },
  "azure/medium/1024-x-1536/gpt-image-1": { mode: "image_generation", input_cost_per_pixel: 40054321e-15, output_cost_per_pixel: 0, litellm_provider: "azure", supported_endpoints: ["/v1/images/generations"] },
  "azure/high/1024-x-1536/gpt-image-1": { mode: "image_generation", input_cost_per_pixel: 158945719e-15, output_cost_per_pixel: 0, litellm_provider: "azure", supported_endpoints: ["/v1/images/generations"] },
  "azure/low/1536-x-1024/gpt-image-1": { mode: "image_generation", input_cost_per_pixel: 10172526e-15, output_cost_per_pixel: 0, litellm_provider: "azure", supported_endpoints: ["/v1/images/generations"] },
  "azure/medium/1536-x-1024/gpt-image-1": { mode: "image_generation", input_cost_per_pixel: 40054321e-15, output_cost_per_pixel: 0, litellm_provider: "azure", supported_endpoints: ["/v1/images/generations"] },
  "azure/high/1536-x-1024/gpt-image-1": { mode: "image_generation", input_cost_per_pixel: 158945719e-15, output_cost_per_pixel: 0, litellm_provider: "azure", supported_endpoints: ["/v1/images/generations"] },
  "azure/standard/1024-x-1024/dall-e-3": { input_cost_per_pixel: 381469e-13, output_cost_per_token: 0, litellm_provider: "azure", mode: "image_generation" },
  "azure/hd/1024-x-1024/dall-e-3": { input_cost_per_pixel: 7629e-11, output_cost_per_token: 0, litellm_provider: "azure", mode: "image_generation" },
  "azure/standard/1024-x-1792/dall-e-3": { input_cost_per_pixel: 4359e-11, output_cost_per_token: 0, litellm_provider: "azure", mode: "image_generation" },
  "azure/standard/1792-x-1024/dall-e-3": { input_cost_per_pixel: 4359e-11, output_cost_per_token: 0, litellm_provider: "azure", mode: "image_generation" },
  "azure/hd/1024-x-1792/dall-e-3": { input_cost_per_pixel: 6539e-11, output_cost_per_token: 0, litellm_provider: "azure", mode: "image_generation" },
  "azure/hd/1792-x-1024/dall-e-3": { input_cost_per_pixel: 6539e-11, output_cost_per_token: 0, litellm_provider: "azure", mode: "image_generation" },
  "azure/standard/1024-x-1024/dall-e-2": { input_cost_per_pixel: 0, output_cost_per_token: 0, litellm_provider: "azure", mode: "image_generation" },
  "azure_ai/deepseek-r1": { max_tokens: 8192, max_input_tokens: 128e3, max_output_tokens: 8192, input_cost_per_token: 135e-8, output_cost_per_token: 54e-7, litellm_provider: "azure_ai", mode: "chat", supports_tool_choice: !0, supports_reasoning: !0, source: "https://techcommunity.microsoft.com/blog/machinelearningblog/deepseek-r1-improved-performance-higher-limits-and-transparent-pricing/4386367" },
  "azure_ai/deepseek-v3": { max_tokens: 8192, max_input_tokens: 128e3, max_output_tokens: 8192, input_cost_per_token: 114e-8, output_cost_per_token: 456e-8, litellm_provider: "azure_ai", mode: "chat", supports_tool_choice: !0, source: "https://techcommunity.microsoft.com/blog/machinelearningblog/announcing-deepseek-v3-on-azure-ai-foundry-and-github/4390438" },
  "azure_ai/deepseek-v3-0324": { max_tokens: 8192, max_input_tokens: 128e3, max_output_tokens: 8192, input_cost_per_token: 114e-8, output_cost_per_token: 456e-8, litellm_provider: "azure_ai", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0, source: "https://techcommunity.microsoft.com/blog/machinelearningblog/announcing-deepseek-v3-on-azure-ai-foundry-and-github/4390438" },
  "azure_ai/jamba-instruct": { max_tokens: 4096, max_input_tokens: 7e4, max_output_tokens: 4096, input_cost_per_token: 5e-7, output_cost_per_token: 7e-7, litellm_provider: "azure_ai", mode: "chat", supports_tool_choice: !0 },
  "azure_ai/mistral-nemo": { max_tokens: 4096, max_input_tokens: 131072, max_output_tokens: 4096, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: "azure_ai", mode: "chat", supports_function_calling: !0, source: "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-nemo-12b-2407?tab=PlansAndPrice" },
  "azure_ai/mistral-medium-2505": { max_tokens: 8191, max_input_tokens: 131072, max_output_tokens: 8191, input_cost_per_token: 4e-7, output_cost_per_token: 2e-6, litellm_provider: "azure_ai", mode: "chat", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "azure_ai/mistral-large": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 4e-6, output_cost_per_token: 12e-6, litellm_provider: "azure_ai", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "azure_ai/mistral-small": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 1e-6, output_cost_per_token: 3e-6, litellm_provider: "azure_ai", supports_function_calling: !0, mode: "chat", supports_tool_choice: !0 },
  "azure_ai/mistral-small-2503": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 1e-6, output_cost_per_token: 3e-6, litellm_provider: "azure_ai", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0 },
  "azure_ai/mistral-large-2407": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: "azure_ai", supports_function_calling: !0, mode: "chat", source: "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview", supports_tool_choice: !0 },
  "azure_ai/mistral-large-latest": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: "azure_ai", supports_function_calling: !0, mode: "chat", source: "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview", supports_tool_choice: !0 },
  "azure_ai/ministral-3b": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 4e-8, output_cost_per_token: 4e-8, litellm_provider: "azure_ai", supports_function_calling: !0, mode: "chat", source: "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.ministral-3b-2410-offer?tab=Overview", supports_tool_choice: !0 },
  "azure_ai/Llama-3.2-11B-Vision-Instruct": { max_tokens: 2048, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 37e-8, output_cost_per_token: 37e-8, litellm_provider: "azure_ai", supports_function_calling: !0, supports_vision: !0, mode: "chat", source: "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-11b-vision-instruct-offer?tab=Overview", supports_tool_choice: !0 },
  "azure_ai/Llama-3.3-70B-Instruct": { max_tokens: 2048, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 71e-8, output_cost_per_token: 71e-8, litellm_provider: "azure_ai", supports_function_calling: !0, mode: "chat", source: "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.llama-3-3-70b-instruct-offer?tab=Overview", supports_tool_choice: !0 },
  "azure_ai/Llama-4-Scout-17B-16E-Instruct": { max_tokens: 16384, max_input_tokens: 1e7, max_output_tokens: 16384, input_cost_per_token: 2e-7, output_cost_per_token: 78e-8, litellm_provider: "azure_ai", supports_function_calling: !0, supports_vision: !0, mode: "chat", source: "https://azure.microsoft.com/en-us/blog/introducing-the-llama-4-herd-in-azure-ai-foundry-and-azure-databricks/", supports_tool_choice: !0 },
  "azure_ai/Llama-4-Maverick-17B-128E-Instruct-FP8": { max_tokens: 16384, max_input_tokens: 1e6, max_output_tokens: 16384, input_cost_per_token: 141e-8, output_cost_per_token: 35e-8, litellm_provider: "azure_ai", supports_function_calling: !0, supports_vision: !0, mode: "chat", source: "https://azure.microsoft.com/en-us/blog/introducing-the-llama-4-herd-in-azure-ai-foundry-and-azure-databricks/", supports_tool_choice: !0 },
  "azure_ai/Llama-3.2-90B-Vision-Instruct": { max_tokens: 2048, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 204e-8, output_cost_per_token: 204e-8, litellm_provider: "azure_ai", supports_function_calling: !0, supports_vision: !0, mode: "chat", source: "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-90b-vision-instruct-offer?tab=Overview", supports_tool_choice: !0 },
  "azure_ai/Meta-Llama-3-70B-Instruct": { max_tokens: 2048, max_input_tokens: 8192, max_output_tokens: 2048, input_cost_per_token: 11e-7, output_cost_per_token: 37e-8, litellm_provider: "azure_ai", mode: "chat", supports_tool_choice: !0 },
  "azure_ai/Meta-Llama-3.1-8B-Instruct": { max_tokens: 2048, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 3e-7, output_cost_per_token: 61e-8, litellm_provider: "azure_ai", mode: "chat", source: "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-8b-instruct-offer?tab=PlansAndPrice", supports_tool_choice: !0 },
  "azure_ai/Meta-Llama-3.1-70B-Instruct": { max_tokens: 2048, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 268e-8, output_cost_per_token: 354e-8, litellm_provider: "azure_ai", mode: "chat", source: "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-70b-instruct-offer?tab=PlansAndPrice", supports_tool_choice: !0 },
  "azure_ai/Meta-Llama-3.1-405B-Instruct": { max_tokens: 2048, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 533e-8, output_cost_per_token: 16e-6, litellm_provider: "azure_ai", mode: "chat", source: "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-405b-instruct-offer?tab=PlansAndPrice", supports_tool_choice: !0 },
  "azure_ai/Phi-4-mini-instruct": { max_tokens: 4096, max_input_tokens: 131072, max_output_tokens: 4096, input_cost_per_token: 75e-9, output_cost_per_token: 3e-7, litellm_provider: "azure_ai", mode: "chat", supports_function_calling: !0, source: "https://techcommunity.microsoft.com/blog/Azure-AI-Services-blog/announcing-new-phi-pricing-empowering-your-business-with-small-language-models/4395112" },
  "azure_ai/Phi-4-multimodal-instruct": { max_tokens: 4096, max_input_tokens: 131072, max_output_tokens: 4096, input_cost_per_token: 8e-8, input_cost_per_audio_token: 4e-6, output_cost_per_token: 32e-8, litellm_provider: "azure_ai", mode: "chat", supports_audio_input: !0, supports_function_calling: !0, supports_vision: !0, source: "https://techcommunity.microsoft.com/blog/Azure-AI-Services-blog/announcing-new-phi-pricing-empowering-your-business-with-small-language-models/4395112" },
  "azure_ai/Phi-4": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 125e-9, output_cost_per_token: 5e-7, litellm_provider: "azure_ai", mode: "chat", supports_vision: !1, source: "https://techcommunity.microsoft.com/blog/machinelearningblog/affordable-innovation-unveiling-the-pricing-of-phi-3-slms-on-models-as-a-service/4156495", supports_function_calling: !0, supports_tool_choice: !0 },
  "azure_ai/Phi-3.5-mini-instruct": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 13e-8, output_cost_per_token: 52e-8, litellm_provider: "azure_ai", mode: "chat", supports_vision: !1, source: "https://azure.microsoft.com/en-us/pricing/details/phi-3/", supports_tool_choice: !0 },
  "azure_ai/Phi-3.5-vision-instruct": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 13e-8, output_cost_per_token: 52e-8, litellm_provider: "azure_ai", mode: "chat", supports_vision: !0, source: "https://azure.microsoft.com/en-us/pricing/details/phi-3/", supports_tool_choice: !0 },
  "azure_ai/Phi-3.5-MoE-instruct": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 16e-8, output_cost_per_token: 64e-8, litellm_provider: "azure_ai", mode: "chat", supports_vision: !1, source: "https://azure.microsoft.com/en-us/pricing/details/phi-3/", supports_tool_choice: !0 },
  "azure_ai/Phi-3-mini-4k-instruct": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 13e-8, output_cost_per_token: 52e-8, litellm_provider: "azure_ai", mode: "chat", supports_vision: !1, source: "https://azure.microsoft.com/en-us/pricing/details/phi-3/", supports_tool_choice: !0 },
  "azure_ai/Phi-3-mini-128k-instruct": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 13e-8, output_cost_per_token: 52e-8, litellm_provider: "azure_ai", mode: "chat", supports_vision: !1, source: "https://azure.microsoft.com/en-us/pricing/details/phi-3/", supports_tool_choice: !0 },
  "azure_ai/Phi-3-small-8k-instruct": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, litellm_provider: "azure_ai", mode: "chat", supports_vision: !1, source: "https://azure.microsoft.com/en-us/pricing/details/phi-3/", supports_tool_choice: !0 },
  "azure_ai/Phi-3-small-128k-instruct": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, litellm_provider: "azure_ai", mode: "chat", supports_vision: !1, source: "https://azure.microsoft.com/en-us/pricing/details/phi-3/", supports_tool_choice: !0 },
  "azure_ai/Phi-3-medium-4k-instruct": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 17e-8, output_cost_per_token: 68e-8, litellm_provider: "azure_ai", mode: "chat", supports_vision: !1, source: "https://azure.microsoft.com/en-us/pricing/details/phi-3/", supports_tool_choice: !0 },
  "azure_ai/Phi-3-medium-128k-instruct": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 17e-8, output_cost_per_token: 68e-8, litellm_provider: "azure_ai", mode: "chat", supports_vision: !1, source: "https://azure.microsoft.com/en-us/pricing/details/phi-3/", supports_tool_choice: !0 },
  "azure_ai/cohere-rerank-v3-multilingual": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, max_query_tokens: 2048, input_cost_per_token: 0, input_cost_per_query: 2e-3, output_cost_per_token: 0, litellm_provider: "azure_ai", mode: "rerank" },
  "azure_ai/cohere-rerank-v3-english": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, max_query_tokens: 2048, input_cost_per_token: 0, input_cost_per_query: 2e-3, output_cost_per_token: 0, litellm_provider: "azure_ai", mode: "rerank" },
  "azure_ai/Cohere-embed-v3-english": { max_tokens: 512, max_input_tokens: 512, output_vector_size: 1024, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "azure_ai", mode: "embedding", supports_embedding_image_input: !0, source: "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice" },
  "azure_ai/Cohere-embed-v3-multilingual": { max_tokens: 512, max_input_tokens: 512, output_vector_size: 1024, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "azure_ai", mode: "embedding", supports_embedding_image_input: !0, source: "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice" },
  "azure_ai/embed-v-4-0": { max_tokens: 128e3, max_input_tokens: 128e3, output_vector_size: 3072, input_cost_per_token: 12e-8, output_cost_per_token: 0, litellm_provider: "azure_ai", mode: "embedding", supports_embedding_image_input: !0, supported_endpoints: ["/v1/embeddings"], supported_modalities: ["text", "image"], source: "https://azuremarketplace.microsoft.com/pt-br/marketplace/apps/cohere.cohere-embed-4-offer?tab=PlansAndPrice" },
  "babbage-002": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 4096, input_cost_per_token: 4e-7, output_cost_per_token: 4e-7, litellm_provider: "text-completion-openai", mode: "completion" },
  "davinci-002": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 4096, input_cost_per_token: 2e-6, output_cost_per_token: 2e-6, litellm_provider: "text-completion-openai", mode: "completion" },
  "gpt-3.5-turbo-instruct": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: "text-completion-openai", mode: "completion" },
  "gpt-3.5-turbo-instruct-0914": { max_tokens: 4097, max_input_tokens: 8192, max_output_tokens: 4097, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: "text-completion-openai", mode: "completion" },
  "claude-instant-1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 163e-8, output_cost_per_token: 551e-8, litellm_provider: "anthropic", mode: "chat" },
  "mistral/mistral-tiny": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 25e-8, output_cost_per_token: 25e-8, litellm_provider: "mistral", mode: "chat", supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/mistral-small": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 1e-7, output_cost_per_token: 3e-7, litellm_provider: "mistral", supports_function_calling: !0, mode: "chat", supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/mistral-small-latest": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 1e-7, output_cost_per_token: 3e-7, litellm_provider: "mistral", supports_function_calling: !0, mode: "chat", supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/mistral-medium": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 27e-7, output_cost_per_token: 81e-7, litellm_provider: "mistral", mode: "chat", supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/mistral-medium-latest": { max_tokens: 8191, max_input_tokens: 131072, max_output_tokens: 8191, input_cost_per_token: 4e-7, output_cost_per_token: 2e-6, litellm_provider: "mistral", mode: "chat", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/mistral-medium-2505": { max_tokens: 8191, max_input_tokens: 131072, max_output_tokens: 8191, input_cost_per_token: 4e-7, output_cost_per_token: 2e-6, litellm_provider: "mistral", mode: "chat", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/mistral-medium-2312": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 27e-7, output_cost_per_token: 81e-7, litellm_provider: "mistral", mode: "chat", supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/mistral-large-latest": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: "mistral", mode: "chat", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/mistral-large-2411": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: "mistral", mode: "chat", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/mistral-large-2402": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 4e-6, output_cost_per_token: 12e-6, litellm_provider: "mistral", mode: "chat", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/mistral-large-2407": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 3e-6, output_cost_per_token: 9e-6, litellm_provider: "mistral", mode: "chat", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/pixtral-large-latest": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: "mistral", mode: "chat", supports_function_calling: !0, supports_assistant_prefill: !0, supports_vision: !0, supports_tool_choice: !0 },
  "mistral/pixtral-large-2411": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: "mistral", mode: "chat", supports_function_calling: !0, supports_assistant_prefill: !0, supports_vision: !0, supports_tool_choice: !0 },
  "mistral/pixtral-12b-2409": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: "mistral", mode: "chat", supports_function_calling: !0, supports_assistant_prefill: !0, supports_vision: !0, supports_tool_choice: !0 },
  "mistral/open-mistral-7b": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 25e-8, output_cost_per_token: 25e-8, litellm_provider: "mistral", mode: "chat", supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/open-mixtral-8x7b": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 7e-7, output_cost_per_token: 7e-7, litellm_provider: "mistral", mode: "chat", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/open-mixtral-8x22b": { max_tokens: 8191, max_input_tokens: 65336, max_output_tokens: 8191, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: "mistral", mode: "chat", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/codestral-latest": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 1e-6, output_cost_per_token: 3e-6, litellm_provider: "mistral", mode: "chat", supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/codestral-2405": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 1e-6, output_cost_per_token: 3e-6, litellm_provider: "mistral", mode: "chat", supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/open-mistral-nemo": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 3e-7, output_cost_per_token: 3e-7, litellm_provider: "mistral", mode: "chat", source: "https://mistral.ai/technology/", supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/open-mistral-nemo-2407": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 3e-7, output_cost_per_token: 3e-7, litellm_provider: "mistral", mode: "chat", source: "https://mistral.ai/technology/", supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/open-codestral-mamba": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 25e-8, output_cost_per_token: 25e-8, litellm_provider: "mistral", mode: "chat", source: "https://mistral.ai/technology/", supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/codestral-mamba-latest": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 25e-8, output_cost_per_token: 25e-8, litellm_provider: "mistral", mode: "chat", source: "https://mistral.ai/technology/", supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/devstral-small-2505": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 1e-7, output_cost_per_token: 3e-7, litellm_provider: "mistral", mode: "chat", source: "https://mistral.ai/news/devstral", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "mistral/magistral-medium-2506": { max_tokens: 4e4, max_input_tokens: 4e4, max_output_tokens: 4e4, input_cost_per_token: 2e-6, output_cost_per_token: 5e-6, litellm_provider: "mistral", mode: "chat", source: "https://mistral.ai/news/magistral", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0, supports_reasoning: !0 },
  "mistral/magistral-small-2506": { max_tokens: 4e4, max_input_tokens: 4e4, max_output_tokens: 4e4, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "mistral", mode: "chat", source: "https://mistral.ai/news/magistral", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0, supports_reasoning: !0 },
  "mistral/mistral-embed": { max_tokens: 8192, max_input_tokens: 8192, input_cost_per_token: 1e-7, litellm_provider: "mistral", mode: "embedding" },
  "deepseek/deepseek-reasoner": { max_tokens: 8192, max_input_tokens: 65536, max_output_tokens: 8192, input_cost_per_token: 55e-8, input_cost_per_token_cache_hit: 14e-8, output_cost_per_token: 219e-8, litellm_provider: "deepseek", mode: "chat", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_prompt_caching: !0 },
  "deepseek/deepseek-chat": { max_tokens: 8192, max_input_tokens: 65536, max_output_tokens: 8192, input_cost_per_token: 27e-8, input_cost_per_token_cache_hit: 7e-8, cache_read_input_token_cost: 7e-8, cache_creation_input_token_cost: 0, output_cost_per_token: 11e-7, litellm_provider: "deepseek", mode: "chat", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0, supports_prompt_caching: !0 },
  "codestral/codestral-latest": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "codestral", mode: "chat", source: "https://docs.mistral.ai/capabilities/code_generation/", supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "codestral/codestral-2405": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "codestral", mode: "chat", source: "https://docs.mistral.ai/capabilities/code_generation/", supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "text-completion-codestral/codestral-latest": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "text-completion-codestral", mode: "completion", source: "https://docs.mistral.ai/capabilities/code_generation/" },
  "text-completion-codestral/codestral-2405": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "text-completion-codestral", mode: "completion", source: "https://docs.mistral.ai/capabilities/code_generation/" },
  "xai/grok-beta": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 5e-6, output_cost_per_token: 15e-6, litellm_provider: "xai", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_web_search: !0 },
  "xai/grok-2-vision-1212": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 2e-6, input_cost_per_image: 2e-6, output_cost_per_token: 1e-5, litellm_provider: "xai", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_web_search: !0 },
  "xai/grok-2-vision-latest": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 2e-6, input_cost_per_image: 2e-6, output_cost_per_token: 1e-5, litellm_provider: "xai", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_web_search: !0 },
  "xai/grok-2-vision": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 2e-6, input_cost_per_image: 2e-6, output_cost_per_token: 1e-5, litellm_provider: "xai", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_web_search: !0 },
  "xai/grok-3": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "xai", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !1, source: "https://x.ai/api#pricing", supports_web_search: !0 },
  "xai/grok-3-beta": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "xai", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !1, source: "https://x.ai/api#pricing", supports_web_search: !0 },
  "xai/grok-3-fast-beta": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 5e-6, output_cost_per_token: 25e-6, litellm_provider: "xai", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !1, source: "https://x.ai/api#pricing", supports_web_search: !0 },
  "xai/grok-3-fast-latest": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 5e-6, output_cost_per_token: 25e-6, litellm_provider: "xai", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !1, source: "https://x.ai/api#pricing", supports_web_search: !0 },
  "xai/grok-3-mini-beta": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 3e-7, output_cost_per_token: 5e-7, litellm_provider: "xai", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_response_schema: !1, source: "https://x.ai/api#pricing", supports_web_search: !0 },
  "xai/grok-3-mini-fast-beta": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 6e-7, output_cost_per_token: 4e-6, litellm_provider: "xai", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_response_schema: !1, source: "https://x.ai/api#pricing", supports_web_search: !0 },
  "xai/grok-3-mini-fast-latest": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 6e-7, output_cost_per_token: 4e-6, litellm_provider: "xai", mode: "chat", supports_reasoning: !0, supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !1, source: "https://x.ai/api#pricing", supports_web_search: !0 },
  "xai/grok-vision-beta": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 5e-6, input_cost_per_image: 5e-6, output_cost_per_token: 15e-6, litellm_provider: "xai", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_web_search: !0 },
  "xai/grok-2-1212": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 2e-6, output_cost_per_token: 1e-5, litellm_provider: "xai", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0, supports_web_search: !0 },
  "xai/grok-2": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 2e-6, output_cost_per_token: 1e-5, litellm_provider: "xai", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0, supports_web_search: !0 },
  "xai/grok-2-latest": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 2e-6, output_cost_per_token: 1e-5, litellm_provider: "xai", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0, supports_web_search: !0 },
  "deepseek/deepseek-coder": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 14e-8, input_cost_per_token_cache_hit: 14e-9, output_cost_per_token: 28e-8, litellm_provider: "deepseek", mode: "chat", supports_function_calling: !0, supports_assistant_prefill: !0, supports_tool_choice: !0, supports_prompt_caching: !0 },
  "groq/deepseek-r1-distill-llama-70b": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 75e-8, output_cost_per_token: 99e-8, litellm_provider: "groq", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },
  "groq/llama-3.3-70b-versatile": { max_tokens: 32768, max_input_tokens: 128e3, max_output_tokens: 32768, input_cost_per_token: 59e-8, output_cost_per_token: 79e-8, litellm_provider: "groq", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0 },
  "groq/llama-3.3-70b-specdec": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 59e-8, output_cost_per_token: 99e-8, litellm_provider: "groq", mode: "chat", supports_tool_choice: !0, deprecation_date: "2025-04-14" },
  "groq/llama-guard-3-8b": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: "groq", mode: "chat" },
  "groq/llama2-70b-4096": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 7e-7, output_cost_per_token: 8e-7, litellm_provider: "groq", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0 },
  "groq/llama3-8b-8192": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 5e-8, output_cost_per_token: 8e-8, litellm_provider: "groq", mode: "chat", supports_tool_choice: !0 },
  "groq/llama-3.2-1b-preview": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 4e-8, output_cost_per_token: 4e-8, litellm_provider: "groq", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0, deprecation_date: "2025-04-14" },
  "groq/llama-3.2-3b-preview": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 6e-8, output_cost_per_token: 6e-8, litellm_provider: "groq", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0, deprecation_date: "2025-04-14" },
  "groq/llama-3.2-11b-text-preview": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 18e-8, output_cost_per_token: 18e-8, litellm_provider: "groq", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0, deprecation_date: "2024-10-28" },
  "groq/llama-3.2-11b-vision-preview": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 18e-8, output_cost_per_token: 18e-8, litellm_provider: "groq", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_tool_choice: !0, deprecation_date: "2025-04-14" },
  "groq/llama-3.2-90b-text-preview": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: "groq", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0, deprecation_date: "2024-11-25" },
  "groq/llama-3.2-90b-vision-preview": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: "groq", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_tool_choice: !0, deprecation_date: "2025-04-14" },
  "groq/llama3-70b-8192": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 59e-8, output_cost_per_token: 79e-8, litellm_provider: "groq", mode: "chat", supports_response_schema: !0, supports_tool_choice: !0 },
  "groq/llama-3.1-8b-instant": { max_tokens: 8192, max_input_tokens: 128e3, max_output_tokens: 8192, input_cost_per_token: 5e-8, output_cost_per_token: 8e-8, litellm_provider: "groq", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0 },
  "groq/llama-3.1-70b-versatile": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 59e-8, output_cost_per_token: 79e-8, litellm_provider: "groq", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0, deprecation_date: "2025-01-24" },
  "groq/llama-3.1-405b-reasoning": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 59e-8, output_cost_per_token: 79e-8, litellm_provider: "groq", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0 },
  "groq/meta-llama/llama-4-scout-17b-16e-instruct": { max_tokens: 8192, max_input_tokens: 131072, max_output_tokens: 8192, input_cost_per_token: 11e-8, output_cost_per_token: 34e-8, litellm_provider: "groq", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0 },
  "groq/meta-llama/llama-4-maverick-17b-128e-instruct": { max_tokens: 8192, max_input_tokens: 131072, max_output_tokens: 8192, input_cost_per_token: 2e-7, output_cost_per_token: 6e-7, litellm_provider: "groq", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0 },
  "groq/mistral-saba-24b": { max_tokens: 32e3, max_input_tokens: 32e3, max_output_tokens: 32e3, input_cost_per_token: 79e-8, output_cost_per_token: 79e-8, litellm_provider: "groq", mode: "chat" },
  "groq/mixtral-8x7b-32768": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 24e-8, output_cost_per_token: 24e-8, litellm_provider: "groq", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0, deprecation_date: "2025-03-20" },
  "groq/gemma-7b-it": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 7e-8, output_cost_per_token: 7e-8, litellm_provider: "groq", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0, deprecation_date: "2024-12-18" },
  "groq/gemma2-9b-it": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: "groq", mode: "chat", supports_function_calling: !1, supports_response_schema: !0, supports_tool_choice: !1 },
  "groq/llama3-groq-70b-8192-tool-use-preview": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 89e-8, output_cost_per_token: 89e-8, litellm_provider: "groq", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0, deprecation_date: "2025-01-06" },
  "groq/llama3-groq-8b-8192-tool-use-preview": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 19e-8, output_cost_per_token: 19e-8, litellm_provider: "groq", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0, deprecation_date: "2025-01-06" },
  "groq/qwen-qwq-32b": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 29e-8, output_cost_per_token: 39e-8, litellm_provider: "groq", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_reasoning: !0, supports_tool_choice: !0 },
  "groq/playai-tts": { max_tokens: 1e4, max_input_tokens: 1e4, max_output_tokens: 1e4, input_cost_per_character: 5e-5, litellm_provider: "groq", mode: "audio_speech" },
  "groq/whisper-large-v3": { input_cost_per_second: 3083e-8, output_cost_per_second: 0, litellm_provider: "groq", mode: "audio_transcription" },
  "groq/whisper-large-v3-turbo": { input_cost_per_second: 1111e-8, output_cost_per_second: 0, litellm_provider: "groq", mode: "audio_transcription" },
  "groq/distil-whisper-large-v3-en": { input_cost_per_second: 556e-8, output_cost_per_second: 0, litellm_provider: "groq", mode: "audio_transcription" },
  "cerebras/llama3.1-8b": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 1e-7, output_cost_per_token: 1e-7, litellm_provider: "cerebras", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "cerebras/llama3.1-70b": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 6e-7, output_cost_per_token: 6e-7, litellm_provider: "cerebras", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "cerebras/llama-3.3-70b": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 85e-8, output_cost_per_token: 12e-7, litellm_provider: "cerebras", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "cerebras/qwen-3-32b": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 4e-7, output_cost_per_token: 8e-7, litellm_provider: "cerebras", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0, source: "https://inference-docs.cerebras.ai/support/pricing" },
  "friendliai/meta-llama-3.1-8b-instruct": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 1e-7, output_cost_per_token: 1e-7, litellm_provider: "friendliai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_system_messages: !0, supports_response_schema: !0, supports_tool_choice: !0 },
  "friendliai/meta-llama-3.1-70b-instruct": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 6e-7, output_cost_per_token: 6e-7, litellm_provider: "friendliai", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_system_messages: !0, supports_response_schema: !0, supports_tool_choice: !0 },
  "claude-instant-1.2": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 163e-9, output_cost_per_token: 551e-9, litellm_provider: "anthropic", mode: "chat", supports_tool_choice: !0 },
  "claude-2": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "anthropic", mode: "chat" },
  "claude-2.1": { max_tokens: 8191, max_input_tokens: 2e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "anthropic", mode: "chat", supports_tool_choice: !0 },
  "claude-3-haiku-20240307": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 25e-8, output_cost_per_token: 125e-8, cache_creation_input_token_cost: 3e-7, cache_read_input_token_cost: 3e-8, litellm_provider: "anthropic", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 264, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: "2025-03-01", supports_tool_choice: !0 },
  "claude-3-5-haiku-20241022": { max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 8e-7, output_cost_per_token: 4e-6, cache_creation_input_token_cost: 1e-6, cache_read_input_token_cost: 8e-8, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, litellm_provider: "anthropic", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 264, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: "2025-10-01", supports_tool_choice: !0, supports_web_search: !0 },
  "claude-3-5-haiku-latest": { max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 1e-6, output_cost_per_token: 5e-6, cache_creation_input_token_cost: 125e-8, cache_read_input_token_cost: 1e-7, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, litellm_provider: "anthropic", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 264, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: "2025-10-01", supports_tool_choice: !0, supports_web_search: !0 },
  "claude-3-opus-latest": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, cache_creation_input_token_cost: 1875e-8, cache_read_input_token_cost: 15e-7, litellm_provider: "anthropic", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 395, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: "2025-03-01", supports_tool_choice: !0 },
  "claude-3-opus-20240229": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, cache_creation_input_token_cost: 1875e-8, cache_read_input_token_cost: 15e-7, litellm_provider: "anthropic", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 395, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: "2025-03-01", supports_tool_choice: !0 },
  "claude-3-sonnet-20240229": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "anthropic", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: "2025-07-21", supports_tool_choice: !0 },
  "claude-3-5-sonnet-latest": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, litellm_provider: "anthropic", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: "2025-06-01", supports_tool_choice: !0, supports_web_search: !0 },
  "claude-3-5-sonnet-20240620": { max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: "anthropic", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: "2025-06-01", supports_tool_choice: !0 },
  "claude-opus-4-20250514": { max_tokens: 32e3, max_input_tokens: 2e5, max_output_tokens: 32e3, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 1875e-8, cache_read_input_token_cost: 15e-7, litellm_provider: "anthropic", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },
  "claude-sonnet-4-20250514": { max_tokens: 64e3, max_input_tokens: 2e5, max_output_tokens: 64e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: "anthropic", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },
  "claude-4-opus-20250514": { max_tokens: 32e3, max_input_tokens: 2e5, max_output_tokens: 32e3, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 1875e-8, cache_read_input_token_cost: 15e-7, litellm_provider: "anthropic", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },
  "claude-4-sonnet-20250514": { max_tokens: 64e3, max_input_tokens: 2e5, max_output_tokens: 64e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: "anthropic", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },
  "claude-3-7-sonnet-latest": { supports_computer_use: !0, max_tokens: 128e3, max_input_tokens: 2e5, max_output_tokens: 128e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: "anthropic", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: "2025-06-01", supports_tool_choice: !0, supports_reasoning: !0 },
  "claude-3-7-sonnet-20250219": { supports_computer_use: !0, max_tokens: 128e3, max_input_tokens: 2e5, max_output_tokens: 128e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, litellm_provider: "anthropic", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: "2026-02-01", supports_tool_choice: !0, supports_reasoning: !0, supports_web_search: !0 },
  "claude-3-5-sonnet-20241022": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, litellm_provider: "anthropic", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: "2025-10-01", supports_tool_choice: !0, supports_web_search: !0 },
  "text-bison": { max_tokens: 2048, max_input_tokens: 8192, max_output_tokens: 2048, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-text-models", mode: "completion", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "text-bison@001": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-text-models", mode: "completion", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "text-bison@002": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-text-models", mode: "completion", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "text-bison32k": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-text-models", mode: "completion", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "text-bison32k@002": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-text-models", mode: "completion", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "text-unicorn": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 1e-5, output_cost_per_token: 28e-6, litellm_provider: "vertex_ai-text-models", mode: "completion", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "text-unicorn@001": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 1e-5, output_cost_per_token: 28e-6, litellm_provider: "vertex_ai-text-models", mode: "completion", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "chat-bison": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-chat-models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0 },
  "chat-bison@001": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-chat-models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0 },
  "chat-bison@002": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-chat-models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", deprecation_date: "2025-04-09", supports_tool_choice: !0 },
  "chat-bison-32k": { max_tokens: 8192, max_input_tokens: 32e3, max_output_tokens: 8192, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-chat-models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0 },
  "chat-bison-32k@002": { max_tokens: 8192, max_input_tokens: 32e3, max_output_tokens: 8192, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-chat-models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0 },
  "code-bison": { max_tokens: 1024, max_input_tokens: 6144, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-code-text-models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0 },
  "code-bison@001": { max_tokens: 1024, max_input_tokens: 6144, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-code-text-models", mode: "completion", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "code-bison@002": { max_tokens: 1024, max_input_tokens: 6144, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-code-text-models", mode: "completion", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "code-bison32k": { max_tokens: 1024, max_input_tokens: 6144, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-code-text-models", mode: "completion", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "code-bison-32k@002": { max_tokens: 1024, max_input_tokens: 6144, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-code-text-models", mode: "completion", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "code-gecko@001": { max_tokens: 64, max_input_tokens: 2048, max_output_tokens: 64, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, litellm_provider: "vertex_ai-code-text-models", mode: "completion", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "code-gecko@002": { max_tokens: 64, max_input_tokens: 2048, max_output_tokens: 64, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, litellm_provider: "vertex_ai-code-text-models", mode: "completion", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "code-gecko": { max_tokens: 64, max_input_tokens: 2048, max_output_tokens: 64, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, litellm_provider: "vertex_ai-code-text-models", mode: "completion", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "code-gecko-latest": { max_tokens: 64, max_input_tokens: 2048, max_output_tokens: 64, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, litellm_provider: "vertex_ai-code-text-models", mode: "completion", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "codechat-bison@latest": { max_tokens: 1024, max_input_tokens: 6144, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-code-chat-models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0 },
  "codechat-bison": { max_tokens: 1024, max_input_tokens: 6144, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-code-chat-models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0 },
  "codechat-bison@001": { max_tokens: 1024, max_input_tokens: 6144, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-code-chat-models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0 },
  "codechat-bison@002": { max_tokens: 1024, max_input_tokens: 6144, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-code-chat-models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0 },
  "codechat-bison-32k": { max_tokens: 8192, max_input_tokens: 32e3, max_output_tokens: 8192, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-code-chat-models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0 },
  "codechat-bison-32k@002": { max_tokens: 8192, max_input_tokens: 32e3, max_output_tokens: 8192, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, input_cost_per_character: 25e-8, output_cost_per_character: 5e-7, litellm_provider: "vertex_ai-code-chat-models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0 },
  "meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8": { max_tokens: 128e3, max_input_tokens: 1e7, max_output_tokens: 4028, litellm_provider: "meta_llama", mode: "chat", supports_function_calling: !1, source: "https://llama.developer.meta.com/docs/models", supports_tool_choice: !1, supported_modalities: ["text", "image"], supported_output_modalities: ["text"] },
  "meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8": { max_tokens: 128e3, max_input_tokens: 1e6, max_output_tokens: 4028, litellm_provider: "meta_llama", mode: "chat", supports_function_calling: !1, source: "https://llama.developer.meta.com/docs/models", supports_tool_choice: !1, supported_modalities: ["text", "image"], supported_output_modalities: ["text"] },
  "meta_llama/Llama-3.3-70B-Instruct": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4028, litellm_provider: "meta_llama", mode: "chat", supports_function_calling: !1, source: "https://llama.developer.meta.com/docs/models", supports_tool_choice: !1, supported_modalities: ["text"], supported_output_modalities: ["text"] },
  "meta_llama/Llama-3.3-8B-Instruct": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4028, litellm_provider: "meta_llama", mode: "chat", supports_function_calling: !1, source: "https://llama.developer.meta.com/docs/models", supports_tool_choice: !1, supported_modalities: ["text"], supported_output_modalities: ["text"] },
  "gemini-pro": { max_tokens: 8192, max_input_tokens: 32760, max_output_tokens: 8192, input_cost_per_image: 25e-4, input_cost_per_video_per_second: 2e-3, input_cost_per_token: 5e-7, input_cost_per_character: 125e-9, output_cost_per_token: 15e-7, output_cost_per_character: 375e-9, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/pricing", supports_tool_choice: !0 },
  "gemini-1.0-pro": { max_tokens: 8192, max_input_tokens: 32760, max_output_tokens: 8192, input_cost_per_image: 25e-4, input_cost_per_video_per_second: 2e-3, input_cost_per_token: 5e-7, input_cost_per_character: 125e-9, output_cost_per_token: 15e-7, output_cost_per_character: 375e-9, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/pricing#google_models", supports_tool_choice: !0 },
  "gemini-1.0-pro-001": { max_tokens: 8192, max_input_tokens: 32760, max_output_tokens: 8192, input_cost_per_image: 25e-4, input_cost_per_video_per_second: 2e-3, input_cost_per_token: 5e-7, input_cost_per_character: 125e-9, output_cost_per_token: 15e-7, output_cost_per_character: 375e-9, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_function_calling: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", deprecation_date: "2025-04-09", supports_tool_choice: !0, supports_parallel_function_calling: !0 },
  "gemini-1.0-ultra": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 2048, input_cost_per_image: 25e-4, input_cost_per_video_per_second: 2e-3, input_cost_per_token: 5e-7, input_cost_per_character: 125e-9, output_cost_per_token: 15e-7, output_cost_per_character: 375e-9, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_function_calling: !0, source: "As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0, supports_parallel_function_calling: !0 },
  "gemini-1.0-ultra-001": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 2048, input_cost_per_image: 25e-4, input_cost_per_video_per_second: 2e-3, input_cost_per_token: 5e-7, input_cost_per_character: 125e-9, output_cost_per_token: 15e-7, output_cost_per_character: 375e-9, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_function_calling: !0, source: "As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0, supports_parallel_function_calling: !0 },
  "gemini-1.0-pro-002": { max_tokens: 8192, max_input_tokens: 32760, max_output_tokens: 8192, input_cost_per_image: 25e-4, input_cost_per_video_per_second: 2e-3, input_cost_per_token: 5e-7, input_cost_per_character: 125e-9, output_cost_per_token: 15e-7, output_cost_per_character: 375e-9, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_function_calling: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", deprecation_date: "2025-04-09", supports_tool_choice: !0, supports_parallel_function_calling: !0 },
  "gemini-1.5-pro": { max_tokens: 8192, max_input_tokens: 2097152, max_output_tokens: 8192, input_cost_per_image: 32875e-8, input_cost_per_audio_per_second: 3125e-8, input_cost_per_video_per_second: 32875e-8, input_cost_per_token: 125e-8, input_cost_per_character: 3125e-10, input_cost_per_image_above_128k_tokens: 6575e-7, input_cost_per_video_per_second_above_128k_tokens: 6575e-7, input_cost_per_audio_per_second_above_128k_tokens: 625e-7, input_cost_per_token_above_128k_tokens: 25e-7, input_cost_per_character_above_128k_tokens: 625e-9, output_cost_per_token: 5e-6, output_cost_per_character: 125e-8, output_cost_per_token_above_128k_tokens: 1e-5, output_cost_per_character_above_128k_tokens: 25e-7, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_vision: !0, supports_pdf_input: !0, supports_system_messages: !0, supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_parallel_function_calling: !0 },
  "gemini-1.5-pro-002": { max_tokens: 8192, max_input_tokens: 2097152, max_output_tokens: 8192, input_cost_per_image: 32875e-8, input_cost_per_audio_per_second: 3125e-8, input_cost_per_video_per_second: 32875e-8, input_cost_per_token: 125e-8, input_cost_per_character: 3125e-10, input_cost_per_image_above_128k_tokens: 6575e-7, input_cost_per_video_per_second_above_128k_tokens: 6575e-7, input_cost_per_audio_per_second_above_128k_tokens: 625e-7, input_cost_per_token_above_128k_tokens: 25e-7, input_cost_per_character_above_128k_tokens: 625e-9, output_cost_per_token: 5e-6, output_cost_per_character: 125e-8, output_cost_per_token_above_128k_tokens: 1e-5, output_cost_per_character_above_128k_tokens: 25e-7, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_vision: !0, supports_system_messages: !0, supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-pro", deprecation_date: "2025-09-24", supports_parallel_function_calling: !0 },
  "gemini-1.5-pro-001": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, input_cost_per_image: 32875e-8, input_cost_per_audio_per_second: 3125e-8, input_cost_per_video_per_second: 32875e-8, input_cost_per_token: 125e-8, input_cost_per_character: 3125e-10, input_cost_per_image_above_128k_tokens: 6575e-7, input_cost_per_video_per_second_above_128k_tokens: 6575e-7, input_cost_per_audio_per_second_above_128k_tokens: 625e-7, input_cost_per_token_above_128k_tokens: 25e-7, input_cost_per_character_above_128k_tokens: 625e-9, output_cost_per_token: 5e-6, output_cost_per_character: 125e-8, output_cost_per_token_above_128k_tokens: 1e-5, output_cost_per_character_above_128k_tokens: 25e-7, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_vision: !0, supports_system_messages: !0, supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", deprecation_date: "2025-05-24", supports_parallel_function_calling: !0 },
  "gemini-1.5-pro-preview-0514": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, input_cost_per_image: 32875e-8, input_cost_per_audio_per_second: 3125e-8, input_cost_per_video_per_second: 32875e-8, input_cost_per_token: 78125e-12, input_cost_per_character: 3125e-10, input_cost_per_image_above_128k_tokens: 6575e-7, input_cost_per_video_per_second_above_128k_tokens: 6575e-7, input_cost_per_audio_per_second_above_128k_tokens: 625e-7, input_cost_per_token_above_128k_tokens: 15625e-11, input_cost_per_character_above_128k_tokens: 625e-9, output_cost_per_token: 3125e-10, output_cost_per_character: 125e-8, output_cost_per_token_above_128k_tokens: 625e-9, output_cost_per_character_above_128k_tokens: 25e-7, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_parallel_function_calling: !0 },
  "gemini-1.5-pro-preview-0215": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, input_cost_per_image: 32875e-8, input_cost_per_audio_per_second: 3125e-8, input_cost_per_video_per_second: 32875e-8, input_cost_per_token: 78125e-12, input_cost_per_character: 3125e-10, input_cost_per_image_above_128k_tokens: 6575e-7, input_cost_per_video_per_second_above_128k_tokens: 6575e-7, input_cost_per_audio_per_second_above_128k_tokens: 625e-7, input_cost_per_token_above_128k_tokens: 15625e-11, input_cost_per_character_above_128k_tokens: 625e-9, output_cost_per_token: 3125e-10, output_cost_per_character: 125e-8, output_cost_per_token_above_128k_tokens: 625e-9, output_cost_per_character_above_128k_tokens: 25e-7, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_parallel_function_calling: !0 },
  "gemini-1.5-pro-preview-0409": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, input_cost_per_image: 32875e-8, input_cost_per_audio_per_second: 3125e-8, input_cost_per_video_per_second: 32875e-8, input_cost_per_token: 78125e-12, input_cost_per_character: 3125e-10, input_cost_per_image_above_128k_tokens: 6575e-7, input_cost_per_video_per_second_above_128k_tokens: 6575e-7, input_cost_per_audio_per_second_above_128k_tokens: 625e-7, input_cost_per_token_above_128k_tokens: 15625e-11, input_cost_per_character_above_128k_tokens: 625e-9, output_cost_per_token: 3125e-10, output_cost_per_character: 125e-8, output_cost_per_token_above_128k_tokens: 625e-9, output_cost_per_character_above_128k_tokens: 25e-7, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_parallel_function_calling: !0 },
  "gemini-1.5-flash": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 2e-5, input_cost_per_video_per_second: 2e-5, input_cost_per_audio_per_second: 2e-6, input_cost_per_token: 75e-9, input_cost_per_character: 1875e-11, input_cost_per_token_above_128k_tokens: 1e-6, input_cost_per_character_above_128k_tokens: 25e-8, input_cost_per_image_above_128k_tokens: 4e-5, input_cost_per_video_per_second_above_128k_tokens: 4e-5, input_cost_per_audio_per_second_above_128k_tokens: 4e-6, output_cost_per_token: 3e-7, output_cost_per_character: 75e-9, output_cost_per_token_above_128k_tokens: 6e-7, output_cost_per_character_above_128k_tokens: 15e-8, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0, supports_parallel_function_calling: !0 },
  "gemini-1.5-flash-exp-0827": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 2e-5, input_cost_per_video_per_second: 2e-5, input_cost_per_audio_per_second: 2e-6, input_cost_per_token: 4688e-12, input_cost_per_character: 1875e-11, input_cost_per_token_above_128k_tokens: 1e-6, input_cost_per_character_above_128k_tokens: 25e-8, input_cost_per_image_above_128k_tokens: 4e-5, input_cost_per_video_per_second_above_128k_tokens: 4e-5, input_cost_per_audio_per_second_above_128k_tokens: 4e-6, output_cost_per_token: 46875e-13, output_cost_per_character: 1875e-11, output_cost_per_token_above_128k_tokens: 9375e-12, output_cost_per_character_above_128k_tokens: 375e-10, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0, supports_parallel_function_calling: !0 },
  "gemini-1.5-flash-002": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 2e-5, input_cost_per_video_per_second: 2e-5, input_cost_per_audio_per_second: 2e-6, input_cost_per_token: 75e-9, input_cost_per_character: 1875e-11, input_cost_per_token_above_128k_tokens: 1e-6, input_cost_per_character_above_128k_tokens: 25e-8, input_cost_per_image_above_128k_tokens: 4e-5, input_cost_per_video_per_second_above_128k_tokens: 4e-5, input_cost_per_audio_per_second_above_128k_tokens: 4e-6, output_cost_per_token: 3e-7, output_cost_per_character: 75e-9, output_cost_per_token_above_128k_tokens: 6e-7, output_cost_per_character_above_128k_tokens: 15e-8, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-flash", deprecation_date: "2025-09-24", supports_tool_choice: !0, supports_parallel_function_calling: !0 },
  "gemini-1.5-flash-001": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 2e-5, input_cost_per_video_per_second: 2e-5, input_cost_per_audio_per_second: 2e-6, input_cost_per_token: 75e-9, input_cost_per_character: 1875e-11, input_cost_per_token_above_128k_tokens: 1e-6, input_cost_per_character_above_128k_tokens: 25e-8, input_cost_per_image_above_128k_tokens: 4e-5, input_cost_per_video_per_second_above_128k_tokens: 4e-5, input_cost_per_audio_per_second_above_128k_tokens: 4e-6, output_cost_per_token: 3e-7, output_cost_per_character: 75e-9, output_cost_per_token_above_128k_tokens: 6e-7, output_cost_per_character_above_128k_tokens: 15e-8, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", deprecation_date: "2025-05-24", supports_tool_choice: !0, supports_parallel_function_calling: !0 },
  "gemini-1.5-flash-preview-0514": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 2e-5, input_cost_per_video_per_second: 2e-5, input_cost_per_audio_per_second: 2e-6, input_cost_per_token: 75e-9, input_cost_per_character: 1875e-11, input_cost_per_token_above_128k_tokens: 1e-6, input_cost_per_character_above_128k_tokens: 25e-8, input_cost_per_image_above_128k_tokens: 4e-5, input_cost_per_video_per_second_above_128k_tokens: 4e-5, input_cost_per_audio_per_second_above_128k_tokens: 4e-6, output_cost_per_token: 46875e-13, output_cost_per_character: 1875e-11, output_cost_per_token_above_128k_tokens: 9375e-12, output_cost_per_character_above_128k_tokens: 375e-10, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0, supports_parallel_function_calling: !0 },
  "gemini-pro-experimental": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, input_cost_per_character: 0, output_cost_per_character: 0, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_function_calling: !1, supports_tool_choice: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental", supports_parallel_function_calling: !0 },
  "gemini-flash-experimental": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, input_cost_per_character: 0, output_cost_per_character: 0, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_function_calling: !1, supports_tool_choice: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental", supports_parallel_function_calling: !0 },
  "gemini-pro-vision": { max_tokens: 2048, max_input_tokens: 16384, max_output_tokens: 2048, max_images_per_prompt: 16, max_videos_per_prompt: 1, max_video_length: 2, input_cost_per_token: 5e-7, output_cost_per_token: 15e-7, input_cost_per_image: 25e-4, litellm_provider: "vertex_ai-vision-models", mode: "chat", supports_function_calling: !0, supports_vision: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0, supports_parallel_function_calling: !0 },
  "gemini-1.0-pro-vision": { max_tokens: 2048, max_input_tokens: 16384, max_output_tokens: 2048, max_images_per_prompt: 16, max_videos_per_prompt: 1, max_video_length: 2, input_cost_per_token: 5e-7, output_cost_per_token: 15e-7, input_cost_per_image: 25e-4, litellm_provider: "vertex_ai-vision-models", mode: "chat", supports_function_calling: !0, supports_vision: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0, supports_parallel_function_calling: !0 },
  "gemini-1.0-pro-vision-001": { max_tokens: 2048, max_input_tokens: 16384, max_output_tokens: 2048, max_images_per_prompt: 16, max_videos_per_prompt: 1, max_video_length: 2, input_cost_per_token: 5e-7, output_cost_per_token: 15e-7, input_cost_per_image: 25e-4, litellm_provider: "vertex_ai-vision-models", mode: "chat", supports_function_calling: !0, supports_vision: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", deprecation_date: "2025-04-09", supports_tool_choice: !0, supports_parallel_function_calling: !0 },
  "medlm-medium": { max_tokens: 8192, max_input_tokens: 32768, max_output_tokens: 8192, input_cost_per_character: 5e-7, output_cost_per_character: 1e-6, litellm_provider: "vertex_ai-language-models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0 },
  "medlm-large": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_character: 5e-6, output_cost_per_character: 15e-6, litellm_provider: "vertex_ai-language-models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0 },
  "gemini-2.5-pro-exp-03-25": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 125e-8, input_cost_per_token_above_200k_tokens: 25e-7, output_cost_per_token: 1e-5, output_cost_per_token_above_200k_tokens: 15e-6, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_audio_input: !0, supports_video_input: !0, supports_pdf_input: !0, supports_response_schema: !0, supports_tool_choice: !0, supported_endpoints: ["/v1/chat/completions", "/v1/completions"], supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text"], source: "https://cloud.google.com/vertex-ai/generative-ai/pricing", supports_parallel_function_calling: !0, supports_web_search: !0 },
  "gemini-2.0-pro-exp-02-05": { max_tokens: 8192, max_input_tokens: 2097152, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 125e-8, input_cost_per_token_above_200k_tokens: 25e-7, output_cost_per_token: 1e-5, output_cost_per_token_above_200k_tokens: 15e-6, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_audio_input: !0, supports_video_input: !0, supports_pdf_input: !0, supports_response_schema: !0, supports_tool_choice: !0, supported_endpoints: ["/v1/chat/completions", "/v1/completions"], supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text"], source: "https://cloud.google.com/vertex-ai/generative-ai/pricing", supports_parallel_function_calling: !0, supports_web_search: !0 },
  "gemini-2.0-flash-exp": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 0, input_cost_per_video_per_second: 0, input_cost_per_audio_per_second: 0, input_cost_per_token: 15e-8, input_cost_per_character: 0, input_cost_per_token_above_128k_tokens: 0, input_cost_per_character_above_128k_tokens: 0, input_cost_per_image_above_128k_tokens: 0, input_cost_per_video_per_second_above_128k_tokens: 0, input_cost_per_audio_per_second_above_128k_tokens: 0, output_cost_per_token: 6e-7, output_cost_per_character: 0, output_cost_per_token_above_128k_tokens: 0, output_cost_per_character_above_128k_tokens: 0, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text", "image"], source: "https://cloud.google.com/vertex-ai/generative-ai/pricing", supports_tool_choice: !0, supports_parallel_function_calling: !0, supports_web_search: !0 },
  "gemini-2.0-flash-001": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 1e-6, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supports_tool_choice: !0, supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text", "image"], source: "https://cloud.google.com/vertex-ai/generative-ai/pricing", deprecation_date: "2026-02-05", supports_parallel_function_calling: !0, supports_web_search: !0 },
  "gemini-2.0-flash-thinking-exp": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 0, input_cost_per_video_per_second: 0, input_cost_per_audio_per_second: 0, input_cost_per_token: 0, input_cost_per_character: 0, input_cost_per_token_above_128k_tokens: 0, input_cost_per_character_above_128k_tokens: 0, input_cost_per_image_above_128k_tokens: 0, input_cost_per_video_per_second_above_128k_tokens: 0, input_cost_per_audio_per_second_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_character: 0, output_cost_per_token_above_128k_tokens: 0, output_cost_per_character_above_128k_tokens: 0, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text", "image"], source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash", supports_tool_choice: !0, supports_parallel_function_calling: !0, supports_web_search: !0 },
  "gemini-2.0-flash-thinking-exp-01-21": { max_tokens: 65536, max_input_tokens: 1048576, max_output_tokens: 65536, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 0, input_cost_per_video_per_second: 0, input_cost_per_audio_per_second: 0, input_cost_per_token: 0, input_cost_per_character: 0, input_cost_per_token_above_128k_tokens: 0, input_cost_per_character_above_128k_tokens: 0, input_cost_per_image_above_128k_tokens: 0, input_cost_per_video_per_second_above_128k_tokens: 0, input_cost_per_audio_per_second_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_character: 0, output_cost_per_token_above_128k_tokens: 0, output_cost_per_character_above_128k_tokens: 0, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_system_messages: !0, supports_function_calling: !1, supports_vision: !0, supports_response_schema: !1, supports_audio_output: !1, supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text", "image"], source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash", supports_tool_choice: !0, supports_parallel_function_calling: !0, supports_web_search: !0 },
  "gemini/gemini-2.5-pro-exp-03-25": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 0, input_cost_per_token_above_200k_tokens: 0, output_cost_per_token: 0, output_cost_per_token_above_200k_tokens: 0, litellm_provider: "gemini", mode: "chat", rpm: 5, tpm: 25e4, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_audio_input: !0, supports_video_input: !0, supports_pdf_input: !0, supports_response_schema: !0, supports_tool_choice: !0, supported_endpoints: ["/v1/chat/completions", "/v1/completions"], supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text"], source: "https://cloud.google.com/vertex-ai/generative-ai/pricing", supports_web_search: !0 },
  "gemini/gemini-2.5-flash-preview-tts": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 1e-6, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, output_cost_per_reasoning_token: 35e-7, litellm_provider: "gemini", mode: "chat", rpm: 10, tpm: 25e4, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_reasoning: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_endpoints: ["/v1/chat/completions", "/v1/completions"], supported_modalities: ["text"], supported_output_modalities: ["audio"], source: "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview", supports_web_search: !0 },
  "gemini/gemini-2.5-flash-preview-05-20": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 1e-6, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, output_cost_per_reasoning_token: 35e-7, litellm_provider: "gemini", mode: "chat", rpm: 10, tpm: 25e4, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_reasoning: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_endpoints: ["/v1/chat/completions", "/v1/completions"], supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text"], source: "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview", supports_web_search: !0, supports_url_context: !0 },
  "gemini/gemini-2.5-flash-preview-04-17": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 1e-6, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, output_cost_per_reasoning_token: 35e-7, litellm_provider: "gemini", mode: "chat", rpm: 10, tpm: 25e4, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_reasoning: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_endpoints: ["/v1/chat/completions", "/v1/completions"], supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text"], source: "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview", supports_web_search: !0 },
  "gemini-2.5-flash-preview-05-20": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 1e-6, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, output_cost_per_reasoning_token: 35e-7, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_reasoning: !0, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_endpoints: ["/v1/chat/completions", "/v1/completions", "/v1/batch"], supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text"], source: "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview", supports_parallel_function_calling: !0, supports_web_search: !0, supports_url_context: !0 },
  "gemini-2.5-flash-preview-04-17": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 1e-6, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, output_cost_per_reasoning_token: 35e-7, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_reasoning: !0, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_endpoints: ["/v1/chat/completions", "/v1/completions", "/v1/batch"], supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text"], source: "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview", supports_parallel_function_calling: !0, supports_web_search: !0 },
  "gemini-2.0-flash": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 1e-7, output_cost_per_token: 4e-7, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supports_audio_input: !0, supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text", "image"], supports_tool_choice: !0, source: "https://ai.google.dev/pricing#2_0flash", supports_parallel_function_calling: !0, supports_web_search: !0, supports_url_context: !0 },
  "gemini-2.0-flash-lite": { max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 50, input_cost_per_audio_token: 75e-9, input_cost_per_token: 75e-9, output_cost_per_token: 3e-7, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text"], source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash", supports_tool_choice: !0, supports_parallel_function_calling: !0, supports_web_search: !0 },
  "gemini-2.0-flash-lite-001": { max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 50, input_cost_per_audio_token: 75e-9, input_cost_per_token: 75e-9, output_cost_per_token: 3e-7, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text"], source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash", supports_tool_choice: !0, deprecation_date: "2026-02-25", supports_parallel_function_calling: !0, supports_web_search: !0 },
  "gemini-2.5-pro-preview-06-05": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 125e-8, input_cost_per_token: 125e-8, input_cost_per_token_above_200k_tokens: 25e-7, output_cost_per_token: 1e-5, output_cost_per_token_above_200k_tokens: 15e-6, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_reasoning: !0, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_endpoints: ["/v1/chat/completions", "/v1/completions", "/v1/batch"], supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text"], source: "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview", supports_parallel_function_calling: !0, supports_web_search: !0 },
  "gemini-2.5-pro-preview-05-06": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 125e-8, input_cost_per_token: 125e-8, input_cost_per_token_above_200k_tokens: 25e-7, output_cost_per_token: 1e-5, output_cost_per_token_above_200k_tokens: 15e-6, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_reasoning: !0, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_endpoints: ["/v1/chat/completions", "/v1/completions", "/v1/batch"], supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text"], supported_regions: ["global"], source: "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview", supports_parallel_function_calling: !0, supports_web_search: !0 },
  "gemini-2.5-pro-preview-03-25": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 125e-8, input_cost_per_token: 125e-8, input_cost_per_token_above_200k_tokens: 25e-7, output_cost_per_token: 1e-5, output_cost_per_token_above_200k_tokens: 15e-6, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_reasoning: !0, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_endpoints: ["/v1/chat/completions", "/v1/completions", "/v1/batch"], supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text"], source: "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview", supports_parallel_function_calling: !0, supports_web_search: !0 },
  "gemini-2.0-flash-preview-image-generation": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 1e-7, output_cost_per_token: 4e-7, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supports_audio_input: !0, supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text", "image"], supports_tool_choice: !0, source: "https://ai.google.dev/pricing#2_0flash", supports_parallel_function_calling: !0, supports_web_search: !0 },
  "gemini-2.5-pro-preview-tts": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 125e-8, input_cost_per_token_above_200k_tokens: 25e-7, output_cost_per_token: 1e-5, output_cost_per_token_above_200k_tokens: 15e-6, litellm_provider: "vertex_ai-language-models", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_modalities: ["text"], supported_output_modalities: ["audio"], source: "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview", supports_parallel_function_calling: !0, supports_web_search: !0 },
  "gemini/gemini-2.0-pro-exp-02-05": { max_tokens: 8192, max_input_tokens: 2097152, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 0, input_cost_per_video_per_second: 0, input_cost_per_audio_per_second: 0, input_cost_per_token: 0, input_cost_per_character: 0, input_cost_per_token_above_128k_tokens: 0, input_cost_per_character_above_128k_tokens: 0, input_cost_per_image_above_128k_tokens: 0, input_cost_per_video_per_second_above_128k_tokens: 0, input_cost_per_audio_per_second_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_character: 0, output_cost_per_token_above_128k_tokens: 0, output_cost_per_character_above_128k_tokens: 0, litellm_provider: "gemini", mode: "chat", rpm: 2, tpm: 1e6, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_audio_input: !0, supports_video_input: !0, supports_pdf_input: !0, supports_response_schema: !0, supports_tool_choice: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/pricing", supports_web_search: !0 },
  "gemini/gemini-2.0-flash-preview-image-generation": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 1e-7, output_cost_per_token: 4e-7, litellm_provider: "gemini", mode: "chat", rpm: 1e4, tpm: 1e7, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supports_audio_input: !0, supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text", "image"], supports_tool_choice: !0, source: "https://ai.google.dev/pricing#2_0flash", supports_web_search: !0 },
  "gemini/gemini-2.0-flash": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 1e-7, output_cost_per_token: 4e-7, litellm_provider: "gemini", mode: "chat", rpm: 1e4, tpm: 1e7, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supports_audio_input: !0, supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text", "image"], supports_tool_choice: !0, source: "https://ai.google.dev/pricing#2_0flash", supports_web_search: !0, supports_url_context: !0 },
  "gemini/gemini-2.0-flash-lite": { max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 50, input_cost_per_audio_token: 75e-9, input_cost_per_token: 75e-9, output_cost_per_token: 3e-7, litellm_provider: "gemini", mode: "chat", tpm: 4e6, rpm: 4e3, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supports_tool_choice: !0, supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text"], source: "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.0-flash-lite", supports_web_search: !0 },
  "gemini/gemini-2.0-flash-001": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 1e-7, output_cost_per_token: 4e-7, litellm_provider: "gemini", mode: "chat", rpm: 1e4, tpm: 1e7, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text", "image"], source: "https://ai.google.dev/pricing#2_0flash", supports_web_search: !0 },
  "gemini/gemini-2.5-pro-preview-tts": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 125e-8, input_cost_per_token_above_200k_tokens: 25e-7, output_cost_per_token: 1e-5, output_cost_per_token_above_200k_tokens: 15e-6, litellm_provider: "gemini", mode: "chat", rpm: 1e4, tpm: 1e7, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_modalities: ["text"], supported_output_modalities: ["audio"], source: "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview", supports_web_search: !0 },
  "gemini/gemini-2.5-pro-preview-06-05": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 125e-8, input_cost_per_token_above_200k_tokens: 25e-7, output_cost_per_token: 1e-5, output_cost_per_token_above_200k_tokens: 15e-6, litellm_provider: "gemini", mode: "chat", rpm: 1e4, tpm: 1e7, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text"], source: "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview", supports_web_search: !0, supports_url_context: !0 },
  "gemini/gemini-2.5-pro-preview-05-06": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 125e-8, input_cost_per_token_above_200k_tokens: 25e-7, output_cost_per_token: 1e-5, output_cost_per_token_above_200k_tokens: 15e-6, litellm_provider: "gemini", mode: "chat", rpm: 1e4, tpm: 1e7, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text"], source: "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview", supports_web_search: !0, supports_url_context: !0 },
  "gemini/gemini-2.5-pro-preview-03-25": { max_tokens: 65535, max_input_tokens: 1048576, max_output_tokens: 65535, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 125e-8, input_cost_per_token_above_200k_tokens: 25e-7, output_cost_per_token: 1e-5, output_cost_per_token_above_200k_tokens: 15e-6, litellm_provider: "gemini", mode: "chat", rpm: 1e4, tpm: 1e7, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text"], source: "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview", supports_web_search: !0 },
  "gemini/gemini-2.0-flash-exp": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 0, input_cost_per_video_per_second: 0, input_cost_per_audio_per_second: 0, input_cost_per_token: 0, input_cost_per_character: 0, input_cost_per_token_above_128k_tokens: 0, input_cost_per_character_above_128k_tokens: 0, input_cost_per_image_above_128k_tokens: 0, input_cost_per_video_per_second_above_128k_tokens: 0, input_cost_per_audio_per_second_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_character: 0, output_cost_per_token_above_128k_tokens: 0, output_cost_per_character_above_128k_tokens: 0, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, tpm: 4e6, rpm: 10, supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text", "image"], source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash", supports_tool_choice: !0, supports_web_search: !0 },
  "gemini/gemini-2.0-flash-lite-preview-02-05": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 75e-9, input_cost_per_token: 75e-9, output_cost_per_token: 3e-7, litellm_provider: "gemini", mode: "chat", rpm: 6e4, tpm: 1e7, supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, supports_tool_choice: !0, supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text"], source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash-lite", supports_web_search: !0 },
  "gemini/gemini-2.0-flash-thinking-exp": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 65536, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 0, input_cost_per_video_per_second: 0, input_cost_per_audio_per_second: 0, input_cost_per_token: 0, input_cost_per_character: 0, input_cost_per_token_above_128k_tokens: 0, input_cost_per_character_above_128k_tokens: 0, input_cost_per_image_above_128k_tokens: 0, input_cost_per_video_per_second_above_128k_tokens: 0, input_cost_per_audio_per_second_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_character: 0, output_cost_per_token_above_128k_tokens: 0, output_cost_per_character_above_128k_tokens: 0, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, tpm: 4e6, rpm: 10, supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text", "image"], source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash", supports_tool_choice: !0, supports_web_search: !0 },
  "gemini/gemini-2.0-flash-thinking-exp-01-21": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 65536, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_image: 0, input_cost_per_video_per_second: 0, input_cost_per_audio_per_second: 0, input_cost_per_token: 0, input_cost_per_character: 0, input_cost_per_token_above_128k_tokens: 0, input_cost_per_character_above_128k_tokens: 0, input_cost_per_image_above_128k_tokens: 0, input_cost_per_video_per_second_above_128k_tokens: 0, input_cost_per_audio_per_second_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_character: 0, output_cost_per_token_above_128k_tokens: 0, output_cost_per_character_above_128k_tokens: 0, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, tpm: 4e6, rpm: 10, supported_modalities: ["text", "image", "audio", "video"], supported_output_modalities: ["text", "image"], source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash", supports_tool_choice: !0, supports_web_search: !0 },
  "gemini/gemma-3-27b-it": { max_tokens: 8192, max_input_tokens: 131072, max_output_tokens: 8192, input_cost_per_image: 0, input_cost_per_video_per_second: 0, input_cost_per_audio_per_second: 0, input_cost_per_token: 0, input_cost_per_character: 0, input_cost_per_token_above_128k_tokens: 0, input_cost_per_character_above_128k_tokens: 0, input_cost_per_image_above_128k_tokens: 0, input_cost_per_video_per_second_above_128k_tokens: 0, input_cost_per_audio_per_second_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_character: 0, output_cost_per_token_above_128k_tokens: 0, output_cost_per_character_above_128k_tokens: 0, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, source: "https://aistudio.google.com", supports_tool_choice: !0 },
  "gemini/learnlm-1.5-pro-experimental": { max_tokens: 8192, max_input_tokens: 32767, max_output_tokens: 8192, input_cost_per_image: 0, input_cost_per_video_per_second: 0, input_cost_per_audio_per_second: 0, input_cost_per_token: 0, input_cost_per_character: 0, input_cost_per_token_above_128k_tokens: 0, input_cost_per_character_above_128k_tokens: 0, input_cost_per_image_above_128k_tokens: 0, input_cost_per_video_per_second_above_128k_tokens: 0, input_cost_per_audio_per_second_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_character: 0, output_cost_per_token_above_128k_tokens: 0, output_cost_per_character_above_128k_tokens: 0, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !1, source: "https://aistudio.google.com", supports_tool_choice: !0 },
  "vertex_ai/claude-3-sonnet": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "vertex_ai-anthropic_models", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "vertex_ai/claude-3-sonnet@20240229": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "vertex_ai-anthropic_models", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "vertex_ai/claude-3-5-sonnet": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "vertex_ai-anthropic_models", mode: "chat", supports_function_calling: !0, supports_pdf_input: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "vertex_ai/claude-3-5-sonnet@20240620": { max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "vertex_ai-anthropic_models", mode: "chat", supports_function_calling: !0, supports_pdf_input: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "vertex_ai/claude-3-5-sonnet-v2": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "vertex_ai-anthropic_models", mode: "chat", supports_function_calling: !0, supports_pdf_input: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "vertex_ai/claude-3-5-sonnet-v2@20241022": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "vertex_ai-anthropic_models", mode: "chat", supports_function_calling: !0, supports_pdf_input: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "vertex_ai/claude-3-7-sonnet@20250219": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: "vertex_ai-anthropic_models", mode: "chat", supports_function_calling: !0, supports_pdf_input: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, deprecation_date: "2025-06-01", supports_reasoning: !0, supports_tool_choice: !0 },
  "vertex_ai/claude-opus-4": { max_tokens: 32e3, max_input_tokens: 2e5, max_output_tokens: 32e3, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 1875e-8, cache_read_input_token_cost: 15e-7, litellm_provider: "vertex_ai-anthropic_models", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },
  "vertex_ai/claude-opus-4@20250514": { max_tokens: 32e3, max_input_tokens: 2e5, max_output_tokens: 32e3, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 1875e-8, cache_read_input_token_cost: 15e-7, litellm_provider: "vertex_ai-anthropic_models", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },
  "vertex_ai/claude-sonnet-4": { max_tokens: 64e3, max_input_tokens: 2e5, max_output_tokens: 64e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: "vertex_ai-anthropic_models", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },
  "vertex_ai/claude-sonnet-4@20250514": { max_tokens: 64e3, max_input_tokens: 2e5, max_output_tokens: 64e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: "vertex_ai-anthropic_models", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },
  "vertex_ai/claude-3-haiku": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 25e-8, output_cost_per_token: 125e-8, litellm_provider: "vertex_ai-anthropic_models", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "vertex_ai/claude-3-haiku@20240307": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 25e-8, output_cost_per_token: 125e-8, litellm_provider: "vertex_ai-anthropic_models", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "vertex_ai/claude-3-5-haiku": { max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 1e-6, output_cost_per_token: 5e-6, litellm_provider: "vertex_ai-anthropic_models", mode: "chat", supports_function_calling: !0, supports_pdf_input: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "vertex_ai/claude-3-5-haiku@20241022": { max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 1e-6, output_cost_per_token: 5e-6, litellm_provider: "vertex_ai-anthropic_models", mode: "chat", supports_function_calling: !0, supports_pdf_input: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "vertex_ai/claude-3-opus": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, litellm_provider: "vertex_ai-anthropic_models", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "vertex_ai/claude-3-opus@20240229": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, litellm_provider: "vertex_ai-anthropic_models", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "vertex_ai/meta/llama3-405b-instruct-maas": { max_tokens: 32e3, max_input_tokens: 32e3, max_output_tokens: 32e3, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "vertex_ai-llama_models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models", supports_tool_choice: !0 },
  "vertex_ai/meta/llama-4-scout-17b-16e-instruct-maas": { max_tokens: 1e7, max_input_tokens: 1e7, max_output_tokens: 1e7, input_cost_per_token: 25e-8, output_cost_per_token: 7e-7, litellm_provider: "vertex_ai-llama_models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models", supports_tool_choice: !0, supports_function_calling: !0, supported_modalities: ["text", "image"], supported_output_modalities: ["text", "code"] },
  "vertex_ai/meta/llama-4-scout-17b-128e-instruct-maas": { max_tokens: 1e7, max_input_tokens: 1e7, max_output_tokens: 1e7, input_cost_per_token: 25e-8, output_cost_per_token: 7e-7, litellm_provider: "vertex_ai-llama_models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models", supports_tool_choice: !0, supports_function_calling: !0, supported_modalities: ["text", "image"], supported_output_modalities: ["text", "code"] },
  "vertex_ai/meta/llama-4-maverick-17b-128e-instruct-maas": { max_tokens: 1e6, max_input_tokens: 1e6, max_output_tokens: 1e6, input_cost_per_token: 35e-8, output_cost_per_token: 115e-8, litellm_provider: "vertex_ai-llama_models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models", supports_tool_choice: !0, supports_function_calling: !0, supported_modalities: ["text", "image"], supported_output_modalities: ["text", "code"] },
  "vertex_ai/meta/llama-4-maverick-17b-16e-instruct-maas": { max_tokens: 1e6, max_input_tokens: 1e6, max_output_tokens: 1e6, input_cost_per_token: 35e-8, output_cost_per_token: 115e-8, litellm_provider: "vertex_ai-llama_models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models", supports_tool_choice: !0, supports_function_calling: !0, supported_modalities: ["text", "image"], supported_output_modalities: ["text", "code"] },
  "vertex_ai/meta/llama3-70b-instruct-maas": { max_tokens: 32e3, max_input_tokens: 32e3, max_output_tokens: 32e3, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "vertex_ai-llama_models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models", supports_tool_choice: !0 },
  "vertex_ai/meta/llama3-8b-instruct-maas": { max_tokens: 32e3, max_input_tokens: 32e3, max_output_tokens: 32e3, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "vertex_ai-llama_models", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models", supports_tool_choice: !0 },
  "vertex_ai/meta/llama-3.2-90b-vision-instruct-maas": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "vertex_ai-llama_models", mode: "chat", supports_system_messages: !0, supports_vision: !0, source: "https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas", supports_tool_choice: !0 },
  "vertex_ai/mistral-large@latest": { max_tokens: 8191, max_input_tokens: 128e3, max_output_tokens: 8191, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: "vertex_ai-mistral_models", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "vertex_ai/mistral-large@2411-001": { max_tokens: 8191, max_input_tokens: 128e3, max_output_tokens: 8191, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: "vertex_ai-mistral_models", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "vertex_ai/mistral-large-2411": { max_tokens: 8191, max_input_tokens: 128e3, max_output_tokens: 8191, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: "vertex_ai-mistral_models", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "vertex_ai/mistral-large@2407": { max_tokens: 8191, max_input_tokens: 128e3, max_output_tokens: 8191, input_cost_per_token: 2e-6, output_cost_per_token: 6e-6, litellm_provider: "vertex_ai-mistral_models", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "vertex_ai/mistral-nemo@latest": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: "vertex_ai-mistral_models", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "vertex_ai/mistral-small-2503@001": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 1e-6, output_cost_per_token: 3e-6, litellm_provider: "vertex_ai-mistral_models", supports_function_calling: !0, mode: "chat", supports_tool_choice: !0 },
  "vertex_ai/mistral-small-2503": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 1e-6, output_cost_per_token: 3e-6, litellm_provider: "vertex_ai-mistral_models", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0 },
  "vertex_ai/jamba-1.5-mini@001": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-7, output_cost_per_token: 4e-7, litellm_provider: "vertex_ai-ai21_models", mode: "chat", supports_tool_choice: !0 },
  "vertex_ai/jamba-1.5-large@001": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, litellm_provider: "vertex_ai-ai21_models", mode: "chat", supports_tool_choice: !0 },
  "vertex_ai/jamba-1.5": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-7, output_cost_per_token: 4e-7, litellm_provider: "vertex_ai-ai21_models", mode: "chat", supports_tool_choice: !0 },
  "vertex_ai/jamba-1.5-mini": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-7, output_cost_per_token: 4e-7, litellm_provider: "vertex_ai-ai21_models", mode: "chat", supports_tool_choice: !0 },
  "vertex_ai/jamba-1.5-large": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, litellm_provider: "vertex_ai-ai21_models", mode: "chat", supports_tool_choice: !0 },
  "vertex_ai/mistral-nemo@2407": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 3e-6, output_cost_per_token: 3e-6, litellm_provider: "vertex_ai-mistral_models", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "vertex_ai/codestral@latest": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 2e-7, output_cost_per_token: 6e-7, litellm_provider: "vertex_ai-mistral_models", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "vertex_ai/codestral@2405": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 2e-7, output_cost_per_token: 6e-7, litellm_provider: "vertex_ai-mistral_models", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "vertex_ai/codestral-2501": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 2e-7, output_cost_per_token: 6e-7, litellm_provider: "vertex_ai-mistral_models", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "vertex_ai/imagegeneration@006": { output_cost_per_image: 0.02, litellm_provider: "vertex_ai-image-models", mode: "image_generation", source: "https://cloud.google.com/vertex-ai/generative-ai/pricing" },
  "vertex_ai/imagen-3.0-generate-002": { output_cost_per_image: 0.04, litellm_provider: "vertex_ai-image-models", mode: "image_generation", source: "https://cloud.google.com/vertex-ai/generative-ai/pricing" },
  "vertex_ai/imagen-3.0-generate-001": { output_cost_per_image: 0.04, litellm_provider: "vertex_ai-image-models", mode: "image_generation", source: "https://cloud.google.com/vertex-ai/generative-ai/pricing" },
  "vertex_ai/imagen-3.0-fast-generate-001": { output_cost_per_image: 0.02, litellm_provider: "vertex_ai-image-models", mode: "image_generation", source: "https://cloud.google.com/vertex-ai/generative-ai/pricing" },
  "text-embedding-004": { max_tokens: 2048, max_input_tokens: 2048, output_vector_size: 768, input_cost_per_character: 25e-9, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "vertex_ai-embedding-models", mode: "embedding", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models" },
  "gemini-embedding-001": { max_tokens: 2048, max_input_tokens: 2048, output_vector_size: 3072, input_cost_per_token: 15e-8, output_cost_per_token: 0, litellm_provider: "vertex_ai-embedding-models", mode: "embedding", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models" },
  "text-embedding-005": { max_tokens: 2048, max_input_tokens: 2048, output_vector_size: 768, input_cost_per_character: 25e-9, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "vertex_ai-embedding-models", mode: "embedding", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models" },
  "text-multilingual-embedding-002": { max_tokens: 2048, max_input_tokens: 2048, output_vector_size: 768, input_cost_per_character: 25e-9, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "vertex_ai-embedding-models", mode: "embedding", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models" },
  multimodalembedding: ot,
  "multimodalembedding@001": { max_tokens: 2048, max_input_tokens: 2048, output_vector_size: 768, input_cost_per_character: 2e-7, input_cost_per_image: 1e-4, input_cost_per_video_per_second: 5e-4, input_cost_per_video_per_second_above_8s_interval: 1e-3, input_cost_per_video_per_second_above_15s_interval: 2e-3, input_cost_per_token: 8e-7, output_cost_per_token: 0, litellm_provider: "vertex_ai-embedding-models", mode: "embedding", supported_endpoints: ["/v1/embeddings"], supported_modalities: ["text", "image", "video"], source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models" },
  "text-embedding-large-exp-03-07": { max_tokens: 8192, max_input_tokens: 8192, output_vector_size: 3072, input_cost_per_character: 25e-9, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "vertex_ai-embedding-models", mode: "embedding", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models" },
  "textembedding-gecko": { max_tokens: 3072, max_input_tokens: 3072, output_vector_size: 768, input_cost_per_character: 25e-9, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "vertex_ai-embedding-models", mode: "embedding", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "textembedding-gecko-multilingual": { max_tokens: 3072, max_input_tokens: 3072, output_vector_size: 768, input_cost_per_character: 25e-9, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "vertex_ai-embedding-models", mode: "embedding", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "textembedding-gecko-multilingual@001": { max_tokens: 3072, max_input_tokens: 3072, output_vector_size: 768, input_cost_per_character: 25e-9, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "vertex_ai-embedding-models", mode: "embedding", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "textembedding-gecko@001": { max_tokens: 3072, max_input_tokens: 3072, output_vector_size: 768, input_cost_per_character: 25e-9, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "vertex_ai-embedding-models", mode: "embedding", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "textembedding-gecko@003": { max_tokens: 3072, max_input_tokens: 3072, output_vector_size: 768, input_cost_per_character: 25e-9, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "vertex_ai-embedding-models", mode: "embedding", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "text-embedding-preview-0409": { max_tokens: 3072, max_input_tokens: 3072, output_vector_size: 768, input_cost_per_token: 625e-11, input_cost_per_token_batch_requests: 5e-9, output_cost_per_token: 0, litellm_provider: "vertex_ai-embedding-models", mode: "embedding", source: "https://cloud.google.com/vertex-ai/generative-ai/pricing" },
  "text-multilingual-embedding-preview-0409": { max_tokens: 3072, max_input_tokens: 3072, output_vector_size: 768, input_cost_per_token: 625e-11, output_cost_per_token: 0, litellm_provider: "vertex_ai-embedding-models", mode: "embedding", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "palm/chat-bison": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, litellm_provider: "palm", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "palm/chat-bison-001": { max_tokens: 4096, max_input_tokens: 8192, max_output_tokens: 4096, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, litellm_provider: "palm", mode: "chat", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "palm/text-bison": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, litellm_provider: "palm", mode: "completion", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "palm/text-bison-001": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, litellm_provider: "palm", mode: "completion", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "palm/text-bison-safety-off": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, litellm_provider: "palm", mode: "completion", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "palm/text-bison-safety-recitation-off": { max_tokens: 1024, max_input_tokens: 8192, max_output_tokens: 1024, input_cost_per_token: 125e-9, output_cost_per_token: 125e-9, litellm_provider: "palm", mode: "completion", source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models" },
  "gemini/gemini-1.5-flash-002": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, cache_read_input_token_cost: 1875e-11, cache_creation_input_token_cost: 1e-6, input_cost_per_token: 75e-9, input_cost_per_token_above_128k_tokens: 15e-8, output_cost_per_token: 3e-7, output_cost_per_token_above_128k_tokens: 6e-7, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_prompt_caching: !0, tpm: 4e6, rpm: 2e3, source: "https://ai.google.dev/pricing", deprecation_date: "2025-09-24", supports_tool_choice: !0 },
  "gemini/gemini-1.5-flash-001": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, cache_read_input_token_cost: 1875e-11, cache_creation_input_token_cost: 1e-6, input_cost_per_token: 75e-9, input_cost_per_token_above_128k_tokens: 15e-8, output_cost_per_token: 3e-7, output_cost_per_token_above_128k_tokens: 6e-7, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_prompt_caching: !0, tpm: 4e6, rpm: 2e3, source: "https://ai.google.dev/pricing", deprecation_date: "2025-05-24", supports_tool_choice: !0 },
  "gemini/gemini-1.5-flash": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 75e-9, input_cost_per_token_above_128k_tokens: 15e-8, output_cost_per_token: 3e-7, output_cost_per_token_above_128k_tokens: 6e-7, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, tpm: 4e6, rpm: 2e3, source: "https://ai.google.dev/pricing", supports_tool_choice: !0 },
  "gemini/gemini-1.5-flash-latest": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 75e-9, input_cost_per_token_above_128k_tokens: 15e-8, output_cost_per_token: 3e-7, output_cost_per_token_above_128k_tokens: 6e-7, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_prompt_caching: !0, tpm: 4e6, rpm: 2e3, source: "https://ai.google.dev/pricing", supports_tool_choice: !0 },
  "gemini/gemini-1.5-flash-8b": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 0, input_cost_per_token_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_token_above_128k_tokens: 0, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_prompt_caching: !0, tpm: 4e6, rpm: 4e3, source: "https://ai.google.dev/pricing", supports_tool_choice: !0 },
  "gemini/gemini-1.5-flash-8b-exp-0924": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 0, input_cost_per_token_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_token_above_128k_tokens: 0, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_prompt_caching: !0, tpm: 4e6, rpm: 4e3, source: "https://ai.google.dev/pricing", supports_tool_choice: !0 },
  "gemini/gemini-exp-1114": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 0, input_cost_per_token_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_token_above_128k_tokens: 0, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_tool_choice: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, tpm: 4e6, rpm: 1e3, source: "https://ai.google.dev/pricing", metadata: { notes: "Rate limits not documented for gemini-exp-1114. Assuming same as gemini-1.5-pro.", supports_tool_choice: !0 } },
  "gemini/gemini-exp-1206": { max_tokens: 8192, max_input_tokens: 2097152, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 0, input_cost_per_token_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_token_above_128k_tokens: 0, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_tool_choice: !0, supports_vision: !0, supports_response_schema: !0, tpm: 4e6, rpm: 1e3, source: "https://ai.google.dev/pricing", metadata: { notes: "Rate limits not documented for gemini-exp-1206. Assuming same as gemini-1.5-pro.", supports_tool_choice: !0 } },
  "gemini/gemini-1.5-flash-exp-0827": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 0, input_cost_per_token_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_token_above_128k_tokens: 0, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, tpm: 4e6, rpm: 2e3, source: "https://ai.google.dev/pricing", supports_tool_choice: !0 },
  "gemini/gemini-1.5-flash-8b-exp-0827": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_token: 0, input_cost_per_token_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_token_above_128k_tokens: 0, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, tpm: 4e6, rpm: 4e3, source: "https://ai.google.dev/pricing", supports_tool_choice: !0 },
  "gemini/gemini-pro": { max_tokens: 8192, max_input_tokens: 32760, max_output_tokens: 8192, input_cost_per_token: 35e-8, input_cost_per_token_above_128k_tokens: 7e-7, output_cost_per_token: 105e-8, output_cost_per_token_above_128k_tokens: 21e-7, litellm_provider: "gemini", mode: "chat", supports_function_calling: !0, rpd: 3e4, tpm: 12e4, rpm: 360, source: "https://ai.google.dev/gemini-api/docs/models/gemini", supports_tool_choice: !0 },
  "gemini/gemini-1.5-pro": { max_tokens: 8192, max_input_tokens: 2097152, max_output_tokens: 8192, input_cost_per_token: 35e-7, input_cost_per_token_above_128k_tokens: 7e-6, output_cost_per_token: 105e-7, output_cost_per_token_above_128k_tokens: 21e-6, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_response_schema: !0, tpm: 4e6, rpm: 1e3, source: "https://ai.google.dev/pricing" },
  "gemini/gemini-1.5-pro-002": { max_tokens: 8192, max_input_tokens: 2097152, max_output_tokens: 8192, input_cost_per_token: 35e-7, input_cost_per_token_above_128k_tokens: 7e-6, output_cost_per_token: 105e-7, output_cost_per_token_above_128k_tokens: 21e-6, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_response_schema: !0, supports_prompt_caching: !0, tpm: 4e6, rpm: 1e3, source: "https://ai.google.dev/pricing", deprecation_date: "2025-09-24" },
  "gemini/gemini-1.5-pro-001": { max_tokens: 8192, max_input_tokens: 2097152, max_output_tokens: 8192, input_cost_per_token: 35e-7, input_cost_per_token_above_128k_tokens: 7e-6, output_cost_per_token: 105e-7, output_cost_per_token_above_128k_tokens: 21e-6, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_response_schema: !0, supports_prompt_caching: !0, tpm: 4e6, rpm: 1e3, source: "https://ai.google.dev/pricing", deprecation_date: "2025-05-24" },
  "gemini/gemini-1.5-pro-exp-0801": { max_tokens: 8192, max_input_tokens: 2097152, max_output_tokens: 8192, input_cost_per_token: 35e-7, input_cost_per_token_above_128k_tokens: 7e-6, output_cost_per_token: 105e-7, output_cost_per_token_above_128k_tokens: 21e-6, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_response_schema: !0, tpm: 4e6, rpm: 1e3, source: "https://ai.google.dev/pricing" },
  "gemini/gemini-1.5-pro-exp-0827": { max_tokens: 8192, max_input_tokens: 2097152, max_output_tokens: 8192, input_cost_per_token: 0, input_cost_per_token_above_128k_tokens: 0, output_cost_per_token: 0, output_cost_per_token_above_128k_tokens: 0, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_response_schema: !0, tpm: 4e6, rpm: 1e3, source: "https://ai.google.dev/pricing" },
  "gemini/gemini-1.5-pro-latest": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, input_cost_per_token: 35e-7, input_cost_per_token_above_128k_tokens: 7e-6, output_cost_per_token: 105e-8, output_cost_per_token_above_128k_tokens: 21e-6, litellm_provider: "gemini", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0, supports_response_schema: !0, tpm: 4e6, rpm: 1e3, source: "https://ai.google.dev/pricing" },
  "gemini/gemini-pro-vision": { max_tokens: 2048, max_input_tokens: 30720, max_output_tokens: 2048, input_cost_per_token: 35e-8, input_cost_per_token_above_128k_tokens: 7e-7, output_cost_per_token: 105e-8, output_cost_per_token_above_128k_tokens: 21e-7, litellm_provider: "gemini", mode: "chat", supports_function_calling: !0, supports_vision: !0, rpd: 3e4, tpm: 12e4, rpm: 360, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0 },
  "gemini/gemini-gemma-2-27b-it": { max_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 35e-8, output_cost_per_token: 105e-8, litellm_provider: "gemini", mode: "chat", supports_function_calling: !0, supports_vision: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0 },
  "gemini/gemini-gemma-2-9b-it": { max_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 35e-8, output_cost_per_token: 105e-8, litellm_provider: "gemini", mode: "chat", supports_function_calling: !0, supports_vision: !0, source: "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models", supports_tool_choice: !0 },
  "command-a-03-2025": { max_tokens: 8e3, max_input_tokens: 256e3, max_output_tokens: 8e3, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, litellm_provider: "cohere_chat", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "command-r": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, litellm_provider: "cohere_chat", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "command-r-08-2024": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, litellm_provider: "cohere_chat", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "command-r7b-12-2024": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 15e-8, output_cost_per_token: 375e-10, litellm_provider: "cohere_chat", mode: "chat", supports_function_calling: !0, source: "https://docs.cohere.com/v2/docs/command-r7b", supports_tool_choice: !0 },
  "command-light": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 3e-7, output_cost_per_token: 6e-7, litellm_provider: "cohere_chat", mode: "chat", supports_tool_choice: !0 },
  "command-r-plus": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, litellm_provider: "cohere_chat", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "command-r-plus-08-2024": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, litellm_provider: "cohere_chat", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "command-nightly": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 1e-6, output_cost_per_token: 2e-6, litellm_provider: "cohere", mode: "completion" },
  command: _t,
  "rerank-v3.5": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, max_query_tokens: 2048, input_cost_per_token: 0, input_cost_per_query: 2e-3, output_cost_per_token: 0, litellm_provider: "cohere", mode: "rerank" },
  "rerank-english-v3.0": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, max_query_tokens: 2048, input_cost_per_token: 0, input_cost_per_query: 2e-3, output_cost_per_token: 0, litellm_provider: "cohere", mode: "rerank" },
  "rerank-multilingual-v3.0": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, max_query_tokens: 2048, input_cost_per_token: 0, input_cost_per_query: 2e-3, output_cost_per_token: 0, litellm_provider: "cohere", mode: "rerank" },
  "rerank-english-v2.0": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, max_query_tokens: 2048, input_cost_per_token: 0, input_cost_per_query: 2e-3, output_cost_per_token: 0, litellm_provider: "cohere", mode: "rerank" },
  "rerank-multilingual-v2.0": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, max_query_tokens: 2048, input_cost_per_token: 0, input_cost_per_query: 2e-3, output_cost_per_token: 0, litellm_provider: "cohere", mode: "rerank" },
  "embed-english-light-v3.0": { max_tokens: 1024, max_input_tokens: 1024, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "cohere", mode: "embedding" },
  "embed-multilingual-v3.0": { max_tokens: 1024, max_input_tokens: 1024, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "cohere", supports_embedding_image_input: !0, mode: "embedding" },
  "embed-english-v2.0": { max_tokens: 4096, max_input_tokens: 4096, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "cohere", mode: "embedding" },
  "embed-english-light-v2.0": { max_tokens: 1024, max_input_tokens: 1024, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "cohere", mode: "embedding" },
  "embed-multilingual-v2.0": { max_tokens: 768, max_input_tokens: 768, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "cohere", mode: "embedding" },
  "embed-english-v3.0": { max_tokens: 1024, max_input_tokens: 1024, input_cost_per_token: 1e-7, input_cost_per_image: 1e-4, output_cost_per_token: 0, litellm_provider: "cohere", mode: "embedding", supports_image_input: !0, supports_embedding_image_input: !0, metadata: { notes: "'supports_image_input' is a deprecated field. Use 'supports_embedding_image_input' instead." } },
  "replicate/meta/llama-2-13b": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 1e-7, output_cost_per_token: 5e-7, litellm_provider: "replicate", mode: "chat", supports_tool_choice: !0 },
  "replicate/meta/llama-2-13b-chat": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 1e-7, output_cost_per_token: 5e-7, litellm_provider: "replicate", mode: "chat", supports_tool_choice: !0 },
  "replicate/meta/llama-2-70b": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 65e-8, output_cost_per_token: 275e-8, litellm_provider: "replicate", mode: "chat", supports_tool_choice: !0 },
  "replicate/meta/llama-2-70b-chat": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 65e-8, output_cost_per_token: 275e-8, litellm_provider: "replicate", mode: "chat", supports_tool_choice: !0 },
  "replicate/meta/llama-2-7b": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 5e-8, output_cost_per_token: 25e-8, litellm_provider: "replicate", mode: "chat", supports_tool_choice: !0 },
  "replicate/meta/llama-2-7b-chat": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 5e-8, output_cost_per_token: 25e-8, litellm_provider: "replicate", mode: "chat", supports_tool_choice: !0 },
  "replicate/meta/llama-3-70b": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 65e-8, output_cost_per_token: 275e-8, litellm_provider: "replicate", mode: "chat", supports_tool_choice: !0 },
  "replicate/meta/llama-3-70b-instruct": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 65e-8, output_cost_per_token: 275e-8, litellm_provider: "replicate", mode: "chat", supports_tool_choice: !0 },
  "replicate/meta/llama-3-8b": { max_tokens: 8086, max_input_tokens: 8086, max_output_tokens: 8086, input_cost_per_token: 5e-8, output_cost_per_token: 25e-8, litellm_provider: "replicate", mode: "chat", supports_tool_choice: !0 },
  "replicate/meta/llama-3-8b-instruct": { max_tokens: 8086, max_input_tokens: 8086, max_output_tokens: 8086, input_cost_per_token: 5e-8, output_cost_per_token: 25e-8, litellm_provider: "replicate", mode: "chat", supports_tool_choice: !0 },
  "replicate/mistralai/mistral-7b-v0.1": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 5e-8, output_cost_per_token: 25e-8, litellm_provider: "replicate", mode: "chat", supports_tool_choice: !0 },
  "replicate/mistralai/mistral-7b-instruct-v0.2": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 5e-8, output_cost_per_token: 25e-8, litellm_provider: "replicate", mode: "chat", supports_tool_choice: !0 },
  "replicate/mistralai/mixtral-8x7b-instruct-v0.1": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 3e-7, output_cost_per_token: 1e-6, litellm_provider: "replicate", mode: "chat", supports_tool_choice: !0 },
  "openrouter/deepseek/deepseek-r1": { max_tokens: 8192, max_input_tokens: 65336, max_output_tokens: 8192, input_cost_per_token: 55e-8, input_cost_per_token_cache_hit: 14e-8, output_cost_per_token: 219e-8, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_assistant_prefill: !0, supports_reasoning: !0, supports_tool_choice: !0, supports_prompt_caching: !0 },
  "openrouter/deepseek/deepseek-chat": { max_tokens: 8192, max_input_tokens: 65536, max_output_tokens: 8192, input_cost_per_token: 14e-8, output_cost_per_token: 28e-8, litellm_provider: "openrouter", supports_prompt_caching: !0, mode: "chat", supports_tool_choice: !0 },
  "openrouter/deepseek/deepseek-coder": { max_tokens: 8192, max_input_tokens: 66e3, max_output_tokens: 4096, input_cost_per_token: 14e-8, output_cost_per_token: 28e-8, litellm_provider: "openrouter", supports_prompt_caching: !0, mode: "chat", supports_tool_choice: !0 },
  "openrouter/microsoft/wizardlm-2-8x22b:nitro": { max_tokens: 65536, input_cost_per_token: 1e-6, output_cost_per_token: 1e-6, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/google/gemini-pro-1.5": { max_tokens: 8192, max_input_tokens: 1e6, max_output_tokens: 8192, input_cost_per_token: 25e-7, output_cost_per_token: 75e-7, input_cost_per_image: 265e-5, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0 },
  "openrouter/google/gemini-2.0-flash-001": { max_tokens: 8192, max_input_tokens: 1048576, max_output_tokens: 8192, max_images_per_prompt: 3e3, max_videos_per_prompt: 10, max_video_length: 1, max_audio_length_hours: 8.4, max_audio_per_prompt: 1, max_pdf_size_mb: 30, input_cost_per_audio_token: 7e-7, input_cost_per_token: 1e-7, output_cost_per_token: 4e-7, litellm_provider: "openrouter", mode: "chat", supports_system_messages: !0, supports_function_calling: !0, supports_vision: !0, supports_response_schema: !0, supports_audio_output: !0, supports_tool_choice: !0 },
  "openrouter/mistralai/mixtral-8x22b-instruct": { max_tokens: 65536, input_cost_per_token: 65e-8, output_cost_per_token: 65e-8, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/cohere/command-r-plus": { max_tokens: 128e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/databricks/dbrx-instruct": { max_tokens: 32768, input_cost_per_token: 6e-7, output_cost_per_token: 6e-7, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/anthropic/claude-3-haiku": { max_tokens: 2e5, input_cost_per_token: 25e-8, output_cost_per_token: 125e-8, input_cost_per_image: 4e-4, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0 },
  "openrouter/anthropic/claude-3-5-haiku": { max_tokens: 2e5, input_cost_per_token: 1e-6, output_cost_per_token: 5e-6, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "openrouter/anthropic/claude-3-haiku-20240307": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 25e-8, output_cost_per_token: 125e-8, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 264, supports_tool_choice: !0 },
  "openrouter/anthropic/claude-3-5-haiku-20241022": { max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 1e-6, output_cost_per_token: 5e-6, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, tool_use_system_prompt_tokens: 264, supports_tool_choice: !0 },
  "openrouter/anthropic/claude-3.5-sonnet": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "openrouter/anthropic/claude-3.5-sonnet:beta": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_tool_choice: !0 },
  "openrouter/anthropic/claude-3.7-sonnet": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, input_cost_per_image: 48e-4, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_reasoning: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_tool_choice: !0 },
  "openrouter/anthropic/claude-3.7-sonnet:beta": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, input_cost_per_image: 48e-4, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_reasoning: !0, tool_use_system_prompt_tokens: 159, supports_tool_choice: !0 },
  "openrouter/anthropic/claude-3-sonnet": { max_tokens: 2e5, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, input_cost_per_image: 48e-4, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0 },
  "openrouter/mistralai/mistral-large": { max_tokens: 32e3, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "mistralai/mistral-small-3.1-24b-instruct": { max_tokens: 32e3, input_cost_per_token: 1e-7, output_cost_per_token: 3e-7, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/cognitivecomputations/dolphin-mixtral-8x7b": { max_tokens: 32769, input_cost_per_token: 5e-7, output_cost_per_token: 5e-7, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/google/gemini-pro-vision": { max_tokens: 45875, input_cost_per_token: 125e-9, output_cost_per_token: 375e-9, input_cost_per_image: 25e-4, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0 },
  "openrouter/fireworks/firellava-13b": { max_tokens: 4096, input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/meta-llama/llama-3-8b-instruct:free": { max_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/meta-llama/llama-3-8b-instruct:extended": { max_tokens: 16384, input_cost_per_token: 225e-9, output_cost_per_token: 225e-8, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/meta-llama/llama-3-70b-instruct:nitro": { max_tokens: 8192, input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/meta-llama/llama-3-70b-instruct": { max_tokens: 8192, input_cost_per_token: 59e-8, output_cost_per_token: 79e-8, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/openai/o1": { max_tokens: 1e5, max_input_tokens: 2e5, max_output_tokens: 1e5, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, cache_read_input_token_cost: 75e-7, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_prompt_caching: !0, supports_system_messages: !0, supports_response_schema: !0, supports_tool_choice: !0 },
  "openrouter/openai/o1-mini": { max_tokens: 65536, max_input_tokens: 128e3, max_output_tokens: 65536, input_cost_per_token: 3e-6, output_cost_per_token: 12e-6, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_tool_choice: !0 },
  "openrouter/openai/o1-mini-2024-09-12": { max_tokens: 65536, max_input_tokens: 128e3, max_output_tokens: 65536, input_cost_per_token: 3e-6, output_cost_per_token: 12e-6, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_tool_choice: !0 },
  "openrouter/openai/o1-preview": { max_tokens: 32768, max_input_tokens: 128e3, max_output_tokens: 32768, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_tool_choice: !0 },
  "openrouter/openai/o1-preview-2024-09-12": { max_tokens: 32768, max_input_tokens: 128e3, max_output_tokens: 32768, input_cost_per_token: 15e-6, output_cost_per_token: 6e-5, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_tool_choice: !0 },
  "openrouter/openai/o3-mini": { max_tokens: 65536, max_input_tokens: 128e3, max_output_tokens: 65536, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_reasoning: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_tool_choice: !0 },
  "openrouter/openai/o3-mini-high": { max_tokens: 65536, max_input_tokens: 128e3, max_output_tokens: 65536, input_cost_per_token: 11e-7, output_cost_per_token: 44e-7, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_reasoning: !0, supports_parallel_function_calling: !0, supports_vision: !1, supports_tool_choice: !0 },
  "openrouter/openai/gpt-4o": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 25e-7, output_cost_per_token: 1e-5, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_tool_choice: !0 },
  "openrouter/openai/gpt-4o-2024-05-13": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 5e-6, output_cost_per_token: 15e-6, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_vision: !0, supports_tool_choice: !0 },
  "openrouter/openai/gpt-4-vision-preview": { max_tokens: 13e4, input_cost_per_token: 1e-5, output_cost_per_token: 3e-5, input_cost_per_image: 0.01445, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_tool_choice: !0 },
  "openrouter/openai/gpt-3.5-turbo": { max_tokens: 4095, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/openai/gpt-3.5-turbo-16k": { max_tokens: 16383, input_cost_per_token: 3e-6, output_cost_per_token: 4e-6, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/openai/gpt-4": { max_tokens: 8192, input_cost_per_token: 3e-5, output_cost_per_token: 6e-5, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/anthropic/claude-instant-v1": { max_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 163e-8, output_cost_per_token: 551e-8, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/anthropic/claude-2": { max_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 1102e-8, output_cost_per_token: 3268e-8, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/anthropic/claude-3-opus": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, litellm_provider: "openrouter", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 395, supports_tool_choice: !0 },
  "openrouter/google/palm-2-chat-bison": { max_tokens: 25804, input_cost_per_token: 5e-7, output_cost_per_token: 5e-7, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/google/palm-2-codechat-bison": { max_tokens: 20070, input_cost_per_token: 5e-7, output_cost_per_token: 5e-7, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/meta-llama/llama-2-13b-chat": { max_tokens: 4096, input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/meta-llama/llama-2-70b-chat": { max_tokens: 4096, input_cost_per_token: 15e-7, output_cost_per_token: 15e-7, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/meta-llama/codellama-34b-instruct": { max_tokens: 8192, input_cost_per_token: 5e-7, output_cost_per_token: 5e-7, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/nousresearch/nous-hermes-llama2-13b": { max_tokens: 4096, input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/mancer/weaver": { max_tokens: 8e3, input_cost_per_token: 5625e-9, output_cost_per_token: 5625e-9, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/gryphe/mythomax-l2-13b": { max_tokens: 8192, input_cost_per_token: 1875e-9, output_cost_per_token: 1875e-9, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/jondurbin/airoboros-l2-70b-2.1": { max_tokens: 4096, input_cost_per_token: 13875e-9, output_cost_per_token: 13875e-9, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/undi95/remm-slerp-l2-13b": { max_tokens: 6144, input_cost_per_token: 1875e-9, output_cost_per_token: 1875e-9, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/pygmalionai/mythalion-13b": { max_tokens: 4096, input_cost_per_token: 1875e-9, output_cost_per_token: 1875e-9, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/mistralai/mistral-7b-instruct": { max_tokens: 8192, input_cost_per_token: 13e-8, output_cost_per_token: 13e-8, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/mistralai/mistral-7b-instruct:free": { max_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "openrouter/qwen/qwen-2.5-coder-32b-instruct": { max_tokens: 33792, max_input_tokens: 33792, max_output_tokens: 33792, input_cost_per_token: 18e-8, output_cost_per_token: 18e-8, litellm_provider: "openrouter", mode: "chat", supports_tool_choice: !0 },
  "j2-ultra": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 15e-6, output_cost_per_token: 15e-6, litellm_provider: "ai21", mode: "completion" },
  "jamba-1.5-mini@001": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-7, output_cost_per_token: 4e-7, litellm_provider: "ai21", mode: "chat", supports_tool_choice: !0 },
  "jamba-1.5-large@001": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, litellm_provider: "ai21", mode: "chat", supports_tool_choice: !0 },
  "jamba-1.5": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-7, output_cost_per_token: 4e-7, litellm_provider: "ai21", mode: "chat", supports_tool_choice: !0 },
  "jamba-1.5-mini": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-7, output_cost_per_token: 4e-7, litellm_provider: "ai21", mode: "chat", supports_tool_choice: !0 },
  "jamba-1.5-large": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, litellm_provider: "ai21", mode: "chat", supports_tool_choice: !0 },
  "jamba-large-1.6": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, litellm_provider: "ai21", mode: "chat", supports_tool_choice: !0 },
  "jamba-mini-1.6": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-7, output_cost_per_token: 4e-7, litellm_provider: "ai21", mode: "chat", supports_tool_choice: !0 },
  "j2-mid": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 1e-5, output_cost_per_token: 1e-5, litellm_provider: "ai21", mode: "completion" },
  "j2-light": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 3e-6, litellm_provider: "ai21", mode: "completion" },
  dolphin: st,
  chatdolphin: pt,
  "luminous-base": { max_tokens: 2048, input_cost_per_token: 3e-5, output_cost_per_token: 33e-6, litellm_provider: "aleph_alpha", mode: "completion" },
  "luminous-base-control": { max_tokens: 2048, input_cost_per_token: 375e-7, output_cost_per_token: 4125e-8, litellm_provider: "aleph_alpha", mode: "chat" },
  "luminous-extended": { max_tokens: 2048, input_cost_per_token: 45e-6, output_cost_per_token: 495e-7, litellm_provider: "aleph_alpha", mode: "completion" },
  "luminous-extended-control": { max_tokens: 2048, input_cost_per_token: 5625e-8, output_cost_per_token: 61875e-9, litellm_provider: "aleph_alpha", mode: "chat" },
  "luminous-supreme": { max_tokens: 2048, input_cost_per_token: 175e-6, output_cost_per_token: 1925e-7, litellm_provider: "aleph_alpha", mode: "completion" },
  "luminous-supreme-control": { max_tokens: 2048, input_cost_per_token: 21875e-8, output_cost_per_token: 240625e-9, litellm_provider: "aleph_alpha", mode: "chat" },
  "ai21.j2-mid-v1": { max_tokens: 8191, max_input_tokens: 8191, max_output_tokens: 8191, input_cost_per_token: 125e-7, output_cost_per_token: 125e-7, litellm_provider: "bedrock", mode: "chat" },
  "ai21.j2-ultra-v1": { max_tokens: 8191, max_input_tokens: 8191, max_output_tokens: 8191, input_cost_per_token: 188e-7, output_cost_per_token: 188e-7, litellm_provider: "bedrock", mode: "chat" },
  "ai21.jamba-instruct-v1:0": { max_tokens: 4096, max_input_tokens: 7e4, max_output_tokens: 4096, input_cost_per_token: 5e-7, output_cost_per_token: 7e-7, litellm_provider: "bedrock", mode: "chat", supports_system_messages: !0 },
  "ai21.jamba-1-5-large-v1:0": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, litellm_provider: "bedrock", mode: "chat" },
  "ai21.jamba-1-5-mini-v1:0": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 256e3, input_cost_per_token: 2e-7, output_cost_per_token: 4e-7, litellm_provider: "bedrock", mode: "chat" },
  "amazon.rerank-v1:0": { max_tokens: 32e3, max_input_tokens: 32e3, max_output_tokens: 32e3, max_query_tokens: 32e3, max_document_chunks_per_query: 100, max_tokens_per_document_chunk: 512, input_cost_per_token: 0, input_cost_per_query: 1e-3, output_cost_per_token: 0, litellm_provider: "bedrock", mode: "rerank" },
  "amazon.titan-text-lite-v1": { max_tokens: 4e3, max_input_tokens: 42e3, max_output_tokens: 4e3, input_cost_per_token: 3e-7, output_cost_per_token: 4e-7, litellm_provider: "bedrock", mode: "chat" },
  "amazon.titan-text-express-v1": { max_tokens: 8e3, max_input_tokens: 42e3, max_output_tokens: 8e3, input_cost_per_token: 13e-7, output_cost_per_token: 17e-7, litellm_provider: "bedrock", mode: "chat" },
  "amazon.titan-text-premier-v1:0": { max_tokens: 32e3, max_input_tokens: 42e3, max_output_tokens: 32e3, input_cost_per_token: 5e-7, output_cost_per_token: 15e-7, litellm_provider: "bedrock", mode: "chat" },
  "amazon.titan-embed-text-v1": { max_tokens: 8192, max_input_tokens: 8192, output_vector_size: 1536, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "bedrock", mode: "embedding" },
  "amazon.titan-embed-text-v2:0": { max_tokens: 8192, max_input_tokens: 8192, output_vector_size: 1024, input_cost_per_token: 2e-7, output_cost_per_token: 0, litellm_provider: "bedrock", mode: "embedding" },
  "amazon.titan-embed-image-v1": { max_tokens: 128, max_input_tokens: 128, output_vector_size: 1024, input_cost_per_token: 8e-7, input_cost_per_image: 6e-5, output_cost_per_token: 0, litellm_provider: "bedrock", supports_image_input: !0, supports_embedding_image_input: !0, mode: "embedding", source: "https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/providers?model=amazon.titan-image-generator-v1", metadata: { notes: "'supports_image_input' is a deprecated field. Use 'supports_embedding_image_input' instead." } },
  "mistral.mistral-7b-instruct-v0:2": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 15e-8, output_cost_per_token: 2e-7, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "mistral.mixtral-8x7b-instruct-v0:1": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 45e-8, output_cost_per_token: 7e-7, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "mistral.mistral-large-2402-v1:0": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "mistral.mistral-large-2407-v1:0": { max_tokens: 8191, max_input_tokens: 128e3, max_output_tokens: 8191, input_cost_per_token: 3e-6, output_cost_per_token: 9e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "mistral.mistral-small-2402-v1:0": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 1e-6, output_cost_per_token: 3e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 45e-8, output_cost_per_token: 7e-7, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 45e-8, output_cost_per_token: 7e-7, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 59e-8, output_cost_per_token: 91e-8, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 15e-8, output_cost_per_token: 2e-7, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 15e-8, output_cost_per_token: 2e-7, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 2e-7, output_cost_per_token: 26e-8, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-east-1/mistral.mistral-large-2402-v1:0": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "bedrock/us-west-2/mistral.mistral-large-2402-v1:0": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "bedrock/eu-west-3/mistral.mistral-large-2402-v1:0": { max_tokens: 8191, max_input_tokens: 32e3, max_output_tokens: 8191, input_cost_per_token: 104e-7, output_cost_per_token: 312e-7, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0 },
  "amazon.nova-micro-v1:0": { max_tokens: 1e4, max_input_tokens: 3e5, max_output_tokens: 1e4, input_cost_per_token: 35e-9, output_cost_per_token: 14e-8, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_prompt_caching: !0, supports_response_schema: !0 },
  "us.amazon.nova-micro-v1:0": { max_tokens: 1e4, max_input_tokens: 3e5, max_output_tokens: 1e4, input_cost_per_token: 35e-9, output_cost_per_token: 14e-8, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_prompt_caching: !0, supports_response_schema: !0 },
  "eu.amazon.nova-micro-v1:0": { max_tokens: 1e4, max_input_tokens: 3e5, max_output_tokens: 1e4, input_cost_per_token: 46e-9, output_cost_per_token: 184e-9, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_prompt_caching: !0, supports_response_schema: !0 },
  "amazon.nova-lite-v1:0": { max_tokens: 1e4, max_input_tokens: 128e3, max_output_tokens: 1e4, input_cost_per_token: 6e-8, output_cost_per_token: 24e-8, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0 },
  "us.amazon.nova-lite-v1:0": { max_tokens: 1e4, max_input_tokens: 128e3, max_output_tokens: 1e4, input_cost_per_token: 6e-8, output_cost_per_token: 24e-8, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0 },
  "eu.amazon.nova-lite-v1:0": { max_tokens: 1e4, max_input_tokens: 128e3, max_output_tokens: 1e4, input_cost_per_token: 78e-9, output_cost_per_token: 312e-9, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0 },
  "amazon.nova-pro-v1:0": { max_tokens: 1e4, max_input_tokens: 3e5, max_output_tokens: 1e4, input_cost_per_token: 8e-7, output_cost_per_token: 32e-7, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0 },
  "us.amazon.nova-pro-v1:0": { max_tokens: 1e4, max_input_tokens: 3e5, max_output_tokens: 1e4, input_cost_per_token: 8e-7, output_cost_per_token: 32e-7, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0 },
  "1024-x-1024/50-steps/bedrock/amazon.nova-canvas-v1:0": { max_input_tokens: 2600, output_cost_per_image: 0.06, litellm_provider: "bedrock", mode: "image_generation" },
  "eu.amazon.nova-pro-v1:0": { max_tokens: 1e4, max_input_tokens: 3e5, max_output_tokens: 1e4, input_cost_per_token: 105e-8, output_cost_per_token: 42e-7, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, source: "https://aws.amazon.com/bedrock/pricing/" },
  "us.amazon.nova-premier-v1:0": { max_tokens: 1e4, max_input_tokens: 1e6, max_output_tokens: 1e4, input_cost_per_token: 25e-7, output_cost_per_token: 125e-7, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_prompt_caching: !1, supports_response_schema: !0 },
  "anthropic.claude-3-sonnet-20240229-v1:0": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_pdf_input: !0, supports_tool_choice: !0 },
  "bedrock/invoke/anthropic.claude-3-5-sonnet-20240620-v1:0": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_tool_choice: !0, metadata: { notes: "Anthropic via Invoke route does not currently support pdf input." } },
  "anthropic.claude-3-5-sonnet-20240620-v1:0": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_pdf_input: !0, supports_tool_choice: !0 },
  "anthropic.claude-opus-4-20250514-v1:0": { max_tokens: 32e3, max_input_tokens: 2e5, max_output_tokens: 32e3, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 1875e-8, cache_read_input_token_cost: 15e-7, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },
  "anthropic.claude-sonnet-4-20250514-v1:0": { max_tokens: 64e3, max_input_tokens: 2e5, max_output_tokens: 64e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },
  "anthropic.claude-3-7-sonnet-20250219-v1:0": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_pdf_input: !0, supports_reasoning: !0, supports_tool_choice: !0 },
  "anthropic.claude-3-5-sonnet-20241022-v2:0": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0 },
  "anthropic.claude-3-haiku-20240307-v1:0": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 25e-8, output_cost_per_token: 125e-8, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_pdf_input: !0, supports_tool_choice: !0 },
  "anthropic.claude-3-5-haiku-20241022-v1:0": { max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 8e-7, output_cost_per_token: 4e-6, cache_creation_input_token_cost: 1e-6, cache_read_input_token_cost: 8e-8, litellm_provider: "bedrock", mode: "chat", supports_assistant_prefill: !0, supports_pdf_input: !0, supports_function_calling: !0, supports_response_schema: !0, supports_prompt_caching: !0, supports_tool_choice: !0 },
  "anthropic.claude-3-opus-20240229-v1:0": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_tool_choice: !0 },
  "us.anthropic.claude-3-sonnet-20240229-v1:0": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_pdf_input: !0, supports_tool_choice: !0 },
  "us.anthropic.claude-3-5-sonnet-20240620-v1:0": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_pdf_input: !0, supports_tool_choice: !0 },
  "us.anthropic.claude-3-5-sonnet-20241022-v2:0": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0 },
  "us.anthropic.claude-3-7-sonnet-20250219-v1:0": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_pdf_input: !0, supports_tool_choice: !0, supports_reasoning: !0 },
  "us.anthropic.claude-opus-4-20250514-v1:0": { max_tokens: 32e3, max_input_tokens: 2e5, max_output_tokens: 32e3, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 1875e-8, cache_read_input_token_cost: 15e-7, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },
  "us.anthropic.claude-sonnet-4-20250514-v1:0": { max_tokens: 64e3, max_input_tokens: 2e5, max_output_tokens: 64e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },
  "us.anthropic.claude-3-haiku-20240307-v1:0": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 25e-8, output_cost_per_token: 125e-8, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_pdf_input: !0, supports_tool_choice: !0 },
  "us.anthropic.claude-3-5-haiku-20241022-v1:0": { max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 8e-7, output_cost_per_token: 4e-6, cache_creation_input_token_cost: 1e-6, cache_read_input_token_cost: 8e-8, litellm_provider: "bedrock", mode: "chat", supports_assistant_prefill: !0, supports_pdf_input: !0, supports_function_calling: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0 },
  "us.anthropic.claude-3-opus-20240229-v1:0": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_tool_choice: !0 },
  "eu.anthropic.claude-3-sonnet-20240229-v1:0": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_pdf_input: !0, supports_tool_choice: !0 },
  "eu.anthropic.claude-3-5-sonnet-20240620-v1:0": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_pdf_input: !0, supports_tool_choice: !0 },
  "eu.anthropic.claude-3-5-sonnet-20241022-v2:0": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_pdf_input: !0, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0 },
  "eu.anthropic.claude-3-7-sonnet-20250219-v1:0": { supports_computer_use: !0, max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_vision: !0, supports_assistant_prefill: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_pdf_input: !0, supports_tool_choice: !0, supports_reasoning: !0 },
  "eu.anthropic.claude-3-haiku-20240307-v1:0": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 25e-8, output_cost_per_token: 125e-8, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_pdf_input: !0, supports_tool_choice: !0 },
  "eu.anthropic.claude-opus-4-20250514-v1:0": { max_tokens: 32e3, max_input_tokens: 2e5, max_output_tokens: 32e3, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 1875e-8, cache_read_input_token_cost: 15e-7, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },
  "eu.anthropic.claude-sonnet-4-20250514-v1:0": { max_tokens: 64e3, max_input_tokens: 2e5, max_output_tokens: 64e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, search_context_cost_per_query: { search_context_size_low: 0.01, search_context_size_medium: 0.01, search_context_size_high: 0.01 }, cache_creation_input_token_cost: 375e-8, cache_read_input_token_cost: 3e-7, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_vision: !0, tool_use_system_prompt_tokens: 159, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0, supports_reasoning: !0, supports_computer_use: !0 },
  "eu.anthropic.claude-3-5-haiku-20241022-v1:0": { max_tokens: 8192, max_input_tokens: 2e5, max_output_tokens: 8192, input_cost_per_token: 25e-8, output_cost_per_token: 125e-8, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_assistant_prefill: !0, supports_pdf_input: !0, supports_prompt_caching: !0, supports_response_schema: !0, supports_tool_choice: !0 },
  "eu.anthropic.claude-3-opus-20240229-v1:0": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 15e-6, output_cost_per_token: 75e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_vision: !0, supports_tool_choice: !0 },
  "anthropic.claude-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/us-east-1/anthropic.claude-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-west-2/anthropic.claude-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/ap-northeast-1/anthropic.claude-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0455, output_cost_per_second: 0.0455, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.02527, output_cost_per_second: 0.02527, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/eu-central-1/anthropic.claude-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0415, output_cost_per_second: 0.0415, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.02305, output_cost_per_second: 0.02305, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/us-east-1/1-month-commitment/anthropic.claude-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0175, output_cost_per_second: 0.0175, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/us-east-1/6-month-commitment/anthropic.claude-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 972e-5, output_cost_per_second: 972e-5, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/us-west-2/1-month-commitment/anthropic.claude-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0175, output_cost_per_second: 0.0175, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/us-west-2/6-month-commitment/anthropic.claude-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 972e-5, output_cost_per_second: 972e-5, litellm_provider: "bedrock", mode: "chat" },
  "anthropic.claude-v2": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-east-1/anthropic.claude-v2": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-west-2/anthropic.claude-v2": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/ap-northeast-1/anthropic.claude-v2": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0455, output_cost_per_second: 0.0455, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.02527, output_cost_per_second: 0.02527, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/eu-central-1/anthropic.claude-v2": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0415, output_cost_per_second: 0.0415, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.02305, output_cost_per_second: 0.02305, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-east-1/1-month-commitment/anthropic.claude-v2": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0175, output_cost_per_second: 0.0175, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-east-1/6-month-commitment/anthropic.claude-v2": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 972e-5, output_cost_per_second: 972e-5, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-west-2/1-month-commitment/anthropic.claude-v2": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0175, output_cost_per_second: 0.0175, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-west-2/6-month-commitment/anthropic.claude-v2": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 972e-5, output_cost_per_second: 972e-5, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "anthropic.claude-v2:1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-east-1/anthropic.claude-v2:1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-west-2/anthropic.claude-v2:1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/ap-northeast-1/anthropic.claude-v2:1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0455, output_cost_per_second: 0.0455, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.02527, output_cost_per_second: 0.02527, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/eu-central-1/anthropic.claude-v2:1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-6, output_cost_per_token: 24e-6, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0415, output_cost_per_second: 0.0415, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.02305, output_cost_per_second: 0.02305, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0175, output_cost_per_second: 0.0175, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 972e-5, output_cost_per_second: 972e-5, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.0175, output_cost_per_second: 0.0175, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 972e-5, output_cost_per_second: 972e-5, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "anthropic.claude-instant-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-7, output_cost_per_token: 24e-7, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-east-1/anthropic.claude-instant-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-7, output_cost_per_token: 24e-7, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.011, output_cost_per_second: 0.011, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 611e-5, output_cost_per_second: 611e-5, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.011, output_cost_per_second: 0.011, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 611e-5, output_cost_per_second: 611e-5, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/us-west-2/anthropic.claude-instant-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 8e-7, output_cost_per_token: 24e-7, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/ap-northeast-1/anthropic.claude-instant-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 223e-8, output_cost_per_token: 755e-8, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.01475, output_cost_per_second: 0.01475, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 8194e-6, output_cost_per_second: 8194e-6, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/eu-central-1/anthropic.claude-instant-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_token: 248e-8, output_cost_per_token: 838e-8, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 0.01635, output_cost_per_second: 0.01635, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1": { max_tokens: 8191, max_input_tokens: 1e5, max_output_tokens: 8191, input_cost_per_second: 9083e-6, output_cost_per_second: 9083e-6, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "cohere.rerank-v3-5:0": { max_tokens: 32e3, max_input_tokens: 32e3, max_output_tokens: 32e3, max_query_tokens: 32e3, max_document_chunks_per_query: 100, max_tokens_per_document_chunk: 512, input_cost_per_token: 0, input_cost_per_query: 2e-3, output_cost_per_token: 0, litellm_provider: "bedrock", mode: "rerank" },
  "cohere.command-text-v14": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 15e-7, output_cost_per_token: 2e-6, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/*/1-month-commitment/cohere.command-text-v14": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_second: 0.011, output_cost_per_second: 0.011, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/*/6-month-commitment/cohere.command-text-v14": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_second: 66027e-7, output_cost_per_second: 66027e-7, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "cohere.command-light-text-v14": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 3e-7, output_cost_per_token: 6e-7, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/*/1-month-commitment/cohere.command-light-text-v14": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_second: 1902e-6, output_cost_per_second: 1902e-6, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "bedrock/*/6-month-commitment/cohere.command-light-text-v14": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_second: 11416e-7, output_cost_per_second: 11416e-7, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "cohere.command-r-plus-v1:0": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "cohere.command-r-v1:0": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 5e-7, output_cost_per_token: 15e-7, litellm_provider: "bedrock", mode: "chat", supports_tool_choice: !0 },
  "cohere.embed-english-v3": { max_tokens: 512, max_input_tokens: 512, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "bedrock", mode: "embedding", supports_embedding_image_input: !0 },
  "cohere.embed-multilingual-v3": { max_tokens: 512, max_input_tokens: 512, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "bedrock", mode: "embedding", supports_embedding_image_input: !0 },
  "us.deepseek.r1-v1:0": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 135e-8, output_cost_per_token: 54e-7, litellm_provider: "bedrock_converse", mode: "chat", supports_reasoning: !0, supports_function_calling: !1, supports_tool_choice: !1 },
  "meta.llama3-3-70b-instruct-v1:0": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 72e-8, output_cost_per_token: 72e-8, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1 },
  "meta.llama2-13b-chat-v1": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 75e-8, output_cost_per_token: 1e-6, litellm_provider: "bedrock", mode: "chat" },
  "meta.llama2-70b-chat-v1": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 195e-8, output_cost_per_token: 256e-8, litellm_provider: "bedrock", mode: "chat" },
  "meta.llama3-8b-instruct-v1:0": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 3e-7, output_cost_per_token: 6e-7, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/us-east-1/meta.llama3-8b-instruct-v1:0": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 3e-7, output_cost_per_token: 6e-7, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/us-west-1/meta.llama3-8b-instruct-v1:0": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 3e-7, output_cost_per_token: 6e-7, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 36e-8, output_cost_per_token: 72e-8, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 35e-8, output_cost_per_token: 69e-8, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 32e-8, output_cost_per_token: 65e-8, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 39e-8, output_cost_per_token: 78e-8, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 5e-7, output_cost_per_token: 101e-8, litellm_provider: "bedrock", mode: "chat" },
  "meta.llama3-70b-instruct-v1:0": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 265e-8, output_cost_per_token: 35e-7, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/us-east-1/meta.llama3-70b-instruct-v1:0": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 265e-8, output_cost_per_token: 35e-7, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/us-west-1/meta.llama3-70b-instruct-v1:0": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 265e-8, output_cost_per_token: 35e-7, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 318e-8, output_cost_per_token: 42e-7, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 305e-8, output_cost_per_token: 403e-8, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 286e-8, output_cost_per_token: 378e-8, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 345e-8, output_cost_per_token: 455e-8, litellm_provider: "bedrock", mode: "chat" },
  "bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 445e-8, output_cost_per_token: 588e-8, litellm_provider: "bedrock", mode: "chat" },
  "meta.llama3-1-8b-instruct-v1:0": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 22e-8, output_cost_per_token: 22e-8, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1 },
  "us.meta.llama3-1-8b-instruct-v1:0": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 22e-8, output_cost_per_token: 22e-8, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1 },
  "meta.llama3-1-70b-instruct-v1:0": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 99e-8, output_cost_per_token: 99e-8, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1 },
  "us.meta.llama3-1-70b-instruct-v1:0": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 2048, input_cost_per_token: 99e-8, output_cost_per_token: 99e-8, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1 },
  "meta.llama3-1-405b-instruct-v1:0": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 532e-8, output_cost_per_token: 16e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1 },
  "us.meta.llama3-1-405b-instruct-v1:0": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 532e-8, output_cost_per_token: 16e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1 },
  "meta.llama3-2-1b-instruct-v1:0": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-7, output_cost_per_token: 1e-7, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1 },
  "us.meta.llama3-2-1b-instruct-v1:0": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 1e-7, output_cost_per_token: 1e-7, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1 },
  "eu.meta.llama3-2-1b-instruct-v1:0": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 13e-8, output_cost_per_token: 13e-8, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1 },
  "meta.llama3-2-3b-instruct-v1:0": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1 },
  "us.meta.llama3-2-3b-instruct-v1:0": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1 },
  "eu.meta.llama3-2-3b-instruct-v1:0": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 19e-8, output_cost_per_token: 19e-8, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1 },
  "meta.llama3-2-11b-instruct-v1:0": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 35e-8, output_cost_per_token: 35e-8, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1, supports_vision: !0 },
  "us.meta.llama3-2-11b-instruct-v1:0": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 35e-8, output_cost_per_token: 35e-8, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1, supports_vision: !0 },
  "meta.llama3-2-90b-instruct-v1:0": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 2e-6, output_cost_per_token: 2e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1, supports_vision: !0 },
  "us.meta.llama3-2-90b-instruct-v1:0": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 2e-6, output_cost_per_token: 2e-6, litellm_provider: "bedrock", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1, supports_vision: !0 },
  "us.meta.llama3-3-70b-instruct-v1:0": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 72e-8, output_cost_per_token: 72e-8, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1 },
  "meta.llama4-maverick-17b-instruct-v1:0": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 24e-8, input_cost_per_token_batches: 12e-8, output_cost_per_token: 97e-8, output_cost_per_token_batches: 485e-9, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1, supported_modalities: ["text", "image"], supported_output_modalities: ["text", "code"] },
  "us.meta.llama4-maverick-17b-instruct-v1:0": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 24e-8, input_cost_per_token_batches: 12e-8, output_cost_per_token: 97e-8, output_cost_per_token_batches: 485e-9, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1, supported_modalities: ["text", "image"], supported_output_modalities: ["text", "code"] },
  "meta.llama4-scout-17b-instruct-v1:0": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 17e-8, input_cost_per_token_batches: 85e-9, output_cost_per_token: 66e-8, output_cost_per_token_batches: 33e-8, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1, supported_modalities: ["text", "image"], supported_output_modalities: ["text", "code"] },
  "us.meta.llama4-scout-17b-instruct-v1:0": { max_tokens: 4096, max_input_tokens: 128e3, max_output_tokens: 4096, input_cost_per_token: 17e-8, input_cost_per_token_batches: 85e-9, output_cost_per_token: 66e-8, output_cost_per_token_batches: 33e-8, litellm_provider: "bedrock_converse", mode: "chat", supports_function_calling: !0, supports_tool_choice: !1, supported_modalities: ["text", "image"], supported_output_modalities: ["text", "code"] },
  "512-x-512/50-steps/stability.stable-diffusion-xl-v0": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.018, litellm_provider: "bedrock", mode: "image_generation" },
  "512-x-512/max-steps/stability.stable-diffusion-xl-v0": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.036, litellm_provider: "bedrock", mode: "image_generation" },
  "max-x-max/50-steps/stability.stable-diffusion-xl-v0": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.036, litellm_provider: "bedrock", mode: "image_generation" },
  "max-x-max/max-steps/stability.stable-diffusion-xl-v0": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.072, litellm_provider: "bedrock", mode: "image_generation" },
  "1024-x-1024/50-steps/stability.stable-diffusion-xl-v1": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.04, litellm_provider: "bedrock", mode: "image_generation" },
  "1024-x-1024/max-steps/stability.stable-diffusion-xl-v1": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.08, litellm_provider: "bedrock", mode: "image_generation" },
  "stability.sd3-large-v1:0": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.08, litellm_provider: "bedrock", mode: "image_generation" },
  "stability.sd3-5-large-v1:0": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.08, litellm_provider: "bedrock", mode: "image_generation" },
  "stability.stable-image-core-v1:0": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.04, litellm_provider: "bedrock", mode: "image_generation" },
  "stability.stable-image-core-v1:1": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.04, litellm_provider: "bedrock", mode: "image_generation" },
  "stability.stable-image-ultra-v1:0": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.14, litellm_provider: "bedrock", mode: "image_generation" },
  "stability.stable-image-ultra-v1:1": { max_tokens: 77, max_input_tokens: 77, output_cost_per_image: 0.14, litellm_provider: "bedrock", mode: "image_generation" },
  "sagemaker/meta-textgeneration-llama-2-7b": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "sagemaker", mode: "completion" },
  "sagemaker/meta-textgeneration-llama-2-7b-f": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "sagemaker", mode: "chat" },
  "sagemaker/meta-textgeneration-llama-2-13b": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "sagemaker", mode: "completion" },
  "sagemaker/meta-textgeneration-llama-2-13b-f": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "sagemaker", mode: "chat" },
  "sagemaker/meta-textgeneration-llama-2-70b": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "sagemaker", mode: "completion" },
  "sagemaker/meta-textgeneration-llama-2-70b-b-f": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "sagemaker", mode: "chat" },
  "together-ai-up-to-4b": { input_cost_per_token: 1e-7, output_cost_per_token: 1e-7, litellm_provider: "together_ai", mode: "chat" },
  "together-ai-4.1b-8b": { input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: "together_ai", mode: "chat" },
  "together-ai-8.1b-21b": { max_tokens: 1e3, input_cost_per_token: 3e-7, output_cost_per_token: 3e-7, litellm_provider: "together_ai", mode: "chat" },
  "together-ai-21.1b-41b": { input_cost_per_token: 8e-7, output_cost_per_token: 8e-7, litellm_provider: "together_ai", mode: "chat" },
  "together-ai-41.1b-80b": { input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: "together_ai", mode: "chat" },
  "together-ai-81.1b-110b": { input_cost_per_token: 18e-7, output_cost_per_token: 18e-7, litellm_provider: "together_ai", mode: "chat" },
  "together-ai-embedding-up-to-150m": { input_cost_per_token: 8e-9, output_cost_per_token: 0, litellm_provider: "together_ai", mode: "embedding" },
  "together-ai-embedding-151m-to-350m": { input_cost_per_token: 16e-9, output_cost_per_token: 0, litellm_provider: "together_ai", mode: "embedding" },
  "together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": { input_cost_per_token: 18e-8, output_cost_per_token: 18e-8, litellm_provider: "together_ai", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, mode: "chat", supports_tool_choice: !0 },
  "together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": { input_cost_per_token: 88e-8, output_cost_per_token: 88e-8, litellm_provider: "together_ai", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, mode: "chat", supports_tool_choice: !0 },
  "together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": { input_cost_per_token: 35e-7, output_cost_per_token: 35e-7, litellm_provider: "together_ai", supports_function_calling: !0, supports_parallel_function_calling: !0, mode: "chat", supports_tool_choice: !0 },
  "together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo": { input_cost_per_token: 88e-8, output_cost_per_token: 88e-8, litellm_provider: "together_ai", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, mode: "chat", supports_tool_choice: !0 },
  "together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free": { input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "together_ai", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, mode: "chat", supports_tool_choice: !0 },
  "together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1": { input_cost_per_token: 6e-7, output_cost_per_token: 6e-7, litellm_provider: "together_ai", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, mode: "chat", supports_tool_choice: !0 },
  "together_ai/mistralai/Mistral-7B-Instruct-v0.1": { litellm_provider: "together_ai", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_response_schema: !0, mode: "chat", supports_tool_choice: !0 },
  "together_ai/togethercomputer/CodeLlama-34b-Instruct": { litellm_provider: "together_ai", supports_function_calling: !0, supports_parallel_function_calling: !0, mode: "chat", supports_tool_choice: !0 },
  "together_ai/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": { litellm_provider: "together_ai", supports_function_calling: !0, supports_parallel_function_calling: !0, mode: "chat", supports_tool_choice: !0 },
  "together_ai/meta-llama/Llama-4-Scout-17B-16E-Instruct": { litellm_provider: "together_ai", supports_function_calling: !0, supports_parallel_function_calling: !0, mode: "chat", supports_tool_choice: !0 },
  "together_ai/meta-llama/Llama-3.2-3B-Instruct-Turbo": { litellm_provider: "together_ai", supports_function_calling: !0, supports_parallel_function_calling: !0, mode: "chat", supports_tool_choice: !0 },
  "together_ai/Qwen/Qwen2.5-7B-Instruct-Turbo": { litellm_provider: "together_ai", supports_function_calling: !0, supports_parallel_function_calling: !0, mode: "chat", supports_tool_choice: !0 },
  "together_ai/Qwen/Qwen2.5-72B-Instruct-Turbo": { litellm_provider: "together_ai", supports_function_calling: !0, supports_parallel_function_calling: !0, mode: "chat", supports_tool_choice: !0 },
  "together_ai/deepseek-ai/DeepSeek-V3": { litellm_provider: "together_ai", supports_function_calling: !0, supports_parallel_function_calling: !0, mode: "chat", supports_tool_choice: !0 },
  "together_ai/mistralai/Mistral-Small-24B-Instruct-2501": { litellm_provider: "together_ai", supports_function_calling: !0, supports_parallel_function_calling: !0, mode: "chat", supports_tool_choice: !0 },
  "ollama/codegemma": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "completion" },
  "ollama/codegeex4": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "chat", supports_function_calling: !1 },
  "ollama/deepseek-coder-v2-instruct": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "chat", supports_function_calling: !0 },
  "ollama/deepseek-coder-v2-base": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "completion", supports_function_calling: !0 },
  "ollama/deepseek-coder-v2-lite-instruct": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "chat", supports_function_calling: !0 },
  "ollama/deepseek-coder-v2-lite-base": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "completion", supports_function_calling: !0 },
  "ollama/internlm2_5-20b-chat": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "chat", supports_function_calling: !0 },
  "ollama/llama2": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "chat" },
  "ollama/llama2:7b": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "chat" },
  "ollama/llama2:13b": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "chat" },
  "ollama/llama2:70b": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "chat" },
  "ollama/llama2-uncensored": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "completion" },
  "ollama/llama3": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "chat" },
  "ollama/llama3:8b": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "chat" },
  "ollama/llama3:70b": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "chat" },
  "ollama/llama3.1": { max_tokens: 32768, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "chat", supports_function_calling: !0 },
  "ollama/mistral-large-instruct-2407": { max_tokens: 65536, max_input_tokens: 65536, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "chat", supports_function_calling: !0 },
  "ollama/mistral": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "completion", supports_function_calling: !0 },
  "ollama/mistral-7B-Instruct-v0.1": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "chat", supports_function_calling: !0 },
  "ollama/mistral-7B-Instruct-v0.2": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "chat", supports_function_calling: !0 },
  "ollama/mixtral-8x7B-Instruct-v0.1": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "chat", supports_function_calling: !0 },
  "ollama/mixtral-8x22B-Instruct-v0.1": { max_tokens: 65536, max_input_tokens: 65536, max_output_tokens: 65536, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "chat", supports_function_calling: !0 },
  "ollama/codellama": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "completion" },
  "ollama/orca-mini": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "completion" },
  "ollama/vicuna": { max_tokens: 2048, max_input_tokens: 2048, max_output_tokens: 2048, input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "ollama", mode: "completion" },
  "deepinfra/lizpreciatior/lzlv_70b_fp16_hf": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 7e-7, output_cost_per_token: 9e-7, litellm_provider: "deepinfra", mode: "chat", supports_tool_choice: !0 },
  "deepinfra/Gryphe/MythoMax-L2-13b": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 22e-8, output_cost_per_token: 22e-8, litellm_provider: "deepinfra", mode: "chat", supports_tool_choice: !0 },
  "deepinfra/mistralai/Mistral-7B-Instruct-v0.1": { max_tokens: 8191, max_input_tokens: 32768, max_output_tokens: 8191, input_cost_per_token: 13e-8, output_cost_per_token: 13e-8, litellm_provider: "deepinfra", mode: "chat", supports_tool_choice: !0 },
  "deepinfra/meta-llama/Llama-2-70b-chat-hf": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 7e-7, output_cost_per_token: 9e-7, litellm_provider: "deepinfra", mode: "chat", supports_tool_choice: !0 },
  "deepinfra/cognitivecomputations/dolphin-2.6-mixtral-8x7b": { max_tokens: 8191, max_input_tokens: 32768, max_output_tokens: 8191, input_cost_per_token: 27e-8, output_cost_per_token: 27e-8, litellm_provider: "deepinfra", mode: "chat", supports_tool_choice: !0 },
  "deepinfra/codellama/CodeLlama-34b-Instruct-hf": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 6e-7, output_cost_per_token: 6e-7, litellm_provider: "deepinfra", mode: "chat", supports_tool_choice: !0 },
  "deepinfra/deepinfra/mixtral": { max_tokens: 4096, max_input_tokens: 32e3, max_output_tokens: 4096, input_cost_per_token: 27e-8, output_cost_per_token: 27e-8, litellm_provider: "deepinfra", mode: "completion" },
  "deepinfra/Phind/Phind-CodeLlama-34B-v2": { max_tokens: 4096, max_input_tokens: 16384, max_output_tokens: 4096, input_cost_per_token: 6e-7, output_cost_per_token: 6e-7, litellm_provider: "deepinfra", mode: "chat", supports_tool_choice: !0 },
  "deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1": { max_tokens: 8191, max_input_tokens: 32768, max_output_tokens: 8191, input_cost_per_token: 27e-8, output_cost_per_token: 27e-8, litellm_provider: "deepinfra", mode: "chat", supports_tool_choice: !0 },
  "deepinfra/deepinfra/airoboros-70b": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 7e-7, output_cost_per_token: 9e-7, litellm_provider: "deepinfra", mode: "chat", supports_tool_choice: !0 },
  "deepinfra/01-ai/Yi-34B-Chat": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 6e-7, output_cost_per_token: 6e-7, litellm_provider: "deepinfra", mode: "chat", supports_tool_choice: !0 },
  "deepinfra/01-ai/Yi-6B-200K": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 13e-8, output_cost_per_token: 13e-8, litellm_provider: "deepinfra", mode: "completion" },
  "deepinfra/jondurbin/airoboros-l2-70b-gpt4-1.4.1": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 7e-7, output_cost_per_token: 9e-7, litellm_provider: "deepinfra", mode: "chat", supports_tool_choice: !0 },
  "deepinfra/meta-llama/Llama-2-13b-chat-hf": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 22e-8, output_cost_per_token: 22e-8, litellm_provider: "deepinfra", mode: "chat", supports_tool_choice: !0 },
  "deepinfra/amazon/MistralLite": { max_tokens: 8191, max_input_tokens: 32768, max_output_tokens: 8191, input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: "deepinfra", mode: "chat", supports_tool_choice: !0 },
  "deepinfra/meta-llama/Llama-2-7b-chat-hf": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 13e-8, output_cost_per_token: 13e-8, litellm_provider: "deepinfra", mode: "chat", supports_tool_choice: !0 },
  "deepinfra/meta-llama/Meta-Llama-3-8B-Instruct": { max_tokens: 8191, max_input_tokens: 8191, max_output_tokens: 4096, input_cost_per_token: 8e-8, output_cost_per_token: 8e-8, litellm_provider: "deepinfra", mode: "chat", supports_tool_choice: !0 },
  "deepinfra/meta-llama/Meta-Llama-3-70B-Instruct": { max_tokens: 8191, max_input_tokens: 8191, max_output_tokens: 4096, input_cost_per_token: 59e-8, output_cost_per_token: 79e-8, litellm_provider: "deepinfra", mode: "chat", supports_tool_choice: !0 },
  "deepinfra/meta-llama/Meta-Llama-3.1-405B-Instruct": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: "deepinfra", mode: "chat", supports_function_calling: !0, supports_parallel_function_calling: !0, supports_tool_choice: !0 },
  "deepinfra/01-ai/Yi-34B-200K": { max_tokens: 4096, max_input_tokens: 2e5, max_output_tokens: 4096, input_cost_per_token: 6e-7, output_cost_per_token: 6e-7, litellm_provider: "deepinfra", mode: "completion" },
  "deepinfra/openchat/openchat_3.5": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 13e-8, output_cost_per_token: 13e-8, litellm_provider: "deepinfra", mode: "chat", supports_tool_choice: !0 },
  "perplexity/codellama-34b-instruct": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 35e-8, output_cost_per_token: 14e-7, litellm_provider: "perplexity", mode: "chat" },
  "perplexity/codellama-70b-instruct": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 7e-7, output_cost_per_token: 28e-7, litellm_provider: "perplexity", mode: "chat" },
  "perplexity/llama-3.1-70b-instruct": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 1e-6, output_cost_per_token: 1e-6, litellm_provider: "perplexity", mode: "chat" },
  "perplexity/llama-3.1-8b-instruct": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: "perplexity", mode: "chat" },
  "perplexity/llama-3.1-sonar-huge-128k-online": { max_tokens: 127072, max_input_tokens: 127072, max_output_tokens: 127072, input_cost_per_token: 5e-6, output_cost_per_token: 5e-6, litellm_provider: "perplexity", mode: "chat", deprecation_date: "2025-02-22" },
  "perplexity/llama-3.1-sonar-large-128k-online": { max_tokens: 127072, max_input_tokens: 127072, max_output_tokens: 127072, input_cost_per_token: 1e-6, output_cost_per_token: 1e-6, litellm_provider: "perplexity", mode: "chat", deprecation_date: "2025-02-22" },
  "perplexity/llama-3.1-sonar-large-128k-chat": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 1e-6, output_cost_per_token: 1e-6, litellm_provider: "perplexity", mode: "chat", deprecation_date: "2025-02-22" },
  "perplexity/llama-3.1-sonar-small-128k-chat": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: "perplexity", mode: "chat", deprecation_date: "2025-02-22" },
  "perplexity/llama-3.1-sonar-small-128k-online": { max_tokens: 127072, max_input_tokens: 127072, max_output_tokens: 127072, input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: "perplexity", mode: "chat", deprecation_date: "2025-02-22" },
  "perplexity/pplx-7b-chat": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 7e-8, output_cost_per_token: 28e-8, litellm_provider: "perplexity", mode: "chat" },
  "perplexity/pplx-70b-chat": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 7e-7, output_cost_per_token: 28e-7, litellm_provider: "perplexity", mode: "chat" },
  "perplexity/pplx-7b-online": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 28e-8, input_cost_per_request: 5e-3, litellm_provider: "perplexity", mode: "chat" },
  "perplexity/pplx-70b-online": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 0, output_cost_per_token: 28e-7, input_cost_per_request: 5e-3, litellm_provider: "perplexity", mode: "chat" },
  "perplexity/llama-2-70b-chat": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 7e-7, output_cost_per_token: 28e-7, litellm_provider: "perplexity", mode: "chat" },
  "perplexity/mistral-7b-instruct": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 7e-8, output_cost_per_token: 28e-8, litellm_provider: "perplexity", mode: "chat" },
  "perplexity/mixtral-8x7b-instruct": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 7e-8, output_cost_per_token: 28e-8, litellm_provider: "perplexity", mode: "chat" },
  "perplexity/sonar-small-chat": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 7e-8, output_cost_per_token: 28e-8, litellm_provider: "perplexity", mode: "chat" },
  "perplexity/sonar-small-online": { max_tokens: 12e3, max_input_tokens: 12e3, max_output_tokens: 12e3, input_cost_per_token: 0, output_cost_per_token: 28e-8, input_cost_per_request: 5e-3, litellm_provider: "perplexity", mode: "chat" },
  "perplexity/sonar-medium-chat": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 6e-7, output_cost_per_token: 18e-7, litellm_provider: "perplexity", mode: "chat" },
  "perplexity/sonar-medium-online": { max_tokens: 12e3, max_input_tokens: 12e3, max_output_tokens: 12e3, input_cost_per_token: 0, output_cost_per_token: 18e-7, input_cost_per_request: 5e-3, litellm_provider: "perplexity", mode: "chat" },
  "perplexity/sonar": { max_tokens: 128e3, max_input_tokens: 128e3, input_cost_per_token: 1e-6, output_cost_per_token: 1e-6, litellm_provider: "perplexity", mode: "chat", search_context_cost_per_query: { search_context_size_low: 5e-3, search_context_size_medium: 8e-3, search_context_size_high: 0.012 }, supports_web_search: !0 },
  "perplexity/sonar-pro": { max_tokens: 8e3, max_input_tokens: 2e5, max_output_tokens: 8e3, input_cost_per_token: 3e-6, output_cost_per_token: 15e-6, litellm_provider: "perplexity", mode: "chat", search_context_cost_per_query: { search_context_size_low: 6e-3, search_context_size_medium: 0.01, search_context_size_high: 0.014 }, supports_web_search: !0 },
  "perplexity/sonar-reasoning": { max_tokens: 128e3, max_input_tokens: 128e3, input_cost_per_token: 1e-6, output_cost_per_token: 5e-6, litellm_provider: "perplexity", mode: "chat", search_context_cost_per_query: { search_context_size_low: 5e-3, search_context_size_medium: 8e-3, search_context_size_high: 0.014 }, supports_web_search: !0, supports_reasoning: !0 },
  "perplexity/sonar-reasoning-pro": { max_tokens: 128e3, max_input_tokens: 128e3, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, litellm_provider: "perplexity", mode: "chat", search_context_cost_per_query: { search_context_size_low: 6e-3, search_context_size_medium: 0.01, search_context_size_high: 0.014 }, supports_web_search: !0, supports_reasoning: !0 },
  "perplexity/sonar-deep-research": { max_tokens: 128e3, max_input_tokens: 128e3, input_cost_per_token: 2e-6, output_cost_per_token: 8e-6, output_cost_per_reasoning_token: 3e-6, litellm_provider: "perplexity", mode: "chat", search_context_cost_per_query: { search_context_size_low: 5e-3, search_context_size_medium: 5e-3, search_context_size_high: 5e-3 }, supports_reasoning: !0, supports_web_search: !0 },
  "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 1e-7, output_cost_per_token: 1e-7, litellm_provider: "fireworks_ai", mode: "chat", supports_function_calling: !1, supports_response_schema: !0, source: "https://fireworks.ai/pricing", supports_tool_choice: !1 },
  "fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 1e-7, output_cost_per_token: 1e-7, litellm_provider: "fireworks_ai", mode: "chat", supports_function_calling: !1, supports_response_schema: !0, source: "https://fireworks.ai/pricing", supports_tool_choice: !1 },
  "fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 1e-7, output_cost_per_token: 1e-7, litellm_provider: "fireworks_ai", mode: "chat", supports_function_calling: !1, supports_response_schema: !0, source: "https://fireworks.ai/pricing", supports_tool_choice: !1 },
  "fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: "fireworks_ai", mode: "chat", supports_function_calling: !1, supports_vision: !0, supports_response_schema: !0, source: "https://fireworks.ai/pricing", supports_tool_choice: !1 },
  "fireworks_ai/accounts/fireworks/models/llama-v3p2-90b-vision-instruct": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: "fireworks_ai", mode: "chat", supports_tool_choice: !1, supports_vision: !0, supports_response_schema: !0, source: "https://fireworks.ai/pricing" },
  "fireworks_ai/accounts/fireworks/models/firefunction-v2": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: "fireworks_ai", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, source: "https://fireworks.ai/pricing", supports_tool_choice: !0 },
  "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf": { max_tokens: 65536, max_input_tokens: 65536, max_output_tokens: 65536, input_cost_per_token: 12e-7, output_cost_per_token: 12e-7, litellm_provider: "fireworks_ai", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, source: "https://fireworks.ai/pricing", supports_tool_choice: !0 },
  "fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: "fireworks_ai", mode: "chat", supports_function_calling: !1, supports_response_schema: !0, source: "https://fireworks.ai/pricing", supports_tool_choice: !1 },
  "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: "fireworks_ai", mode: "chat", supports_function_calling: !1, supports_response_schema: !0, source: "https://fireworks.ai/pricing", supports_tool_choice: !1 },
  "fireworks_ai/accounts/fireworks/models/yi-large": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 3e-6, output_cost_per_token: 3e-6, litellm_provider: "fireworks_ai", mode: "chat", supports_function_calling: !1, supports_response_schema: !0, source: "https://fireworks.ai/pricing", supports_tool_choice: !1 },
  "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct": { max_tokens: 65536, max_input_tokens: 65536, max_output_tokens: 65536, input_cost_per_token: 12e-7, output_cost_per_token: 12e-7, litellm_provider: "fireworks_ai", mode: "chat", supports_function_calling: !1, supports_response_schema: !0, source: "https://fireworks.ai/pricing", supports_tool_choice: !1 },
  "fireworks_ai/accounts/fireworks/models/deepseek-v3": { max_tokens: 8192, max_input_tokens: 128e3, max_output_tokens: 8192, input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: "fireworks_ai", mode: "chat", supports_response_schema: !0, source: "https://fireworks.ai/pricing", supports_tool_choice: !1 },
  "fireworks_ai/accounts/fireworks/models/deepseek-r1": { max_tokens: 20480, max_input_tokens: 128e3, max_output_tokens: 20480, input_cost_per_token: 3e-6, output_cost_per_token: 8e-6, litellm_provider: "fireworks_ai", mode: "chat", supports_response_schema: !0, source: "https://fireworks.ai/pricing", supports_tool_choice: !1 },
  "fireworks_ai/accounts/fireworks/models/deepseek-r1-basic": { max_tokens: 20480, max_input_tokens: 128e3, max_output_tokens: 20480, input_cost_per_token: 55e-8, output_cost_per_token: 219e-8, litellm_provider: "fireworks_ai", mode: "chat", supports_response_schema: !0, source: "https://fireworks.ai/pricing", supports_tool_choice: !1 },
  "fireworks_ai/accounts/fireworks/models/deepseek-r1-0528": { max_tokens: 16e4, max_input_tokens: 16e4, max_output_tokens: 16e4, input_cost_per_token: 3e-6, output_cost_per_token: 8e-6, litellm_provider: "fireworks_ai", mode: "chat", source: "https://fireworks.ai/pricing", supports_tool_choice: !1, supports_response_schema: !0 },
  "fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct": { max_tokens: 16384, max_input_tokens: 128e3, max_output_tokens: 16384, input_cost_per_token: 3e-6, output_cost_per_token: 3e-6, litellm_provider: "fireworks_ai", mode: "chat", supports_response_schema: !0, source: "https://fireworks.ai/pricing", supports_tool_choice: !0, supports_function_calling: !0 },
  "fireworks_ai/accounts/fireworks/models/llama4-maverick-instruct-basic": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 22e-8, output_cost_per_token: 88e-8, litellm_provider: "fireworks_ai", mode: "chat", supports_response_schema: !0, source: "https://fireworks.ai/pricing", supports_tool_choice: !1 },
  "fireworks_ai/accounts/fireworks/models/llama4-scout-instruct-basic": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 15e-8, output_cost_per_token: 6e-7, litellm_provider: "fireworks_ai", mode: "chat", supports_response_schema: !0, source: "https://fireworks.ai/pricing", supports_tool_choice: !1 },
  "fireworks_ai/nomic-ai/nomic-embed-text-v1.5": { max_tokens: 8192, max_input_tokens: 8192, input_cost_per_token: 8e-9, output_cost_per_token: 0, litellm_provider: "fireworks_ai-embedding-models", mode: "embedding", source: "https://fireworks.ai/pricing" },
  "fireworks_ai/nomic-ai/nomic-embed-text-v1": { max_tokens: 8192, max_input_tokens: 8192, input_cost_per_token: 8e-9, output_cost_per_token: 0, litellm_provider: "fireworks_ai-embedding-models", mode: "embedding", source: "https://fireworks.ai/pricing" },
  "fireworks_ai/WhereIsAI/UAE-Large-V1": { max_tokens: 512, max_input_tokens: 512, input_cost_per_token: 16e-9, output_cost_per_token: 0, litellm_provider: "fireworks_ai-embedding-models", mode: "embedding", source: "https://fireworks.ai/pricing" },
  "fireworks_ai/thenlper/gte-large": { max_tokens: 512, max_input_tokens: 512, input_cost_per_token: 16e-9, output_cost_per_token: 0, litellm_provider: "fireworks_ai-embedding-models", mode: "embedding", source: "https://fireworks.ai/pricing" },
  "fireworks_ai/thenlper/gte-base": { max_tokens: 512, max_input_tokens: 512, input_cost_per_token: 8e-9, output_cost_per_token: 0, litellm_provider: "fireworks_ai-embedding-models", mode: "embedding", source: "https://fireworks.ai/pricing" },
  "fireworks-ai-up-to-4b": { input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: "fireworks_ai" },
  "fireworks-ai-4.1b-to-16b": { input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: "fireworks_ai" },
  "fireworks-ai-above-16b": { input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: "fireworks_ai" },
  "fireworks-ai-moe-up-to-56b": { input_cost_per_token: 5e-7, output_cost_per_token: 5e-7, litellm_provider: "fireworks_ai" },
  "fireworks-ai-56b-to-176b": { input_cost_per_token: 12e-7, output_cost_per_token: 12e-7, litellm_provider: "fireworks_ai" },
  "fireworks-ai-default": { input_cost_per_token: 0, output_cost_per_token: 0, litellm_provider: "fireworks_ai" },
  "fireworks-ai-embedding-up-to-150m": { input_cost_per_token: 8e-9, output_cost_per_token: 0, litellm_provider: "fireworks_ai-embedding-models" },
  "fireworks-ai-embedding-150m-to-350m": { input_cost_per_token: 16e-9, output_cost_per_token: 0, litellm_provider: "fireworks_ai-embedding-models" },
  "anyscale/mistralai/Mistral-7B-Instruct-v0.1": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: "anyscale", mode: "chat", supports_function_calling: !0, source: "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mistral-7B-Instruct-v0.1" },
  "anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: "anyscale", mode: "chat", supports_function_calling: !0, source: "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x7B-Instruct-v0.1" },
  "anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1": { max_tokens: 65536, max_input_tokens: 65536, max_output_tokens: 65536, input_cost_per_token: 9e-7, output_cost_per_token: 9e-7, litellm_provider: "anyscale", mode: "chat", supports_function_calling: !0, source: "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x22B-Instruct-v0.1" },
  "anyscale/HuggingFaceH4/zephyr-7b-beta": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: "anyscale", mode: "chat" },
  "anyscale/google/gemma-7b-it": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: "anyscale", mode: "chat", source: "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/google-gemma-7b-it" },
  "anyscale/meta-llama/Llama-2-7b-chat-hf": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: "anyscale", mode: "chat" },
  "anyscale/meta-llama/Llama-2-13b-chat-hf": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 25e-8, output_cost_per_token: 25e-8, litellm_provider: "anyscale", mode: "chat" },
  "anyscale/meta-llama/Llama-2-70b-chat-hf": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 1e-6, output_cost_per_token: 1e-6, litellm_provider: "anyscale", mode: "chat" },
  "anyscale/codellama/CodeLlama-34b-Instruct-hf": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 1e-6, output_cost_per_token: 1e-6, litellm_provider: "anyscale", mode: "chat" },
  "anyscale/codellama/CodeLlama-70b-Instruct-hf": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 1e-6, output_cost_per_token: 1e-6, litellm_provider: "anyscale", mode: "chat", source: "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/codellama-CodeLlama-70b-Instruct-hf" },
  "anyscale/meta-llama/Meta-Llama-3-8B-Instruct": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: "anyscale", mode: "chat", source: "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-8B-Instruct" },
  "anyscale/meta-llama/Meta-Llama-3-70B-Instruct": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 1e-6, output_cost_per_token: 1e-6, litellm_provider: "anyscale", mode: "chat", source: "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-70B-Instruct" },
  "cloudflare/@cf/meta/llama-2-7b-chat-fp16": { max_tokens: 3072, max_input_tokens: 3072, max_output_tokens: 3072, input_cost_per_token: 1923e-9, output_cost_per_token: 1923e-9, litellm_provider: "cloudflare", mode: "chat" },
  "cloudflare/@cf/meta/llama-2-7b-chat-int8": { max_tokens: 2048, max_input_tokens: 2048, max_output_tokens: 2048, input_cost_per_token: 1923e-9, output_cost_per_token: 1923e-9, litellm_provider: "cloudflare", mode: "chat" },
  "cloudflare/@cf/mistral/mistral-7b-instruct-v0.1": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 1923e-9, output_cost_per_token: 1923e-9, litellm_provider: "cloudflare", mode: "chat" },
  "cloudflare/@hf/thebloke/codellama-7b-instruct-awq": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 1923e-9, output_cost_per_token: 1923e-9, litellm_provider: "cloudflare", mode: "chat" },
  "voyage/voyage-01": { max_tokens: 4096, max_input_tokens: 4096, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "voyage", mode: "embedding" },
  "voyage/voyage-lite-01": { max_tokens: 4096, max_input_tokens: 4096, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "voyage", mode: "embedding" },
  "voyage/voyage-large-2": { max_tokens: 16e3, max_input_tokens: 16e3, input_cost_per_token: 12e-8, output_cost_per_token: 0, litellm_provider: "voyage", mode: "embedding" },
  "voyage/voyage-finance-2": { max_tokens: 32e3, max_input_tokens: 32e3, input_cost_per_token: 12e-8, output_cost_per_token: 0, litellm_provider: "voyage", mode: "embedding" },
  "voyage/voyage-lite-02-instruct": { max_tokens: 4e3, max_input_tokens: 4e3, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "voyage", mode: "embedding" },
  "voyage/voyage-law-2": { max_tokens: 16e3, max_input_tokens: 16e3, input_cost_per_token: 12e-8, output_cost_per_token: 0, litellm_provider: "voyage", mode: "embedding" },
  "voyage/voyage-code-2": { max_tokens: 16e3, max_input_tokens: 16e3, input_cost_per_token: 12e-8, output_cost_per_token: 0, litellm_provider: "voyage", mode: "embedding" },
  "voyage/voyage-2": { max_tokens: 4e3, max_input_tokens: 4e3, input_cost_per_token: 1e-7, output_cost_per_token: 0, litellm_provider: "voyage", mode: "embedding" },
  "voyage/voyage-3-large": { max_tokens: 32e3, max_input_tokens: 32e3, input_cost_per_token: 18e-8, output_cost_per_token: 0, litellm_provider: "voyage", mode: "embedding" },
  "voyage/voyage-3": { max_tokens: 32e3, max_input_tokens: 32e3, input_cost_per_token: 6e-8, output_cost_per_token: 0, litellm_provider: "voyage", mode: "embedding" },
  "voyage/voyage-3-lite": { max_tokens: 32e3, max_input_tokens: 32e3, input_cost_per_token: 2e-8, output_cost_per_token: 0, litellm_provider: "voyage", mode: "embedding" },
  "voyage/voyage-code-3": { max_tokens: 32e3, max_input_tokens: 32e3, input_cost_per_token: 18e-8, output_cost_per_token: 0, litellm_provider: "voyage", mode: "embedding" },
  "voyage/voyage-multimodal-3": { max_tokens: 32e3, max_input_tokens: 32e3, input_cost_per_token: 12e-8, output_cost_per_token: 0, litellm_provider: "voyage", mode: "embedding" },
  "voyage/rerank-2": { max_tokens: 16e3, max_input_tokens: 16e3, max_output_tokens: 16e3, max_query_tokens: 16e3, input_cost_per_token: 5e-8, input_cost_per_query: 5e-8, output_cost_per_token: 0, litellm_provider: "voyage", mode: "rerank" },
  "voyage/rerank-2-lite": { max_tokens: 8e3, max_input_tokens: 8e3, max_output_tokens: 8e3, max_query_tokens: 8e3, input_cost_per_token: 2e-8, input_cost_per_query: 2e-8, output_cost_per_token: 0, litellm_provider: "voyage", mode: "rerank" },
  "databricks/databricks-claude-3-7-sonnet": { max_tokens: 2e5, max_input_tokens: 2e5, max_output_tokens: 128e3, input_cost_per_token: 25e-7, input_dbu_cost_per_token: 3571e-8, output_cost_per_token: 17857e-9, output_db_cost_per_token: 214286e-9, litellm_provider: "databricks", mode: "chat", source: "https://www.databricks.com/product/pricing/foundation-model-serving", metadata: { notes: "Input/output cost per token is dbu cost * $0.070, based on databricks Claude 3.7 conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation." }, supports_assistant_prefill: !0, supports_function_calling: !0, supports_tool_choice: !0, supports_reasoning: !0 },
  "databricks/databricks-meta-llama-3-1-405b-instruct": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 5e-6, input_dbu_cost_per_token: 71429e-9, output_cost_per_token: 1500002e-11, output_db_cost_per_token: 214286e-9, litellm_provider: "databricks", mode: "chat", source: "https://www.databricks.com/product/pricing/foundation-model-serving", metadata: { notes: "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation." }, supports_tool_choice: !0 },
  "databricks/databricks-meta-llama-3-1-70b-instruct": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 100002e-11, input_dbu_cost_per_token: 14286e-9, output_cost_per_token: 299999e-11, output_dbu_cost_per_token: 42857e-9, litellm_provider: "databricks", mode: "chat", source: "https://www.databricks.com/product/pricing/foundation-model-serving", metadata: { notes: "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation." }, supports_tool_choice: !0 },
  "databricks/databricks-meta-llama-3-3-70b-instruct": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 100002e-11, input_dbu_cost_per_token: 14286e-9, output_cost_per_token: 299999e-11, output_dbu_cost_per_token: 42857e-9, litellm_provider: "databricks", mode: "chat", source: "https://www.databricks.com/product/pricing/foundation-model-serving", metadata: { notes: "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation." }, supports_tool_choice: !0 },
  "databricks/databricks-llama-4-maverick": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 5e-6, input_dbu_cost_per_token: 7143e-8, output_cost_per_token: 15e-6, output_dbu_cost_per_token: 21429e-8, litellm_provider: "databricks", mode: "chat", source: "https://www.databricks.com/product/pricing/foundation-model-serving", metadata: { notes: "Databricks documentation now provides both DBU costs (_dbu_cost_per_token) and dollar costs(_cost_per_token)." }, supports_tool_choice: !0 },
  "databricks/databricks-dbrx-instruct": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 74998e-11, input_dbu_cost_per_token: 10714e-9, output_cost_per_token: 224901e-11, output_dbu_cost_per_token: 32143e-9, litellm_provider: "databricks", mode: "chat", source: "https://www.databricks.com/product/pricing/foundation-model-serving", metadata: { notes: "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation." }, supports_tool_choice: !0 },
  "databricks/databricks-meta-llama-3-70b-instruct": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 128e3, input_cost_per_token: 100002e-11, input_dbu_cost_per_token: 14286e-9, output_cost_per_token: 299999e-11, output_dbu_cost_per_token: 42857e-9, litellm_provider: "databricks", mode: "chat", source: "https://www.databricks.com/product/pricing/foundation-model-serving", metadata: { notes: "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation." }, supports_tool_choice: !0 },
  "databricks/databricks-llama-2-70b-chat": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 50001e-11, input_dbu_cost_per_token: 7143e-9, output_cost_per_token: 15e-7, output_dbu_cost_per_token: 21429e-9, litellm_provider: "databricks", mode: "chat", source: "https://www.databricks.com/product/pricing/foundation-model-serving", metadata: { notes: "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation." }, supports_tool_choice: !0 },
  "databricks/databricks-mixtral-8x7b-instruct": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 50001e-11, input_dbu_cost_per_token: 7143e-9, output_cost_per_token: 99902e-11, output_dbu_cost_per_token: 14286e-9, litellm_provider: "databricks", mode: "chat", source: "https://www.databricks.com/product/pricing/foundation-model-serving", metadata: { notes: "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation." }, supports_tool_choice: !0 },
  "databricks/databricks-mpt-30b-instruct": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 99902e-11, input_dbu_cost_per_token: 14286e-9, output_cost_per_token: 99902e-11, output_dbu_cost_per_token: 14286e-9, litellm_provider: "databricks", mode: "chat", source: "https://www.databricks.com/product/pricing/foundation-model-serving", metadata: { notes: "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation." }, supports_tool_choice: !0 },
  "databricks/databricks-mpt-7b-instruct": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 50001e-11, input_dbu_cost_per_token: 7143e-9, output_cost_per_token: 0, output_dbu_cost_per_token: 0, litellm_provider: "databricks", mode: "chat", source: "https://www.databricks.com/product/pricing/foundation-model-serving", metadata: { notes: "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation." }, supports_tool_choice: !0 },
  "databricks/databricks-bge-large-en": { max_tokens: 512, max_input_tokens: 512, output_vector_size: 1024, input_cost_per_token: 10003e-11, input_dbu_cost_per_token: 1429e-9, output_cost_per_token: 0, output_dbu_cost_per_token: 0, litellm_provider: "databricks", mode: "embedding", source: "https://www.databricks.com/product/pricing/foundation-model-serving", metadata: { notes: "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation." } },
  "databricks/databricks-gte-large-en": { max_tokens: 8192, max_input_tokens: 8192, output_vector_size: 1024, input_cost_per_token: 12999e-11, input_dbu_cost_per_token: 1857e-9, output_cost_per_token: 0, output_dbu_cost_per_token: 0, litellm_provider: "databricks", mode: "embedding", source: "https://www.databricks.com/product/pricing/foundation-model-serving", metadata: { notes: "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation." } },
  "sambanova/Meta-Llama-3.1-8B-Instruct": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 1e-7, output_cost_per_token: 2e-7, litellm_provider: "sambanova", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !0, source: "https://cloud.sambanova.ai/plans/pricing" },
  "sambanova/Meta-Llama-3.1-405B-Instruct": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 5e-6, output_cost_per_token: 1e-5, litellm_provider: "sambanova", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !0, source: "https://cloud.sambanova.ai/plans/pricing" },
  "sambanova/Meta-Llama-3.2-1B-Instruct": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 4e-8, output_cost_per_token: 8e-8, litellm_provider: "sambanova", mode: "chat", source: "https://cloud.sambanova.ai/plans/pricing" },
  "sambanova/Meta-Llama-3.2-3B-Instruct": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 8e-8, output_cost_per_token: 16e-8, litellm_provider: "sambanova", mode: "chat", source: "https://cloud.sambanova.ai/plans/pricing" },
  "sambanova/Llama-4-Maverick-17B-128E-Instruct": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 63e-8, output_cost_per_token: 18e-7, litellm_provider: "sambanova", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !0, supports_vision: !0, source: "https://cloud.sambanova.ai/plans/pricing", metadata: { notes: "For vision models, images are converted to 6432 input tokens and are billed at that amount" } },
  "sambanova/Llama-4-Scout-17B-16E-Instruct": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 4e-7, output_cost_per_token: 7e-7, litellm_provider: "sambanova", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0, supports_response_schema: !0, source: "https://cloud.sambanova.ai/plans/pricing", metadata: { notes: "For vision models, images are converted to 6432 input tokens and are billed at that amount" } },
  "sambanova/Meta-Llama-3.3-70B-Instruct": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 6e-7, output_cost_per_token: 12e-7, litellm_provider: "sambanova", mode: "chat", supports_function_calling: !0, supports_response_schema: !0, supports_tool_choice: !0, source: "https://cloud.sambanova.ai/plans/pricing" },
  "sambanova/Meta-Llama-Guard-3-8B": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 3e-7, output_cost_per_token: 3e-7, litellm_provider: "sambanova", mode: "chat", source: "https://cloud.sambanova.ai/plans/pricing" },
  "sambanova/Qwen3-32B": { max_tokens: 8192, max_input_tokens: 8192, max_output_tokens: 8192, input_cost_per_token: 4e-7, output_cost_per_token: 8e-7, litellm_provider: "sambanova", supports_function_calling: !0, supports_tool_choice: !0, supports_reasoning: !0, mode: "chat", source: "https://cloud.sambanova.ai/plans/pricing" },
  "sambanova/QwQ-32B": { max_tokens: 16384, max_input_tokens: 16384, max_output_tokens: 16384, input_cost_per_token: 5e-7, output_cost_per_token: 1e-6, litellm_provider: "sambanova", mode: "chat", source: "https://cloud.sambanova.ai/plans/pricing" },
  "sambanova/Qwen2-Audio-7B-Instruct": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 4096, input_cost_per_token: 5e-7, output_cost_per_token: 1e-4, litellm_provider: "sambanova", mode: "chat", supports_audio_input: !0, source: "https://cloud.sambanova.ai/plans/pricing" },
  "sambanova/DeepSeek-R1-Distill-Llama-70B": { max_tokens: 131072, max_input_tokens: 131072, max_output_tokens: 131072, input_cost_per_token: 7e-7, output_cost_per_token: 14e-7, litellm_provider: "sambanova", mode: "chat", source: "https://cloud.sambanova.ai/plans/pricing" },
  "sambanova/DeepSeek-R1": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 5e-6, output_cost_per_token: 7e-6, litellm_provider: "sambanova", mode: "chat", source: "https://cloud.sambanova.ai/plans/pricing" },
  "sambanova/DeepSeek-V3-0324": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 32768, input_cost_per_token: 3e-6, output_cost_per_token: 45e-7, litellm_provider: "sambanova", mode: "chat", supports_function_calling: !0, supports_tool_choice: !0, supports_reasoning: !0, source: "https://cloud.sambanova.ai/plans/pricing" },
  "assemblyai/nano": { mode: "audio_transcription", input_cost_per_second: 10278e-8, output_cost_per_second: 0, litellm_provider: "assemblyai" },
  "assemblyai/best": { mode: "audio_transcription", input_cost_per_second: 3333e-8, output_cost_per_second: 0, litellm_provider: "assemblyai" },
  "jina-reranker-v2-base-multilingual": { max_tokens: 1024, max_input_tokens: 1024, max_output_tokens: 1024, max_document_chunks_per_query: 2048, input_cost_per_token: 18e-9, output_cost_per_token: 18e-9, litellm_provider: "jina_ai", mode: "rerank" },
  "snowflake/deepseek-r1": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 8192, litellm_provider: "snowflake", supports_reasoning: !0, mode: "chat" },
  "snowflake/snowflake-arctic": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/claude-3-5-sonnet": { supports_computer_use: !0, max_tokens: 18e3, max_input_tokens: 18e3, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/mistral-large": { max_tokens: 32e3, max_input_tokens: 32e3, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/mistral-large2": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/reka-flash": { max_tokens: 1e5, max_input_tokens: 1e5, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/reka-core": { max_tokens: 32e3, max_input_tokens: 32e3, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/jamba-instruct": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/jamba-1.5-mini": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/jamba-1.5-large": { max_tokens: 256e3, max_input_tokens: 256e3, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/mixtral-8x7b": { max_tokens: 32e3, max_input_tokens: 32e3, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/llama2-70b-chat": { max_tokens: 4096, max_input_tokens: 4096, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/llama3-8b": { max_tokens: 8e3, max_input_tokens: 8e3, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/llama3-70b": { max_tokens: 8e3, max_input_tokens: 8e3, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/llama3.1-8b": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/llama3.1-70b": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/llama3.3-70b": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/snowflake-llama-3.3-70b": { max_tokens: 8e3, max_input_tokens: 8e3, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/llama3.1-405b": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/snowflake-llama-3.1-405b": { max_tokens: 8e3, max_input_tokens: 8e3, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/llama3.2-1b": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/llama3.2-3b": { max_tokens: 128e3, max_input_tokens: 128e3, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/mistral-7b": { max_tokens: 32e3, max_input_tokens: 32e3, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "snowflake/gemma-7b": { max_tokens: 8e3, max_input_tokens: 8e3, max_output_tokens: 8192, litellm_provider: "snowflake", mode: "chat" },
  "nscale/meta-llama/Llama-4-Scout-17B-16E-Instruct": { input_cost_per_token: 9e-8, output_cost_per_token: 29e-8, litellm_provider: "nscale", mode: "chat", source: "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models" },
  "nscale/Qwen/Qwen2.5-Coder-3B-Instruct": { input_cost_per_token: 1e-8, output_cost_per_token: 3e-8, litellm_provider: "nscale", mode: "chat", source: "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models" },
  "nscale/Qwen/Qwen2.5-Coder-7B-Instruct": { input_cost_per_token: 1e-8, output_cost_per_token: 3e-8, litellm_provider: "nscale", mode: "chat", source: "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models" },
  "nscale/Qwen/Qwen2.5-Coder-32B-Instruct": { input_cost_per_token: 6e-8, output_cost_per_token: 2e-7, litellm_provider: "nscale", mode: "chat", source: "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models" },
  "nscale/Qwen/QwQ-32B": { input_cost_per_token: 18e-8, output_cost_per_token: 2e-7, litellm_provider: "nscale", mode: "chat", source: "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models" },
  "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-70B": { input_cost_per_token: 375e-9, output_cost_per_token: 375e-9, litellm_provider: "nscale", mode: "chat", source: "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models", metadata: { notes: "Pricing listed as $0.75/1M tokens total. Assumed 50/50 split for input/output." } },
  "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-8B": { input_cost_per_token: 25e-9, output_cost_per_token: 25e-9, litellm_provider: "nscale", mode: "chat", source: "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models", metadata: { notes: "Pricing listed as $0.05/1M tokens total. Assumed 50/50 split for input/output." } },
  "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B": { input_cost_per_token: 9e-8, output_cost_per_token: 9e-8, litellm_provider: "nscale", mode: "chat", source: "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models", metadata: { notes: "Pricing listed as $0.18/1M tokens total. Assumed 50/50 split for input/output." } },
  "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B": { input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: "nscale", mode: "chat", source: "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models", metadata: { notes: "Pricing listed as $0.40/1M tokens total. Assumed 50/50 split for input/output." } },
  "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B": { input_cost_per_token: 7e-8, output_cost_per_token: 7e-8, litellm_provider: "nscale", mode: "chat", source: "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models", metadata: { notes: "Pricing listed as $0.14/1M tokens total. Assumed 50/50 split for input/output." } },
  "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": { input_cost_per_token: 15e-8, output_cost_per_token: 15e-8, litellm_provider: "nscale", mode: "chat", source: "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models", metadata: { notes: "Pricing listed as $0.30/1M tokens total. Assumed 50/50 split for input/output." } },
  "nscale/mistralai/mixtral-8x22b-instruct-v0.1": { input_cost_per_token: 6e-7, output_cost_per_token: 6e-7, litellm_provider: "nscale", mode: "chat", source: "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models", metadata: { notes: "Pricing listed as $1.20/1M tokens total. Assumed 50/50 split for input/output." } },
  "nscale/meta-llama/Llama-3.1-8B-Instruct": { input_cost_per_token: 3e-8, output_cost_per_token: 3e-8, litellm_provider: "nscale", mode: "chat", source: "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models", metadata: { notes: "Pricing listed as $0.06/1M tokens total. Assumed 50/50 split for input/output." } },
  "nscale/meta-llama/Llama-3.3-70B-Instruct": { input_cost_per_token: 2e-7, output_cost_per_token: 2e-7, litellm_provider: "nscale", mode: "chat", source: "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models", metadata: { notes: "Pricing listed as $0.40/1M tokens total. Assumed 50/50 split for input/output." } },
  "nscale/black-forest-labs/FLUX.1-schnell": { mode: "image_generation", input_cost_per_pixel: 13e-10, output_cost_per_pixel: 0, litellm_provider: "nscale", supported_endpoints: ["/v1/images/generations"], source: "https://docs.nscale.com/docs/inference/serverless-models/current#image-models" },
  "nscale/stabilityai/stable-diffusion-xl-base-1.0": { mode: "image_generation", input_cost_per_pixel: 3e-9, output_cost_per_pixel: 0, litellm_provider: "nscale", supported_endpoints: ["/v1/images/generations"], source: "https://docs.nscale.com/docs/inference/serverless-models/current#image-models" },
  "featherless_ai/featherless-ai/Qwerky-72B": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 4096, litellm_provider: "featherless_ai", mode: "chat" },
  "featherless_ai/featherless-ai/Qwerky-QwQ-32B": { max_tokens: 32768, max_input_tokens: 32768, max_output_tokens: 4096, litellm_provider: "featherless_ai", mode: "chat" },
  "deepgram/nova-3": { mode: "audio_transcription", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 43e-4, calculation: "$0.0043/60 seconds = $0.00007167 per second" } },
  "deepgram/nova-3-general": { mode: "audio_transcription", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 43e-4, calculation: "$0.0043/60 seconds = $0.00007167 per second" } },
  "deepgram/nova-3-medical": { mode: "audio_transcription", input_cost_per_second: 8667e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 52e-4, calculation: "$0.0052/60 seconds = $0.00008667 per second (multilingual)" } },
  "deepgram/nova-2": { mode: "audio_transcription", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 43e-4, calculation: "$0.0043/60 seconds = $0.00007167 per second" } },
  "deepgram/nova-2-general": { mode: "audio_transcription", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 43e-4, calculation: "$0.0043/60 seconds = $0.00007167 per second" } },
  "deepgram/nova-2-meeting": { mode: "audio_transcription", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 43e-4, calculation: "$0.0043/60 seconds = $0.00007167 per second" } },
  "deepgram/nova-2-phonecall": { mode: "audio_transcription", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 43e-4, calculation: "$0.0043/60 seconds = $0.00007167 per second" } },
  "deepgram/nova-2-voicemail": { mode: "audio_transcription", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 43e-4, calculation: "$0.0043/60 seconds = $0.00007167 per second" } },
  "deepgram/nova-2-finance": { mode: "audio_transcription", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 43e-4, calculation: "$0.0043/60 seconds = $0.00007167 per second" } },
  "deepgram/nova-2-conversationalai": { mode: "audio_transcription", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 43e-4, calculation: "$0.0043/60 seconds = $0.00007167 per second" } },
  "deepgram/nova-2-video": { mode: "audio_transcription", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 43e-4, calculation: "$0.0043/60 seconds = $0.00007167 per second" } },
  "deepgram/nova-2-drivethru": { mode: "audio_transcription", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 43e-4, calculation: "$0.0043/60 seconds = $0.00007167 per second" } },
  "deepgram/nova-2-automotive": { mode: "audio_transcription", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 43e-4, calculation: "$0.0043/60 seconds = $0.00007167 per second" } },
  "deepgram/nova-2-atc": { mode: "audio_transcription", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 43e-4, calculation: "$0.0043/60 seconds = $0.00007167 per second" } },
  "deepgram/nova": { mode: "audio_transcription", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 43e-4, calculation: "$0.0043/60 seconds = $0.00007167 per second" } },
  "deepgram/nova-general": { mode: "audio_transcription", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 43e-4, calculation: "$0.0043/60 seconds = $0.00007167 per second" } },
  "deepgram/nova-phonecall": { mode: "audio_transcription", input_cost_per_second: 7167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 43e-4, calculation: "$0.0043/60 seconds = $0.00007167 per second" } },
  "deepgram/enhanced": { mode: "audio_transcription", input_cost_per_second: 24167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 0.0145, calculation: "$0.0145/60 seconds = $0.00024167 per second" } },
  "deepgram/enhanced-general": { mode: "audio_transcription", input_cost_per_second: 24167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 0.0145, calculation: "$0.0145/60 seconds = $0.00024167 per second" } },
  "deepgram/enhanced-meeting": { mode: "audio_transcription", input_cost_per_second: 24167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 0.0145, calculation: "$0.0145/60 seconds = $0.00024167 per second" } },
  "deepgram/enhanced-phonecall": { mode: "audio_transcription", input_cost_per_second: 24167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 0.0145, calculation: "$0.0145/60 seconds = $0.00024167 per second" } },
  "deepgram/enhanced-finance": { mode: "audio_transcription", input_cost_per_second: 24167e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 0.0145, calculation: "$0.0145/60 seconds = $0.00024167 per second" } },
  "deepgram/base": { mode: "audio_transcription", input_cost_per_second: 20833e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 0.0125, calculation: "$0.0125/60 seconds = $0.00020833 per second" } },
  "deepgram/base-general": { mode: "audio_transcription", input_cost_per_second: 20833e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 0.0125, calculation: "$0.0125/60 seconds = $0.00020833 per second" } },
  "deepgram/base-meeting": { mode: "audio_transcription", input_cost_per_second: 20833e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 0.0125, calculation: "$0.0125/60 seconds = $0.00020833 per second" } },
  "deepgram/base-phonecall": { mode: "audio_transcription", input_cost_per_second: 20833e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 0.0125, calculation: "$0.0125/60 seconds = $0.00020833 per second" } },
  "deepgram/base-voicemail": { mode: "audio_transcription", input_cost_per_second: 20833e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 0.0125, calculation: "$0.0125/60 seconds = $0.00020833 per second" } },
  "deepgram/base-finance": { mode: "audio_transcription", input_cost_per_second: 20833e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 0.0125, calculation: "$0.0125/60 seconds = $0.00020833 per second" } },
  "deepgram/base-conversationalai": { mode: "audio_transcription", input_cost_per_second: 20833e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 0.0125, calculation: "$0.0125/60 seconds = $0.00020833 per second" } },
  "deepgram/base-video": { mode: "audio_transcription", input_cost_per_second: 20833e-8, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { original_pricing_per_minute: 0.0125, calculation: "$0.0125/60 seconds = $0.00020833 per second" } },
  "deepgram/whisper": { mode: "audio_transcription", input_cost_per_second: 1e-4, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { notes: "Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models" } },
  "deepgram/whisper-tiny": { mode: "audio_transcription", input_cost_per_second: 1e-4, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { notes: "Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models" } },
  "deepgram/whisper-base": { mode: "audio_transcription", input_cost_per_second: 1e-4, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { notes: "Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models" } },
  "deepgram/whisper-small": { mode: "audio_transcription", input_cost_per_second: 1e-4, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { notes: "Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models" } },
  "deepgram/whisper-medium": { mode: "audio_transcription", input_cost_per_second: 1e-4, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { notes: "Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models" } },
  "deepgram/whisper-large": { mode: "audio_transcription", input_cost_per_second: 1e-4, output_cost_per_second: 0, litellm_provider: "deepgram", supported_endpoints: ["/v1/audio/transcriptions"], source: "https://deepgram.com/pricing", metadata: { notes: "Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models" } }
};
let g = {};
const v = class v {
  constructor(t) {
    this.service = t;
  }
  getModel(t, e = {}) {
    return v.get(this.service, t, e);
  }
  async refresh() {
    await v.refresh();
  }
  models() {
    return v.getByService(this.service);
  }
  static get(t, e, o = {}) {
    let _ = this.getByServiceModel(t, e);
    return _ || (o.allowSimilar ? (_ = this.getByServiceModel(t, `${e}-latest`), _ || (_ = this.getByServiceModel(t, `${e}-beta`), _) || (_ = this.getByServiceModel(t, `${t}/${e}`), _) || (_ = this.getByServiceModel(t, `${t}/${e}-beta`), _) || (_ = this.getByServiceModel(t, e.replace("-beta", "")), _) || (_ = this.getByServiceModel(t, e.replace("-thinking", "")), _) || (_ = this.getByServiceModel(t, e.replace("-exp", "")), _) || (_ = this.getByServiceModel(t, e.replace("-experimental", "")), _) || (_ = this.getByServiceModel(t, e.replace("-thinking-exp", "")), _) || (_ = this.getByServiceModel(t, e.replace("-preview", "")), _) ? _ : null) : null);
  }
  static getAll() {
    return this.factories(Q).filter(this.filter());
  }
  static getByService(t) {
    return this.factories(Q).filter(this.filter(t));
  }
  static getByServiceModel(t, e) {
    return this.getByService(t).find((o) => o.model === e) || null;
  }
  static filter(t) {
    return (e) => e.mode !== "chat" && e.mode !== "responses" ? !1 : t === "google" && e.service === "gemini" ? !0 : t ? e.service === t : !0;
  }
  static factories(t) {
    const e = Object.assign({}, t, g);
    return Object.keys(e).map((o) => {
      const _ = e[o], s = _.max_input_tokens || 0, r = _.max_output_tokens || 0, u = _.max_tokens ? _.max_tokens : s + r, n = _.input_cost_per_token || 0, c = _.output_cost_per_token || 0, i = _.output_cost_per_reasoning_token || 0, l = _.supported_modalities || [];
      let F = o;
      return o.includes("/") && (F = o.split("/").slice(1).join("/")), {
        service: _.litellm_provider || _.service,
        mode: _.mode,
        model: F,
        max_tokens: u,
        max_input_tokens: s,
        max_output_tokens: r,
        input_cost_per_token: n,
        output_cost_per_token: c,
        output_cost_per_reasoning_token: i,
        supports_reasoning: _.supports_reasoning || !1,
        supported_modalities: l
      };
    });
  }
  static async refresh(t) {
    const o = await (await fetch(this.DEFAULT_BASE_URL)).json();
    return this.factories(o).filter(this.filter(t));
  }
  static addCustom(t) {
    g[`${t.service}/${t.model}`] = Object.assign({}, { mode: "chat" }, t);
  }
  static getCustom(t, e) {
    return g[`${t}/${e}`] || null;
  }
  static getCustoms() {
    return g;
  }
  static removeCustom(t, e) {
    delete g[`${t}/${e}`];
  }
  static clearCustom() {
    g = {};
  }
};
v.DEFAULT_BASE_URL = "https://raw.githubusercontent.com/BerriAI/litellm/refs/heads/main/model_prices_and_context_window.json";
let B = v;
const Y = {
  service: "ollama",
  max_tokens: 1024
}, R = j("llm.js:parsers");
function M(p) {
  return function(t) {
    try {
      return t.split("```" + p)[1].split("```")[0].trim();
    } catch (e) {
      throw R.error(`error parsing code block of type ${p} from content`, t), e;
    }
  };
}
function rt(p) {
  try {
    return M("markdown")(p);
  } catch {
    return M("md")(p);
  }
}
function W(p) {
  try {
    return JSON.parse(p);
  } catch {
    const e = M("json");
    try {
      return JSON.parse(e(p));
    } catch (o) {
      throw R.error("error parsing json from content", p), o;
    }
  }
}
function ut(p) {
  return function(t) {
    try {
      const e = t.split(`<${p}>`)[1].split(`</${p}>`)[0].trim();
      if (!e || e.length == 0)
        throw new Error(`No content found inside of XML tag ${p}`);
      return e;
    } catch (e) {
      throw R.error(`error parsing xml tag ${p} from content`, t), e;
    }
  };
}
const H = /* @__PURE__ */ Object.freeze(/* @__PURE__ */ Object.defineProperty({
  __proto__: null,
  codeBlock: M,
  json: W,
  markdown: rt,
  xml: ut
}, Symbol.toStringTag, { value: "Module" })), nt = {}, it = j("llm.js:utils");
async function J(p, t = "Error while handling response") {
  if (p.ok) return !0;
  let e;
  try {
    e = await p.json();
  } catch {
    let s = "Unable to parse response";
    throw p.status && p.statusText && (s = `${p.status} ${p.statusText}`), new Error(s);
  }
  let o = t;
  throw e.error && typeof e.error == "string" ? o = e.error : e.error && typeof e.error == "object" && e.error.type && e.error.message ? o = `${e.error.type}: ${e.error.message}` : e.error && typeof e.error == "object" && (o = JSON.stringify(e.error)), new Error(o);
}
async function* at(p) {
  const t = p.getReader(), e = new TextDecoder();
  let o = "";
  for (; ; ) {
    let { done: _, value: s } = await t.read();
    if (_) break;
    let r = e.decode(s, { stream: !0 });
    if (!r) continue;
    const u = r.split(`
`);
    let n = [];
    for (let i of u)
      i.startsWith("event: ") || (i.startsWith("data: ") && (i = i.slice(6)), i.length !== 0 && n.push(i));
    o = n.join(`
`), n = [];
    const c = o.split(`
`);
    for (const i of c)
      try {
        const l = JSON.parse(i);
        if (yield l, l.type === "message_stop" || l.type === "response.completed" || l.done) {
          _ = !0;
          break;
        }
      } catch {
        n.push(i);
      }
    o = n.join(`
`);
  }
  if (o.length > 0)
    try {
      yield JSON.parse(o);
    } catch {
      it.error("Error parsing JSON LINE:", o);
    }
}
function ct(p, t) {
  return p.filter((e) => e.role === t);
}
function lt(p, t) {
  return p.filter((e) => e.role !== t);
}
function mt() {
  return crypto.randomUUID();
}
function V(p) {
  if (!p.name) throw new Error("Tool name is required");
  if (!p.description) throw new Error("Tool description is required");
  if (!p.input_schema) throw new Error("Tool input schema is required");
  return {
    type: "function",
    function: { name: p.name, description: p.description, parameters: p.input_schema }
  };
}
function P(p) {
  if (!p.function) throw new Error("Tool call function is required");
  if (p.function.id || (p.function.id = crypto.randomUUID()), !p.function.name) throw new Error("Tool call function name is required");
  if (!p.function.arguments) throw new Error("Tool call function arguments is required");
  let t = p.function.arguments;
  return typeof t == "string" && (t = JSON.parse(t)), { id: p.function.id, name: p.function.name, input: t };
}
function D(p, t) {
  for (const e of t)
    if (p.includes(`${e}-`) || p.includes(`-${e}`)) return !1;
  return !0;
}
function O() {
  return typeof window < "u" && !G();
}
function G() {
  return typeof process < "u" && !O();
}
O() || process.env;
function m(...p) {
  if (p.length === 0) return ".";
  const t = p[0];
  if (t.startsWith("http://") || t.startsWith("https://")) {
    const [s, ...r] = t.split("://"), u = p.slice(1), c = [r.join("://"), ...u].join("/").replace(/\/+/g, "/");
    return `${s}://${c}`;
  }
  let o = [];
  for (let s = 0, r = p.length; s < r; s++)
    o = o.concat(p[s].split("/"));
  const _ = [];
  for (let s = 0, r = o.length; s < r; s++) {
    const u = o[s];
    !u || u === "." || (u === ".." ? _.pop() : _.push(u));
  }
  return o[0] === "" && _.unshift(""), _.join("/") || (_.length ? "/" : ".");
}
const N = j("llm.js:index"), w = class w {
  constructor(t, e = {}) {
    this.abortController = null, this.cache = {};
    const o = this.constructor;
    this.service = e.service ?? this.constructor.service, this.messages = [], t && typeof t == "string" ? this.user(t) : t && Array.isArray(t) && (this.messages = t), this.options = e, this.model = e.model ?? o.DEFAULT_MODEL, this.baseUrl = e.baseUrl ?? o.DEFAULT_BASE_URL, this.modelUsage = new B(this.service), this.stream = e.stream ?? !1, this.max_tokens = e.max_tokens ?? Y.max_tokens, this.extended = e.extended ?? !1, this.think = e.think ?? !1, this.qualityFilter = e.qualityFilter ?? {}, typeof e.temperature == "number" && (this.temperature = e.temperature), typeof e.max_thinking_tokens == "number" && (this.max_thinking_tokens = e.max_thinking_tokens), typeof e.parser == "string" && (this.parser = this.parsers[e.parser]), typeof e.json == "boolean" && (this.json = e.json), this.json && !this.parser && (this.parser = W), Array.isArray(e.tools) && (this.tools = e.tools), this.think && (this.extended = !0), this.tools && this.tools.length > 0 && (this.extended = !0), N.debug(`LLM ${this.service} constructor`);
  }
  get isLocal() {
    return this.constructor.isLocal;
  }
  get apiKey() {
    var t;
    if (this.options.apiKey) return this.options.apiKey;
    if (O()) {
      if (localStorage.getItem(`${this.service.toUpperCase()}_API_KEY`)) return localStorage.getItem(`${this.service.toUpperCase()}_API_KEY`);
    } else if (G() && typeof process < "u" && (t = process.env) != null && t[`${this.service.toUpperCase()}_API_KEY`])
      return process.env[`${this.service.toUpperCase()}_API_KEY`];
  }
  get llmOptions() {
    const t = {
      model: this.model,
      messages: this.parseMessages(this.messages),
      stream: this.stream,
      max_tokens: this.max_tokens,
      think: this.think
    };
    return typeof this.max_thinking_tokens == "number" && (t.max_thinking_tokens = this.max_thinking_tokens), typeof this.temperature == "number" && (t.temperature = this.temperature), this.tools && (t.tools = this.tools), t;
  }
  get llmHeaders() {
    const t = {
      "Content-Type": "application/json"
    };
    return this.constructor.isBearerAuth ? t.Authorization = `Bearer ${this.apiKey}` : this.apiKey && (t["x-api-key"] = this.apiKey), t;
  }
  get chatUrl() {
    return m(this.baseUrl, "api/chat");
  }
  get modelsUrl() {
    return m(this.baseUrl, "api/tags");
  }
  getChatUrl(t) {
    return this.chatUrl;
  }
  getModelsUrl() {
    return this.modelsUrl;
  }
  get parsers() {
    return {
      thinking: this.parseThinkingChunk.bind(this),
      content: this.parseContentChunk.bind(this),
      usage: this.parseTokenUsage.bind(this),
      tool_calls: this.parseToolsChunk.bind(this)
    };
  }
  addMessage(t, e) {
    this.messages.push({ role: t, content: e });
  }
  user(t) {
    this.addMessage("user", t);
  }
  assistant(t) {
    this.addMessage("assistant", t);
  }
  system(t) {
    this.addMessage("system", t);
  }
  thinking(t) {
    this.addMessage("thinking", t);
  }
  toolCall(t) {
    this.addMessage("tool_call", t);
  }
  async chat(t, e) {
    return this.user(t), await this.send(e);
  }
  abort() {
    this.abortController && this.abortController.abort();
  }
  async send(t) {
    const e = { ...this.llmOptions, ...t || {} }, o = this.parseOptions(JSON.parse(JSON.stringify(e)));
    this.resetCache(), o.tools && o.tools.length > 0 && (this.extended = !0), N.debug(`LLM ${this.service} send`), this.abortController = new AbortController();
    const _ = await fetch(this.getChatUrl(o), {
      method: "POST",
      body: JSON.stringify(o),
      headers: this.llmHeaders,
      signal: this.abortController.signal,
      mode: "cors",
      credentials: "omit"
    });
    if (await J(_, "Failed to send request"), this.stream) {
      const s = _.body;
      if (!s) throw new Error("No body found");
      return this.extended ? this.extendedStreamResponse(s, e) : this.streamResponse(s);
    }
    try {
      const s = await _.json();
      return this.extended ? this.extendedResponse(s, e) : this.response(s);
    } finally {
      this.abortController = null;
    }
  }
  response(t) {
    let e = this.parseContent(t);
    return this.parser && (e = this.parser(e)), e && this.assistant(e), e;
  }
  extendedResponse(t, e) {
    const o = {
      service: this.service,
      options: e
    }, _ = this.parseTokenUsage(t);
    if (_ && (o.usage = this.parseUsage(_)), e.think) {
      const r = this.parseThinking(t);
      r && (o.thinking = r, this.thinking(r));
    }
    let s = this.parseContent(t);
    if (this.parser && (s = this.parser(s)), s && this.assistant(s), this.tools && this.tools.length > 0) {
      o.tool_calls = this.parseTools(t);
      for (const r of o.tool_calls)
        r && Object.keys(r).length > 0 && this.toolCall(r);
    }
    return o.content = s, o.messages = JSON.parse(JSON.stringify(this.messages)), o;
  }
  async *streamResponse(t) {
    const e = this.streamResponses(t, { content: this.parseContentChunk.bind(this) });
    for await (const o of e)
      o.type === "content" && (yield o.content);
    this.abortController = null;
  }
  async *streamResponses(t, e) {
    const o = await at(t);
    let _ = { type: "buffers" };
    for await (const s of o)
      for (const [r, u] of Object.entries(e)) {
        const n = u(s);
        if (n)
          if (r === "usage")
            _[r] = n, yield { type: r, content: n };
          else if (r === "tool_calls") {
            if (!Array.isArray(n) || n.length === 0) continue;
            _[r] || (_[r] = []), _[r].push(...n), yield { type: r, content: n };
          } else
            _[r] || (_[r] = ""), _[r] += n, yield { type: r, content: n };
      }
    return this.saveBuffers(_), _;
  }
  saveBuffers(t) {
    for (let [e, o] of Object.entries(t))
      if (e === "thinking")
        this.thinking(o);
      else if (e === "tool_calls")
        for (const _ of o)
          _ && Object.keys(_).length > 0 && this.toolCall(_);
      else e === "content" && (this.parser && (o = this.parser(o), t[e] = o), o && this.assistant(o));
  }
  async *restream(t, e) {
    for (; ; ) {
      const { value: o, done: _ } = await t.next();
      if (e && o && e(o), _) break;
      yield o;
    }
  }
  extendedStreamResponse(t, e) {
    let o, _ = "", s = "", r = [];
    const u = async () => {
      const i = JSON.parse(JSON.stringify(this.messages)), l = { service: this.service, options: e, usage: o, messages: i, content: s };
      return _ && (l.thinking = _), r.length > 0 && (l.tool_calls = r), this.abortController = null, l;
    }, n = this.streamResponses(t, this.parsers), c = this.restream(n, (i) => {
      if (i.type === "usage" && i.content && typeof i.content == "object") {
        const l = i.content;
        o = this.parseUsage(l);
      }
      i.type === "tool_calls" && i.content && Array.isArray(i.content) && r.push(...i.content), i.type === "buffers" && (i.thinking && (_ = i.thinking), i.content && (s = i.content));
    });
    return { service: this.service, options: e, stream: c, complete: u, think: this.think ?? !1 };
  }
  async fetchModels() {
    const t = { headers: this.llmHeaders };
    N.debug(`LLM ${this.service} fetchModels`);
    const e = await fetch(this.getModelsUrl(), t);
    await J(e, "Failed to fetch models");
    const o = await e.json();
    let _ = [];
    if (Array.isArray(o) ? _ = o : Array.isArray(o.models) ? _ = o.models : Array.isArray(o.data) && (_ = o.data), !_) throw new Error("No models found");
    return _.map(this.parseModel);
  }
  async verifyConnection() {
    return (await this.fetchModels()).length > 0;
  }
  async getModels(t = {}) {
    return (await this.fetchModels()).map((o) => {
      let _ = B.get(this.service, o.model, t);
      if (!_)
        if (t.allowUnknown)
          _ = { input_cost_per_token: 0, output_cost_per_token: 0, output_cost_per_reasoning_token: 0 };
        else
          throw new Error(`model info not found for ${o.model}`);
      return this.isLocal && (_.input_cost_per_token = 0, _.output_cost_per_token = 0, _.output_cost_per_reasoning_token = 0), { ..._, name: o.name, model: o.model, created: o.created, service: this.service, raw: o };
    }).filter(this.filterQualityModel);
  }
  filterQualityModel(t) {
    return !0;
  }
  async getQualityModels() {
    return this.getModels({ allowUnknown: !0, allowSimilar: !0, topModels: !0 });
  }
  async refreshModelUsage() {
    await this.modelUsage.refresh();
  }
  parseContent(t) {
    throw new Error("parseContent not implemented");
  }
  parseTools(t) {
    return [];
  }
  parseToolsChunk(t) {
    return this.parseTools(t);
  }
  parseContentChunk(t) {
    return this.parseContent(t);
  }
  parseThinking(t) {
    return "";
  }
  parseThinkingChunk(t) {
    return this.parseThinking(t);
  }
  parseModel(t) {
    throw new Error("parseModel not implemented");
  }
  parseMessages(t) {
    return t.map((e) => ((e.role === "thinking" || e.role === "tool_call") && (e.role = "assistant"), e));
  }
  parseOptions(t) {
    return t || {};
  }
  parseTokenUsage(t) {
    return t;
  }
  parseUsage(t) {
    const e = this.modelUsage.getModel(this.model, this.qualityFilter);
    let o = (e == null ? void 0 : e.input_cost_per_token) || 0, _ = (e == null ? void 0 : e.output_cost_per_token) || 0;
    this.isLocal && (o = 0, _ = 0);
    const s = t.input_tokens * o, r = t.output_tokens * _, u = s + r;
    return {
      ...t,
      local: this.isLocal,
      total_tokens: t.input_tokens + t.output_tokens,
      input_cost: s,
      output_cost: r,
      total_cost: u
    };
  }
  resetCache() {
    this.cache = {};
  }
};
w.parsers = H, w.isLocal = !1, w.isBearerAuth = !1;
let d = w;
const k = class k extends d {
  get chatUrl() {
    return m(this.baseUrl, "messages");
  }
  get modelsUrl() {
    return m(this.baseUrl, "models");
  }
  get llmHeaders() {
    const t = Object.assign({
      "anthropic-version": k.API_VERSION
    }, super.llmHeaders);
    return O() && (t["anthropic-dangerous-direct-browser-access"] = "true"), t;
  }
  parseOptions(t) {
    if (t.think) {
      const e = Math.floor((t.max_tokens || 0) / 2);
      t.thinking = { type: "enabled", budget_tokens: e };
    }
    return typeof t.max_thinking_tokens == "number" && (t.thinking.budget_tokens = t.max_thinking_tokens, delete t.max_thinking_tokens), delete t.think, t;
  }
  parseThinking(t) {
    const e = t.content ?? [];
    for (const o of e)
      if (o.type === "thinking" && o.thinking)
        return o.thinking;
    return "";
  }
  parseThinkingChunk(t) {
    if (!t || t.type !== "content_block_delta" || !t.delta) return "";
    const e = t.delta;
    return e.type !== "thinking_delta" || !e.thinking ? "" : e.thinking;
  }
  parseTokenUsage(t) {
    var _, s, r, u, n, c;
    if (!t) return null;
    const e = ((s = (_ = t.message) == null ? void 0 : _.usage) == null ? void 0 : s.input_tokens) || ((r = t.usage) == null ? void 0 : r.input_tokens), o = ((n = (u = t.message) == null ? void 0 : u.usage) == null ? void 0 : n.output_tokens) || ((c = t.usage) == null ? void 0 : c.output_tokens);
    return typeof e != "number" || typeof o != "number" ? null : { input_tokens: e, output_tokens: o };
  }
  parseContent(t) {
    const e = t.content ?? [];
    for (const o of e)
      if (!(o.type !== "text" || !o.text))
        return o.text;
    return "";
  }
  parseContentChunk(t) {
    return t.type !== "content_block_delta" || !t.delta || t.delta.type !== "text_delta" || !t.delta.text ? "" : t.delta.text;
  }
  parseToolsChunk(t) {
    if (t.type === "content_block_start" && t.content_block && t.content_block.type === "tool_use" && (this.cache.tool_call = t.content_block), this.cache.tool_call && t.type === "content_block_delta" && t.delta && t.delta.type === "input_json_delta" && (this.cache.tool_call_input || (this.cache.tool_call_input = ""), this.cache.tool_call_input += t.delta.partial_json), !this.cache.tool_call) return [];
    if (!this.cache.tool_call_input) return [];
    try {
      const e = JSON.parse(this.cache.tool_call_input), o = { id: this.cache.tool_call.id, name: this.cache.tool_call.name, input: e };
      return delete this.cache.tool_call, delete this.cache.tool_call_input, [o];
    } catch {
      return [];
    }
  }
  parseTools(t) {
    if (!t || !t.content || !Array.isArray(t.content)) return [];
    const e = [];
    for (const o of t.content)
      o.type !== "tool_use" || !o.id || !o.name || !o.input || e.push({ id: o.id, name: o.name, input: o.input });
    return e;
  }
  parseModel(t) {
    return { name: t.display_name, model: t.id, created: new Date(t.created_at) };
  }
  filterQualityModel(t) {
    return !(t.mode !== "chat" || t.model.startsWith("claude-2"));
  }
};
k.service = "anthropic", k.DEFAULT_BASE_URL = "https://api.anthropic.com/v1", k.DEFAULT_MODEL = "claude-opus-4-20250514", k.API_VERSION = "2023-06-01";
let C = k;
const f = class f extends d {
  get chatUrl() {
    return m(this.baseUrl, "api/chat");
  }
  get modelsUrl() {
    return m(this.baseUrl, "api/tags");
  }
  get llmHeaders() {
    const t = super.llmHeaders;
    return delete t["x-api-key"], t;
  }
  parseOptions(t) {
    if (t.max_tokens) {
      const e = t.max_tokens;
      delete t.max_tokens, t.options || (t.options = {}), t.options.num_predict = e;
    }
    if (t.tools) {
      const e = t.tools.map((o) => V(o));
      t.tools = e;
    }
    return delete t.apiKey, t;
  }
  parseThinking(t) {
    return !t || !t.message || !t.message.thinking ? "" : t.message.thinking;
  }
  parseTokenUsage(t) {
    return !t || typeof t.prompt_eval_count != "number" || typeof t.eval_count != "number" ? null : { input_tokens: t.prompt_eval_count, output_tokens: t.eval_count };
  }
  parseContent(t) {
    return !t || !t.message || !t.message.content ? "" : t.message.content;
  }
  parseContentChunk(t) {
    return !t || !t.message || !t.message.content || t.message.role !== "assistant" ? "" : t.message.content;
  }
  parseTools(t) {
    return !t || !t.message || !t.message.tool_calls ? [] : t.message.tool_calls.map((e) => P(e));
  }
  parseModel(t) {
    return { name: t.model, model: t.model, created: new Date(t.modified_at) };
  }
  async verifyConnection() {
    return await (await fetch(`${this.baseUrl}`)).text() === "Ollama is running";
  }
};
f.service = "ollama", f.DEFAULT_BASE_URL = "http://localhost:11434", f.DEFAULT_MODEL = "gemma3:4b", f.isLocal = !0;
let A = f;
const b = class b extends d {
  get chatUrl() {
    return m(this.baseUrl, "responses");
  }
  get modelsUrl() {
    return m(this.baseUrl, "models");
  }
  parseOptions(t) {
    if (t.input = t.messages, delete t.messages, t.max_tokens) {
      const e = t.max_tokens;
      delete t.max_tokens, t.max_output_tokens = e;
    }
    if (t.tools) {
      const e = t.tools.map((o) => dt(o));
      t.tools = e;
    }
    return t.think && !t.reasoning && (t.reasoning = { effort: "medium", summary: "detailed" }), delete t.think, t;
  }
  parseContent(t) {
    if (!t || !t.output || !Array.isArray(t.output) || t.object !== "response" || t.status !== "completed") return "";
    for (const e of t.output)
      if (!(e.type !== "message" || e.role !== "assistant" || e.status !== "completed" || !e.content || !Array.isArray(e.content))) {
        for (const o of e.content)
          if (!(o.type !== "output_text" || !o.text))
            return o.text;
      }
    return "";
  }
  parseTokenUsage(t) {
    return t.response && t.type === "response.completed" && (t = t.response), !t || !t.usage || !t.usage.input_tokens || !t.usage.output_tokens ? null : {
      input_tokens: t.usage.input_tokens,
      output_tokens: t.usage.output_tokens
    };
  }
  parseTools(t) {
    if (!t || !t.output || !Array.isArray(t.output)) return [];
    if (t.object !== "response" || t.status !== "completed") return [];
    const e = [];
    for (const o of t.output)
      o.type !== "function_call" || o.status !== "completed" || !o.call_id || !o.name || !o.arguments || e.push({
        id: o.call_id,
        name: o.name,
        input: JSON.parse(o.arguments)
      });
    return e;
  }
  parseToolsChunk(t) {
    if (t.type === "response.output_item.added" && t.item && t.item.type === "function_call" && (this.cache.tool_call = t.item), this.cache.tool_call && t.type === "response.function_call_arguments.done" && (this.cache.tool_call_input = t.arguments), !this.cache.tool_call) return [];
    if (!this.cache.tool_call_input) return [];
    try {
      const e = JSON.parse(this.cache.tool_call_input), o = { id: this.cache.tool_call.id, name: this.cache.tool_call.name, input: e };
      return delete this.cache.tool_call, delete this.cache.tool_call_input, [o];
    } catch {
      return [];
    }
  }
  parseThinking(t) {
    if (!t || !t.output || !Array.isArray(t.output) || t.object !== "response" || t.status !== "completed") return "";
    for (const e of t.output)
      if (!(e.type !== "reasoning" || !e.summary || !Array.isArray(e.summary))) {
        for (const o of e.summary)
          if (!(o.type !== "summary_text" || !o.text))
            return o.text;
      }
    return "";
  }
  parseThinkingChunk(t) {
    return !t || t.type !== "response.reasoning_summary_text.delta" || !t.delta ? "" : t.delta;
  }
  parseContentChunk(t) {
    return !t || !t.delta || t.type !== "response.output_text.delta" ? "" : t.delta;
  }
  parseModel(t) {
    return {
      name: t.model,
      model: t.id,
      created: new Date(t.created * 1e3)
    };
  }
  filterQualityModel(t) {
    const e = [
      "audio",
      "image",
      "davinci",
      "babbage",
      "dall-e",
      "tts",
      "whisper",
      "embedding",
      "vision",
      "moderation",
      "realtime",
      "computer-use",
      "transcribe",
      "instruct",
      "codex"
    ];
    return D(t.model, e);
  }
};
b.service = "openai", b.DEFAULT_BASE_URL = "https://api.openai.com/v1", b.DEFAULT_MODEL = "gpt-4o-mini", b.isBearerAuth = !0;
let T = b;
function dt(p) {
  return {
    name: p.name,
    parameters: Object.assign({}, p.input_schema, { additionalProperties: !1 }),
    strict: !0,
    type: "function",
    description: p.description
  };
}
const z = class z extends d {
  get chatUrl() {
    return m(this.baseUrl, "chat/completions");
  }
  get modelsUrl() {
    return m(this.baseUrl, "models");
  }
  getChatUrl(t) {
    return m(this.baseUrl, "models", `${t.model}:generateContent?key=${this.apiKey}`);
  }
  getModelsUrl() {
    return `${this.modelsUrl}?key=${this.apiKey}`;
  }
  parseOptions(t) {
    const e = JSON.parse(JSON.stringify(t.messages || [])).map((s) => (s.role === "assistant" && (s.role = "model"), s)), o = ct(e, "system"), _ = lt(e, "system");
    return delete t.messages, o.length > 0 && (t.system_instruction = { parts: o.map((s) => ({ text: s.content })) }), _.length > 0 && (t.contents = _.map((s) => ({ role: s.role, parts: [{ text: s.content }] }))), t.generationConfig || (t.generationConfig = {}), typeof t.temperature == "number" && (t.generationConfig.temperature = t.temperature), typeof t.max_tokens == "number" && (t.generationConfig.maxOutputTokens = t.max_tokens), t.generationConfig.maxOutputTokens || (t.generationConfig.maxOutputTokens = this.max_tokens), t.tools && (t.tools = [{ functionDeclarations: t.tools.map((s) => ({
      name: s.name,
      description: s.description,
      parameters: s.input_schema
    })) }]), t.think && (t.generationConfig || (t.generationConfig = {}), t.generationConfig.thinkingConfig = { includeThoughts: !0 }, delete t.think), delete t.think, delete t.max_tokens, delete t.temperature, delete t.stream, t;
  }
  get llmHeaders() {
    const t = super.llmHeaders;
    return delete t["x-api-key"], t;
  }
  parseContent(t) {
    var o, _, s;
    if (!((s = (_ = (o = t == null ? void 0 : t.candidates) == null ? void 0 : o[0]) == null ? void 0 : _.content) != null && s.parts)) return "";
    const e = t.candidates[0].content.parts;
    for (const r of e)
      if (!r.thought)
        return r.text;
    return "";
  }
  parseTokenUsage(t) {
    var o, _;
    if (!((o = t == null ? void 0 : t.usageMetadata) != null && o.promptTokenCount) || !((_ = t == null ? void 0 : t.usageMetadata) != null && _.candidatesTokenCount)) return null;
    const e = t.usageMetadata;
    return { input_tokens: e.promptTokenCount, output_tokens: e.candidatesTokenCount };
  }
  parseModel(t) {
    return {
      name: t.displayName,
      model: t.name.replace(/^models\//, ""),
      created: /* @__PURE__ */ new Date()
      // :(
    };
  }
  parseTools(t) {
    var o, _, s, r, u;
    if (!((u = (r = (s = (_ = (o = t == null ? void 0 : t.candidates) == null ? void 0 : o[0]) == null ? void 0 : _.content) == null ? void 0 : s.parts) == null ? void 0 : r[0]) != null && u.functionCall)) return [];
    const e = t.candidates[0].content.parts[0].functionCall;
    return [{ id: mt(), name: e.name, input: e.args }];
  }
  parseThinking(t) {
    var o, _, s;
    if (!((s = (_ = (o = t == null ? void 0 : t.candidates) == null ? void 0 : o[0]) == null ? void 0 : _.content) != null && s.parts)) return "";
    const e = t.candidates[0].content.parts;
    for (const r of e)
      if (r.thought === !0)
        return r.text;
    return "";
  }
  filterQualityModel(t) {
    const e = ["embedding", "vision", "learnlm", "image-generation", "gemma-3", "gemma-3n", "gemini-1.5", "embedding"];
    return D(t.model, e);
  }
};
z.service = "google", z.DEFAULT_BASE_URL = "https://generativelanguage.googleapis.com/v1beta/", z.DEFAULT_MODEL = "gemini-2.5-flash-preview-05-20";
let U = z;
const h = class h extends d {
  get chatUrl() {
    return m(this.baseUrl, "chat/completions");
  }
  get modelsUrl() {
    return m(this.baseUrl, "models");
  }
  parseOptions(t) {
    if (t.think && !t.reasoning_effort && (t.reasoning_effort = "high"), delete t.think, t.tools) {
      const e = t.tools.map((o) => V(o));
      t.tools = e;
    }
    return t.stream && (t.stream_options = { include_usage: !0 }), t;
  }
  parseContent(t) {
    return !t || !t.choices || !t.choices[0] || !t.choices[0].message ? "" : t.choices[0].message.content;
  }
  parseContentChunk(t) {
    return !t || !t.choices || !t.choices[0] || !t.choices[0].delta || !t.choices[0].delta.content ? "" : t.choices[0].delta.content;
  }
  parseThinking(t) {
    const e = this.constructor.KEY_REASONING_CONTENT;
    return !t || !t.choices || !t.choices[0] || !t.choices[0].message || !t.choices[0].message[e] ? "" : t.choices[0].message[e];
  }
  parseThinkingChunk(t) {
    const e = this.constructor.KEY_REASONING_CONTENT;
    return !t || !t.choices || !t.choices[0] || !t.choices[0].delta || !t.choices[0].delta[e] ? "" : t.choices[0].delta[e];
  }
  parseTokenUsage(t) {
    return !t || !t.usage || !t.usage.prompt_tokens || !t.usage.completion_tokens ? null : {
      input_tokens: t.usage.prompt_tokens,
      output_tokens: t.usage.completion_tokens
    };
  }
  parseModel(t) {
    let e = t.created ? new Date(t.created * 1e3) : /* @__PURE__ */ new Date();
    return { name: t.model, model: t.id, created: e };
  }
  parseTools(t) {
    return !t || !t.choices || !t.choices[0] || !t.choices[0].message || !t.choices[0].message.tool_calls ? [] : t.choices[0].message.tool_calls.map((e) => P(e));
  }
  parseToolsChunk(t) {
    return !t || !t.choices || !t.choices[0] || !t.choices[0].delta || !t.choices[0].delta.tool_calls ? [] : t.choices[0].delta.tool_calls.map((e) => P(e));
  }
  filterQualityModel(t) {
    const e = ["audio", "vision", "image"];
    return D(t.model, e);
  }
};
h.service = "openai", h.DEFAULT_BASE_URL = "", h.DEFAULT_MODEL = "", h.isBearerAuth = !0, h.KEY_REASONING_CONTENT = "reasoning_content";
let x = h;
const q = class q extends x {
};
q.service = "xai", q.DEFAULT_BASE_URL = "https://api.x.ai/v1/", q.DEFAULT_MODEL = "grok-3";
let E = q;
const y = class y extends x {
  parseOptions(t) {
    return t = super.parseOptions(t), t.reasoning_effort === "high" && (delete t.reasoning_effort, t.reasoning_format || (t.reasoning_format = "parsed")), t;
  }
  // groq wraps usage in x_groq for streaming
  parseTokenUsage(t) {
    return !t || (!t.usage && t.x_groq && t.x_groq.usage && (t = t.x_groq), !t || !t.usage) || !t.usage.prompt_tokens || !t.usage.completion_tokens ? null : {
      input_tokens: t.usage.prompt_tokens,
      output_tokens: t.usage.completion_tokens
    };
  }
  filterQualityModel(t) {
    return D(t.model, ["whisper", "tts"]);
  }
};
y.service = "groq", y.DEFAULT_BASE_URL = "https://api.groq.com/openai/v1/", y.DEFAULT_MODEL = "deepseek-r1-distill-llama-70b", y.KEY_REASONING_CONTENT = "reasoning";
let I = y;
const $ = class $ extends x {
};
$.service = "deepseek", $.DEFAULT_BASE_URL = "https://api.deepseek.com/v1/", $.DEFAULT_MODEL = "deepseek-chat";
let S = $, L = [C, A, T, U, E, I, S];
function kt(p, t) {
  let e, o;
  typeof p == "string" || Array.isArray(p) ? (e = p, o = t || {}) : typeof p == "object" && p !== null ? (e = void 0, o = p) : (e = void 0, o = {});
  let _;
  const s = (o == null ? void 0 : o.service) ?? Y.service;
  let r = L.find((n) => n.service === s);
  return r || (r = x), _ = new r(e, o), new.target ? _ : _.send();
}
const a = kt;
a.parsers = H;
a.services = L;
a.ModelUsage = B;
a.Anthropic = C;
a.Ollama = A;
a.OpenAI = T;
a.Google = U;
a.xAI = E;
a.Groq = I;
a.DeepSeek = S;
a.APIv1 = x;
a.LLM = d;
a.register = (p) => {
  L.push(p);
};
a.unregister = (p) => {
  L = L.filter((t) => t !== p);
};

//# sourceMappingURL=index.mjs.map


/***/ }),

/***/ "./private/js/ask_jenna.js":
/*!*********************************!*\
  !*** ./private/js/ask_jenna.js ***!
  \*********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AskJenna: () => (/* binding */ AskJenna)
/* harmony export */ });
/* harmony import */ var _themaximalist_llm_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @themaximalist/llm.js */ "./node_modules/@themaximalist/llm.js/dist/index.mjs");


class AskJenna {
    constructor(options, prompts) {
        this.options = options;
        this.prompts = prompts;
    }

    fill_input(el) {
        if (!this.prompts[el.name]) {
            return;
        }
        const status = el.disabled;
        const previousValue = el.value;
        el.value = '';  // Clear the input field
        el.disabled = true;  // Disable the input field to prevent changes while processing
        console.log("Field", el.value);
        this.extendedLLM(el.name).then((result) => {
            console.log(result);
            el.value = this.deconstructJson(result);
            el.disabled = status;
        }).catch(err => {
            el.value = previousValue;  // Restore previous value on error
            el.disabled = status;  // Restore previous disabled state
            console.error(err);
        });
    }

    deconstructJson(json) {
        if (typeof json == 'string') {
            return json;
        }
        if (typeof json == 'object' && Object.keys(json).length === 1) {
            const key = Object.keys(json)[0];
            return this.deconstructJson(json[key]);
        }
        if (Array.isArray(json) && json.length === 1) {
            return this.deconstructJson(json[0]);
        }
        return json;
    }

    async extendedLLM(name) {
        if (this.prompts[name]?.dynamic_content) {
            const response = await fetch(this.prompts[name].dynamic_content);
            const div = document.createElement('div');
            div.innerHTML = await response.text();
            const nodeToRemove = div.querySelector('div#cms-top');
            if (nodeToRemove) {
                nodeToRemove.remove();
            }
            div.querySelectorAll('meta, style, script, template, nav').forEach(node => node.remove());
            const content = this.htmlToMDContent(div);
            return (0,_themaximalist_llm_js__WEBPACK_IMPORTED_MODULE_0__["default"])(`Here is HTML content: ${content}\n\n${this.prompts[name].prompt}`, this.options);
        }
        return (0,_themaximalist_llm_js__WEBPACK_IMPORTED_MODULE_0__["default"])(this.prompts[name].prompt, this.options);
    }

    htmlToMDContent (element) {
        function traverse(node) {
            if (node.nodeType === Node.TEXT_NODE) {
            return node.textContent;
            }
            if (node.nodeType !== Node.ELEMENT_NODE) {
            return '';
            }
            let md = '';
            switch (node.tagName.toLowerCase()) {
            case 'h1':
                md += '# ' + Array.from(node.childNodes).map(traverse).join('').trim() + '\n\n';
                break;
            case 'h2':
                md += '## ' + Array.from(node.childNodes).map(traverse).join('').trim() + '\n\n';
                break;
            case 'h3':
                md += '### ' + Array.from(node.childNodes).map(traverse).join('').trim() + '\n\n';
                break;
            case 'h4':
                md += '#### ' + Array.from(node.childNodes).map(traverse).join('').trim() + '\n\n';
                break;
            case 'h5':
                md += '##### ' + Array.from(node.childNodes).map(traverse).join('').trim() + '\n\n';
                break;
            case 'h6':
                md += '###### ' + Array.from(node.childNodes).map(traverse).join('').trim() + '\n\n';
                break;
            case 'strong':
            case 'b':
                md += '**' + Array.from(node.childNodes).map(traverse).join('') + '**';
                break;
            case 'em':
            case 'i':
                md += '*' + Array.from(node.childNodes).map(traverse).join('') + '*';
                break;
            case 'code':
                md += '`' + Array.from(node.childNodes).map(traverse).join('') + '`';
                break;
            case 'pre':
                md += '```\n' + Array.from(node.childNodes).map(traverse).join('') + '\n```\n\n';
                break;
            case 'ul':
                md += Array.from(node.children).map(li => '- ' + traverse(li).trim()).join('\n') + '\n\n';
                break;
            case 'ol':
                md += Array.from(node.children).map((li, i) => `${i + 1}. ${traverse(li).trim()}`).join('\n') + '\n\n';
                break;
            case 'li':
                md += Array.from(node.childNodes).map(traverse).join('');
                break;
            case 'a':
                const href = node.getAttribute('href') || '';
                md += `[${Array.from(node.childNodes).map(traverse).join('')}](${href})`;
                break;
            case 'img':
                const alt = node.getAttribute('alt') || '';
                const src = node.getAttribute('src') || '';
                md += `![${alt}](${src})`;
                break;
            case 'blockquote':
                md += '> ' + Array.from(node.childNodes).map(traverse).join('').replace(/\n/g, '\n> ') + '\n\n';
                break;
            case 'br':
                md += '  \n';
                break;
            case 'p':
                md += Array.from(node.childNodes).map(traverse).join('').trim() + '\n\n';
                break;
            default:
                md += Array.from(node.childNodes).map(traverse).join('');
            }
            return md;
        }
        return traverse(element).replace(/\n{3,}/g, '\n\n').trim();
    }

    async ask(question) {
        try {
            const response = await this.llm.chat({
                messages: [
                    { role: "system", content: "You are Jenna, a helpful assistant." },
                    { role: "user", content: question }
                ]
            });
            return response.choices[0].message.content;
        } catch (error) {
            console.error("Error asking Jenna:", error);
            throw new Error("Failed to get a response from Jenna.");
        }
    }
}



/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId](module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
var __webpack_exports__ = {};
// This entry needs to be wrapped in an IIFE because it needs to be isolated against other modules in the chunk.
(() => {
/*!***************************************!*\
  !*** ./private/js/admin.ask_jenna.js ***!
  \***************************************/
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _ask_jenna__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ask_jenna */ "./private/js/ask_jenna.js");



document.addEventListener('DOMContentLoaded', () => {
    const jenna_config = JSON.parse(document.getElementById('ask_jenna_settings').textContent);
    const jenna_scripts = JSON.parse(document.getElementById('ask_jenna_scripts').textContent);

    const llm = new _ask_jenna__WEBPACK_IMPORTED_MODULE_0__.AskJenna(jenna_config, jenna_scripts);
    for (let field of Object.keys(jenna_scripts)) {
        console.log(field);
        const el = document.querySelector(`input[name="${field}"]:not([disabled]),textarea[name="${field}"]:not([disabled])`);
        if (el) {
            console.log("adding listener");
            el.addEventListener('dblclick', (ev) => {
                console.log("dblClick on ", ev.target.name);
                llm.fill_input(ev.target, jenna_scripts[ev.target.name]?.prompt);
            })
        }
    }
    }
)
})();

/******/ })()
;
//# sourceMappingURL=bundle.admin.min.js.map